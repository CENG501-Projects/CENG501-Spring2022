{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3ed2b79-1e79-4bd4-a2a6-49c0f861eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#  print(\"Cuda (GPU support) is available and enabled!\")\n",
    "#  device = torch.device(\"cuda\")\n",
    "#else:\n",
    "#  print(\"Cuda (GPU support) is not available :(\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f1b255-c2a7-45f9-839c-922daac148bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/umut/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/umut/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/umut/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "Using cache found in /home/umut/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
    "\n",
    "resnet50.eval().to(device)\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc84006e-079c-419e-b414-6a56b781f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"/home/umut/Desktop/501/others/Export/\"\n",
    "image_filenames = os.listdir(feature_path)[:2880]\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82be921-1b5b-4a3c-82e5-e9d29e52ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, _ = get_graph_node_names(resnet50)\n",
    "\n",
    "return_nodes = {\n",
    "    'layers.0.0.downsample.1': 'layer1',\n",
    "    'layers.1.0.downsample.1': 'layer2',\n",
    "    'layers.2.0.downsample.1': 'layer3'\n",
    "}\n",
    "\n",
    "\n",
    "extractor = create_feature_extractor(resnet50, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "007b9ea4-9746-4ad3-aced-04ae4bf6d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = torch.Tensor(np.zeros(shape=(len(image_filenames), 3, 480, 640)))\n",
    "idx = 0\n",
    "for idx, filename in enumerate(image_filenames):\n",
    "    image = Image.open(feature_path + filename)\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "    input_tensor = preprocess(image)\n",
    "    all_tensors[idx] = input_tensor\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c4b6c1-29cd-477f-9206-f2077a1ddbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor(all_tensors.to(device)) # Unable to run this with all the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec215f5-3a91-448b-93b7-a3773ed3103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['layer1', 'layer2', 'layer3'])\n"
     ]
    }
   ],
   "source": [
    "print(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "636bcb0a-82ae-4806-85d1-f52de6e6851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/features.pkl', 'wb') as f:\n",
    "    pickle.dump(features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
