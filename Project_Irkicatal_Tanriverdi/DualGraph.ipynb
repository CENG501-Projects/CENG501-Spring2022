{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DualGraph.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOyeuL9KXf2jhhH76qKfJJf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JtqmJn2XsZx4"},"outputs":[],"source":[""]},{"cell_type":"code","source":["import os\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision.transforms as transforms\n","import argparse, sys\n","import numpy as np\n","import datetime\n","import shutil\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric \n","\n","from torch_geometric.datasets import CitationFull\n","import torch_geometric.utils as utils"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"switi-F6sbCM","executionInfo":{"status":"ok","timestamp":1657133022376,"user_tz":-180,"elapsed":29389,"user":{"displayName":"Kadir TANRIVERDİ","userId":"12146459471137891605"}},"outputId":"035a2b6d-9d26-4194-f002-ecfe71d76c53"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 3.8 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.14-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.14\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 3.9 MB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n","Collecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n","\u001b[K     |████████████████████████████████| 750 kB 3.6 MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n","\u001b[K     |████████████████████████████████| 407 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=fe3220c60eddeb092ff29f3420d7fd5543e3014df8c5463a461d754ab0819e66\n","  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.0.4\n"]}]},{"cell_type":"markdown","source":["**Graph Conv Layer Forward Pass**"],"metadata":{"id":"WaRPY7fBGUeX"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from copy import deepcopy\n","from torch_geometric.nn import GCNConv\n","import numpy as np\n","import scipy.sparse as sp\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","\n","\n","class GraphConvLayer(nn.Module):\n","    def __init__(self, in_feature, out_feature, no_class, dropout=0.6, lr=0.001, weight_decay=6e-4,device=None):\n","\n","        super(GraphConvLayer, self).__init__()\n","\n","        # Iteration number for DualGraph is 2\n","        self.device = device\n","        self.in_feature = in_feature\n","        self.out_feature = [out_feature]\n","        self.no_class = no_class\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","        self.edge_index = None\n","        self.edge_weight = None\n","        self.features = None\n","        \n","        self.gcn1 = GCNConv(in_feature, out_feature, bias=True,add_self_loops=True)\n","        self.gcn2 = GCNConv(out_feature, no_class, bias=True,add_self_loops=True)\n","\n","        self.dropout = dropout\n","\n","        # Conv_ReLu_BN mapping from Rm to R1\n","        self.conv_layer =nn.Conv2d(in_feature,128,kernel_size=3,stride=1, padding=1)\n","        self.BN = nn.BatchNorm2d(128)\n","\n","\n","    def forward(self, x, edge_index, edge_weight):\n","        #trans_net = self.dropout(F.relu(self.BN(self.conv_layer(x))))\n","        x = F.relu(self.gcn1(x, edge_index,edge_weight),inplace = False)\n","        x = F.dropout(x, self.dropout, training=self.training)\n","        x = self.gcn2(x, edge_index,edge_weight)\n","\n","        return x"],"metadata":{"id":"aiLp3Z_gsa8S","executionInfo":{"status":"ok","timestamp":1657142009844,"user_tz":-180,"elapsed":468,"user":{"displayName":"Kadir TANRIVERDİ","userId":"12146459471137891605"}}},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":["**Adding Noise For Noisy Labels**"],"metadata":{"id":"zj71EFHXGsZ1"}},{"cell_type":"code","source":["import numpy as np\n","from numpy.testing import assert_array_almost_equal\n","import torch\n","\n","# %%\n","def acc(output, labels):\n","    if not hasattr(labels, '__len__'):\n","        labels = [labels]\n","    if type(labels) is not torch.Tensor:\n","        labels = torch.LongTensor(labels)\n","    preds = output.max(1)[1].type_as(labels)\n","    correct = preds.eq(labels).double()\n","    correct = correct.sum()\n","    return correct / len(labels)\n","\n","def ConstructPairMatrix(size, noise):\n","    assert(noise >= 0.) and (noise <= 1.)\n","    PairMatrix = (1.0 - np.float64(noise)) * np.eye(size)\n","    for i in range(size):\n","        PairMatrix[i,i-1] = np.float64(noise)\n","    assert_array_almost_equal(PairMatrix.sum(axis=1), 1, 1)\n","    return PairMatrix\n","\n","\n","def ConstructUniforMatrix(size, noise):\n","    assert(noise >= 0.) and (noise <= 1.)\n","\n","    UniformMatrix = np.float64(noise) / np.float64(size - 1) * np.ones((size, size))\n","    np.fill_diagonal(UniformMatrix, (np.float64(1)-np.float64(noise))*np.ones(size))\n","    \n","    diag_idx = np.arange(size)\n","    UniformMatrix[diag_idx,diag_idx] = UniformMatrix[diag_idx,diag_idx] + 1.0 - UniformMatrix.sum(0)\n","    assert_array_almost_equal(UniformMatrix.sum(axis=1), 1, 1)\n","    return UniformMatrix\n","\n","def AddNoiseForMultClass(inp, NoiseMatrix, random_state=0):\n","    \"\"\" Flip classes according to transition probability matrix T.\n","    It expects a number between 0 and the number of classes - 1.\n","    \"\"\"\n","\n","    assert NoiseMatrix.shape[0] == NoiseMatrix.shape[1]\n","    assert np.max(inp) < NoiseMatrix.shape[0]\n","\n","    # row stochastic matrix\n","    assert_array_almost_equal(NoiseMatrix.sum(axis=1), np.ones(NoiseMatrix.shape[1]))\n","    assert (NoiseMatrix >= 0.0).all()\n","\n","    m = inp.shape[0]\n","    out = inp.copy()\n","    flipper = np.random.RandomState(random_state)\n","\n","    for idx in np.arange(m):\n","        i = inp[idx]\n","        flipped = flipper.multinomial(1, NoiseMatrix[i, :], 1)[0]\n","        out[idx] = np.where(flipped == 1)[0]\n","    return out\n","\n","def Add_noise(train_inp, no_classes, noise, random_state=None,  noise_type='uniform'):\n","    if noise > 0.0:\n","        if noise_type=='pair':\n","            NoiseMatrix = ConstructPairMatrix(no_classes, noise)\n","        elif noise_type == 'uniform':\n","            NoiseMatrix = ConstructUniforMatrix(no_classes, noise)\n","        noisy_train_inp = AddNoiseForMultClass(train_inp, NoiseMatrix=NoiseMatrix,\n","                                           random_state=random_state)\n","        actual_noise = (noisy_train_inp != train_inp).mean()\n","        assert actual_noise > 0.0\n","        print('Actual noise %.2f' % actual_noise)\n","        train_inp = noisy_train_inp\n","    else:\n","        NoiseMatrix = np.eye(no_classes)\n","\n","    return train_inp, NoiseMatrix"],"metadata":{"id":"kCbgsQMYtRNW","executionInfo":{"status":"ok","timestamp":1657142017760,"user_tz":-180,"elapsed":416,"user":{"displayName":"Kadir TANRIVERDİ","userId":"12146459471137891605"}}},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":["**Our Model For DualGraph**"],"metadata":{"id":"Di4cDzCFGvkR"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from copy import deepcopy\n","\n","import numpy as np\n","import scipy.sparse as sp\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","\n","class CELogLoss(nn.Module):\n","\n","    def __init__(self, nclass):\n","        super(CELogLoss, self).__init__()\n","        P = torch.FloatTensor(ConstructUniforMatrix(nclass,0.1))\n","        self.B = torch.nn.parameter.Parameter(torch.log(P))\n","    \n","    def forward(self, pred):\n","        P = F.softmax(self.B, dim=1)\n","        return pred @ P\n","\n","class DualGraph(nn.Module):\n","    \"\"\" 2 Layer Graph Convolutional Network.\n","    \"\"\"\n","\n","    def __init__(self, in_feature, out_feature, no_class, dropout=0.51, lr=0.012, weight_decay=6e-4,device=None):\n","\n","        super(DualGraph, self).__init__()\n","        assert device is not None, \"Please specify 'device'!\"\n","        self.device = device\n","        self.in_feature = in_feature\n","        self.out_feature = [out_feature]\n","        self.no_class = no_class\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","        self.edge_index = None\n","        self.edge_weight = None\n","        self.features = None\n","\n","        self.loss_log = CELogLoss(no_class)\n","        self.dropout = dropout\n","        self.GCN1 = GraphConvLayer(in_feature,out_feature,no_class,dropout,device=device)\n","        self.GCN2 = GraphConvLayer(in_feature,out_feature,no_class,dropout,device=device)\n","\n","    def forward(self, x, edge_index, edge_weight):\n","\n","        return self.GCN1(x,edge_index,edge_weight), self.GCN2(x,edge_index,edge_weight)\n","\n","    def fit(self, features, adj, labels, train_index, valid_index=None, noise_rate=0.19, ek=10,train_iters=205, verbose=True):\n","\n","        self.edge_index, self.edge_weight = from_scipy_sparse_matrix(adj)\n","        self.edge_index, self.edge_weight = self.edge_index.to(self.device), self.edge_weight.float().to(self.device)\n","\n","        if sp.issparse(features):\n","            features = utils.sparse_mx_to_torch_sparse_tensor(features).to_dense().float()\n","        else:\n","            features = torch.FloatTensor(np.array(features))\n","        self.features = features.to(self.device)\n","        self.labels = torch.LongTensor(np.array(labels)).to(self.device)\n","\n","        self.noise_rate = noise_rate\n","        self.Train(self.labels, train_index, valid_index, ek ,train_iters, verbose)\n","\n","    def Train(self, labels, train_index, idx_val, ek,train_iters, verbose):\n","        if verbose:\n","            print('=== training gcn model ===')\n","        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n","\n","        best_loss_val = 100\n","        best_acc_val = 0\n","        train_index = np.asarray(train_index)\n","\n","        for i in range(train_iters):\n","            self.train()\n","            optimizer.zero_grad()\n","            out_1, out_2 = self.forward(self.features, self.edge_index, self.edge_weight)\n","\n","            prediction_1 = out_1[train_index].max(1)[1]\n","            prediction_2 = out_2[train_index].max(1)[1]\n","\n","            disagree = (prediction_1 != prediction_2).cpu().numpy()\n","            idx_update = train_index[disagree]\n","\n","            if len(idx_update) == 0:\n","                break\n","\n","            prediction_1 = F.softmax(out_1,dim=1)\n","            prediction_2 = F.softmax(out_2,dim=1)\n","            eps = 1e-8\n","            score_1 = self.loss_log(prediction_1).clamp(eps,1-eps)\n","            score_2 = self.loss_log(prediction_2).clamp(eps,1-eps)\n","\n","            loss_1 = F.cross_entropy(torch.log(score_1[idx_update]), self.labels[idx_update])\n","            loss_2 = F.cross_entropy(torch.log(score_2[idx_update]), self.labels[idx_update])\n","\n","            train_loss = loss_1.mean() + loss_2.mean()\n","            train_loss.backward()\n","            optimizer.step()\n","\n","            self.eval()\n","            output1, output2 = self.forward(self.features, self.edge_index, self.edge_weight)\n","            acc_val = max(acc(output1[idx_val], labels[idx_val]),acc(output2[idx_val], labels[idx_val]))\n","            if acc_val > best_acc_val:\n","                best_acc_val = acc_val\n","                weights = deepcopy(self.state_dict())\n","            if verbose and i % 1 == 0:\n","                print('Epoch {}, training loss: {}, acc_val: {:.4f}'.format(i, train_loss.item(),acc_val))\n","\n","        if verbose:\n","            print('=== picking the best model according to the performance on validation ===')\n","        self.load_state_dict(weights)\n","\n","\n","    def Test(self, test_index):\n","        self.eval()\n","        out1, out2 = self.forward(self.features, self.edge_index, self.edge_weight)\n","        accuracy_1 = acc(out1[test_index], self.labels[test_index])\n","        accuracy_2 = acc(out2[test_index], self.labels[test_index])\n","        print(\"Test set results:\",\n","              \"acc_1= {:.4f}\".format(accuracy_1.item()),\n","              \"acc_2= {:.4f}\".format(accuracy_2.item()))\n","        return out1,out2\n","\n","\n","# %%"],"metadata":{"id":"jalxFEhYsajn","executionInfo":{"status":"ok","timestamp":1657142021412,"user_tz":-180,"elapsed":419,"user":{"displayName":"Kadir TANRIVERDİ","userId":"12146459471137891605"}}},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":["**Main Code**"],"metadata":{"id":"0ds-rMHoG4RS"}},{"cell_type":"code","source":["import time\n","import argparse\n","import numpy as np\n","import torch\n","\n","# Parameters for the Training Session\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--ek', type=int, default=50)\n","parser.add_argument('--no-cuda', action='store_true', default=False)\n","parser.add_argument('--epochs', type=int,  default=500)\n","parser.add_argument(\"--label_rate\", type=float, default=0.069)\n","parser.add_argument('--ptb_rate', type=float, default=0.19)\n","parser.add_argument('--dropout', type=float, default=0.6)\n","parser.add_argument('--lr', type=float, default=0.01)\n","parser.add_argument('--debug', action='store_true',default=False)\n","parser.add_argument('--seed', type=int, default=11)\n","parser.add_argument('--weight_decay', type=float, default=6e-4)\n","parser.add_argument('--hidden', type=int, default=20)\n","parser.add_argument('--dataset', type=str, default='dplb',choices=['cora', 'cora_ml', 'citeseer', 'polblogs', 'pubmed','dblp'])\n","parser.add_argument('--noise', type=str, default='uniform',choices=['uniform', 'pair'])\n","args = parser.parse_known_args()[0]\n","args.cuda = not args.no_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","\n","if args.cuda:\n","    torch.cuda.manual_seed(args.seed)\n","print(args)\n","\n","np.random.seed(15) \n","\n","\n","from torch_geometric.datasets import CitationFull\n","import torch_geometric.utils as torch_utils\n","\n","dataset = CitationFull('./data','dblp')\n","adj = torch_utils.to_scipy_sparse_matrix(dataset.data.edge_index)\n","\n","labels = dataset.data.y.numpy()\n","features = dataset.data.x.numpy()\n","index = np.arange(len(labels))\n","np.random.shuffle(index)\n","\n","valid_index = index[int(0.8 * len(labels)):int(0.9 * len(labels))]\n","train_index = index[int(0.9 * len(labels)):int((0.9+args.label_rate) * len(labels))]\n","test_index = index[:int(0.8 * len(labels))]\n","\n","\n","ptb = args.ptb_rate\n","no_class = labels.max() + 1\n","Train_data = labels[train_index]\n","noisy_out, _ = Add_noise(Train_data,no_class, ptb,10, args.noise)\n","noisy_labels = labels.copy()\n","noisy_labels[train_index] = noisy_out\n","\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","\n","model = DualGraph(in_feature=features.shape[1],\n","            out_feature=args.hidden,\n","            no_class=labels.max().item() + 1,\n","            dropout=args.dropout, device=device).to(device)\n","\n","#%%\n","model.fit(features, adj, noisy_labels, train_index, valid_index,train_iters=200, ek=args.ek,verbose=args.debug)\n","model.Test(test_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yawoK7Y8tGH_","executionInfo":{"status":"ok","timestamp":1657142120702,"user_tz":-180,"elapsed":96957,"user":{"displayName":"Kadir TANRIVERDİ","userId":"12146459471137891605"}},"outputId":"31a30e34-9a02-4863-df43-25a4b4904188"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(cuda=False, dataset='dplb', debug=False, dropout=0.6, ek=50, epochs=500, hidden=20, label_rate=0.069, lr=0.01, no_cuda=False, noise='uniform', ptb_rate=0.19, seed=11, weight_decay=0.0006)\n","Actual noise 0.18\n","Test set results: acc_1= 0.7948 acc_2= 0.8025\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.1342,  0.7117, -0.3678, -0.2778],\n","         [ 0.2525,  0.5993, -0.4415, -0.1878],\n","         [ 0.0897,  0.6830, -0.2571, -0.2657],\n","         ...,\n","         [ 0.3589,  0.2860, -0.3128, -0.4767],\n","         [ 0.2239,  0.2602, -0.3767, -0.1291],\n","         [ 0.2544,  0.0280, -0.3141, -0.0533]], grad_fn=<AddBackward0>),\n"," tensor([[-0.3050,  0.3632, -0.2144, -0.3986],\n","         [-0.1551,  0.1421, -0.3134, -0.4124],\n","         [-0.2900,  0.3383, -0.1037, -0.4785],\n","         ...,\n","         [ 0.2470, -0.2791,  0.0032, -0.5151],\n","         [ 0.0539, -0.1170, -0.4240, -0.1629],\n","         [ 0.2377, -0.2898, -0.4556,  0.0070]], grad_fn=<AddBackward0>))"]},"metadata":{},"execution_count":126}]}]}