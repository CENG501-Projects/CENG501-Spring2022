{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yigitv4rli/CENG501-Spring2022/blob/main/Project_Kose_Varli/experiments/fashionmnist_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiwgXYDpmn7h",
        "outputId": "3340da3e-d096-4955-bd06-d8635af51d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# import libraries here\n",
        "import torch \n",
        "import math\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import json\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "\n",
        "seed_alg = random.randint(0,100)\n",
        "torch.manual_seed(seed_alg)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eA315F9m526"
      },
      "source": [
        "# Utility Functions\n",
        "\n",
        "This section includes utility functions for overall model\n",
        "1. Learning Schedulers\n",
        "2. Data Loaders\n",
        "3. Train and Test Accuracy\n",
        "4. Result Saving\n",
        "5. Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbY8kFD0nWct"
      },
      "outputs": [],
      "source": [
        "# scheduler functions\n",
        "def constant_learning_rate_scheduler(lr):\n",
        "    def scheduler(_):\n",
        "        return lr\n",
        "    return scheduler\n",
        "\n",
        "def cosine_learning_rate_scheduler(lr, epoch_count):\n",
        "    def scheduler(current_epoch):\n",
        "        return lr * (1 + math.cos(current_epoch * math.pi / epoch_count))\n",
        "    return scheduler\n",
        "\n",
        "def diminishing_learning_rate_scheduler(lr, alpha):\n",
        "    def scheduler(current_epoch):\n",
        "        return lr / ((current_epoch + alpha) ** (1/3))\n",
        "    return scheduler\n",
        "\n",
        "def exponential_learning_rate_scheduler(lr, alpha):\n",
        "    def scheduler(current_epoch):\n",
        "        return lr * (alpha ** current_epoch)\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "# function that saves history a json\n",
        "def save_history_json(file_name, history):\n",
        "  with open(file_name, \"w\") as out:\n",
        "    json.dump(history, out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxCuSdVmW4qu"
      },
      "outputs": [],
      "source": [
        "# data loaders for cifar10 and fashionmnist\n",
        "def cifar10_loader(batch_size, ssmg):\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "    \n",
        "    # a check if the loader is called for Single Shuffling Momentum Gradient (SSMG)\n",
        "    # we do shuffling once at the beginning then we create the train loader\n",
        "    if ssmg:\n",
        "        shuffled_set = torch.utils.data.Subset(train_set, torch.randperm(len(train_set)))\n",
        "        train_loader = torch.utils.data.DataLoader(shuffled_set, batch_size=batch_size,\n",
        "                                            shuffle=False, num_workers=2) \n",
        "\n",
        "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "\n",
        "    # classes = ('plane', 'car', 'bird', 'cat',\n",
        "    #        'deer', 'dog', 'frog', 'horse', 'ship', 'truck')     \n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def fashionmnist_loader(batch_size, ssmg):\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean = (0.1307,), std = (0.3081,))]) #Stolen\n",
        "    \n",
        "    train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, \n",
        "                                                download=True, transform=transform,) \n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # a check if the loader is called for Single Shuffling Momentum Gradient (SSMG)\n",
        "    # we do shuffling once at the beginning then we create the train loader\n",
        "    if ssmg:\n",
        "        shuffled_set = torch.utils.data.Subset(train_set, torch.randperm(len(train_set)))\n",
        "        train_loader = torch.utils.data.DataLoader(shuffled_set, batch_size=batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "\n",
        "    test_set = torchvision.datasets.FashionMNIST(root='./data', train=False, \n",
        "                                                download=True, transform=transform,) \n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twidz1Pzclrt"
      },
      "outputs": [],
      "source": [
        "def train_and_test_accuracy(model, train_loader, test_loader):\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    test_accuracy = 100 * correct / total\n",
        "\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data in train_loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    return train_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "    plt.legend(fontsize = 18)\n",
        "    plt.xticks(size = 18)\n",
        "    plt.yticks(size = 18)\n",
        "    plt.xlabel('Number of effective passes', fontsize = 25)\n",
        "    plt.ylabel('Train Loss', fontsize = 25)\n",
        "    plt.yscale('log')\n",
        "    loss_history = history['loss_history']\n",
        "    x = [i for i in range(10,210,10)]\n",
        "    y = [np.sum(loss_history[k:k+10])/10 for k in range(0,200,10)]\n",
        "    plt.plot(x, y, '-ok', color='blue')\n",
        "\n",
        "def plot_norm_square_grad(history):\n",
        "    plt.xticks(size = 18)\n",
        "    plt.yticks(size = 18)\n",
        "    plt.xlabel('Number of effective passes', fontsize = 18)\n",
        "    plt.ylabel('Grad loss', fontsize = 18)\n",
        "    plt.yscale('log')\n",
        "    grad_history = history['grad_history']\n",
        "    x = [i for i in range(10,210, 10)]\n",
        "    y = [np.sum(grad_history[y:y+10])/10 for y in range(0,200,10)]\n",
        "    plt.plot(x, y, '-ok', color='red')\n"
      ],
      "metadata": {
        "id": "hOtpmmIlTLEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSBigh9DcC2e"
      },
      "source": [
        "# Trainers Code Section"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMG Train Function"
      ],
      "metadata": {
        "id": "LVoe9zLPPeNt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mwjdWiDiag9"
      },
      "outputs": [],
      "source": [
        "# This trainer trains the net using the SMG algorithm proposed in the paper.\n",
        "# We named the variables identical with the paper's algorithm notation. Different from paper\n",
        "# the types we used are PyTorch tensors.\n",
        "def SMG_train(model, criterion, epochs, train_loader, test_loader, scheduler, beta, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the dictionary of history that includes loss, grads, test and train accuracies.\n",
        "  \"\"\"\n",
        "  history = dict()\n",
        "  history['loss_history'], history['grad_history'] = list(), list()\n",
        "  history['test_acc_history'], history['train_acc_history'] = list(), list()\n",
        "  \n",
        "  #Note that velocity depends on gradient. So, per each different weight gradient we will have a different velocity, thus different momentum.\n",
        "  #Therefore, we store velocity and momentum per weight seperately.\n",
        "  m = dict()\n",
        "  v = dict()\n",
        "  # Initialize momentum and velocity dictionaries for weights with zeros.\n",
        "  for n, w in model.named_parameters():\n",
        "    m[n] = torch.zeros_like(w.data, memory_format = torch.preserve_format)\n",
        "    v[n] = torch.zeros_like(w.data, memory_format = torch.preserve_format)\n",
        "\n",
        "\n",
        "\n",
        "  #Note that we have activated shuffling. When iterator advances to the end\n",
        "  #of the batches reshuffles. This is effectively shuffling the batch\n",
        "  #before every batch.\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_grad_norm = 0\n",
        "    lr = scheduler(epoch+1)\n",
        "    # At the beginning of each epoch\n",
        "    # Set m = v\n",
        "    for n, w in model.named_parameters():\n",
        "      m[n] = v[n]\n",
        "    \n",
        "    # Set v = 0\n",
        "    for n, w in model.named_parameters():\n",
        "      v[n] = torch.zeros_like(w.data, memory_format = torch.preserve_format)\n",
        "\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):    \n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      normalizer = labels.size(0) / len(train_loader.dataset)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "      total_loss += loss.item() * normalizer;\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Paper proposes an alternative scheme to update the weights using momentum with batch shuffling. \n",
        "      for n, w in model.named_parameters():\n",
        "        with torch.no_grad():\n",
        "          #Pytorch computes a batch gradient which is 1/batch_size * grad. In update scheme we use 1/n so we set a grad_scale to compansate that.\n",
        "          g_scale = labels.size(0) / len(train_loader.dataset) #batch_size / dataset_size\n",
        "          #Update v\n",
        "          v[n] += g_scale * w.grad.data\n",
        "          delta = beta * m[n] + (1-beta) * w.grad.data #weight_update\n",
        "          w.data += -lr * delta\n",
        "\n",
        "\n",
        "\n",
        "      #Measure grad_square\n",
        "      for p in model.parameters():\n",
        "          param_norm = p.grad.detach().data.norm(2)\n",
        "          total_grad_norm += param_norm.item() ** 2 * normalizer\n",
        "      \n",
        "    \n",
        "    \n",
        "    history['grad_history'].append(total_grad_norm)\n",
        "    history['loss_history'].append(total_loss)\n",
        "    \n",
        "    train_acc, test_acc = train_and_test_accuracy(model, train_loader, test_loader)\n",
        "    history['train_acc_history'].append(train_acc)\n",
        "    history['test_acc_history'].append(test_acc)\n",
        "    loss_history = history['loss_history']\n",
        "    if verbose: print(f'Epoch {epoch+1} / {epochs}: avg. loss of last epoch {total_loss}')\n",
        "    if verbose: print(f'avg. grad_norm of last epoch {total_grad_norm}')\n",
        "    if verbose: print(f'Current train acc: {train_acc}%, test acc: {test_acc}%')\n",
        "    \n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SSMG Train Function"
      ],
      "metadata": {
        "id": "pS-UgspvPhz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4xGM4WRTd58"
      },
      "outputs": [],
      "source": [
        "# This trainer trains the net using the SSMG algorithm proposed in the paper.\n",
        "# We named the variables identical with the paper's algorithm notation. Different from paper\n",
        "# the types we used are PyTorch tensors. Also, SSMG is single shuffle variant of SMG so batches wont \n",
        "# be reshuffled every epoch.\n",
        "def SSMG_train(model, criterion, epochs, train_loader, test_loader, scheduler, beta, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the dictionary of history that includes loss, grads, test and train accuracies.\n",
        "  \"\"\"\n",
        "  history = dict()\n",
        "  history['loss_history'], history['grad_history'] = list(), list()\n",
        "  history['test_acc_history'], history['train_acc_history'] = list(), list()\n",
        "  \n",
        "\n",
        "\n",
        "  m = dict()\n",
        "  # Initialize momentum dictionaries for weights with zeros.\n",
        "  for n, w in model.named_parameters():\n",
        "    m[n] = torch.zeros_like(w.data, memory_format = torch.preserve_format)\n",
        "\n",
        "\n",
        "\n",
        "  #Note that we have activated shuffling. When iterator advances to the end\n",
        "  #of the batches reshuffles. This is effectively shuffling the batch\n",
        "  #before every batch.\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_grad_norm = 0\n",
        "    lr = scheduler(epoch+1)\n",
        "  \n",
        "    for i, data in enumerate(train_loader, 0):    \n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      #There is no momentum update here. We want to preserve the momentum value of the\n",
        "      #previous epoch.\n",
        "\n",
        "      normalizer = labels.size(0) / len(train_loader.dataset)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "      total_loss += loss.item() * normalizer;\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Paper proposes an alternative scheme to update the weights using momentum with single batch shuffling. \n",
        "      for n, w in model.named_parameters():\n",
        "        with torch.no_grad():\n",
        "          g_scale = labels.size(0) / len(train_loader.dataset) #batch_size / dataset_size\n",
        "          #Update momentum in every iteration (Most important difference from SMG)\n",
        "          m[n] = beta * m[n] + (1-beta) * w.grad.data\n",
        "          w.data += -lr * m[n] #weight_update using the momentum directly\n",
        "\n",
        "\n",
        "\n",
        "      #Measure grad_square\n",
        "      for p in model.parameters():\n",
        "          param_norm = p.grad.detach().data.norm(2)\n",
        "          total_grad_norm += param_norm.item() ** 2 * normalizer\n",
        "      \n",
        "    \n",
        "    \n",
        "    history['grad_history'].append(total_grad_norm)\n",
        "    history['loss_history'].append(total_loss)\n",
        "    \n",
        "    train_acc, test_acc = train_and_test_accuracy(model, train_loader, test_loader)\n",
        "    history['train_acc_history'].append(train_acc)\n",
        "    history['test_acc_history'].append(test_acc)\n",
        "    loss_history = history['loss_history']\n",
        "    if verbose: print(f'Epoch {epoch+1} / {epochs}: avg. loss of last epoch {total_loss}')\n",
        "    if verbose: print(f'avg. grad_norm of last epoch {total_grad_norm}')\n",
        "    if verbose: print(f'Current train acc: {train_acc}%, test acc: {test_acc}%')\n",
        "    \n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Function for Other Optimizers"
      ],
      "metadata": {
        "id": "DaS7ZvMcPnDz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kmzxxKPcKN5"
      },
      "outputs": [],
      "source": [
        "# This is a general trainer that uses PyTorch's built-in optimizers.\n",
        "# This function will be used compare other optimizers with SMG\n",
        "def train(model, criterion, optimizer, epochs, train_loader, test_loader, scheduler, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the dictionary of history that includes loss, grads, test and train accuracies.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  history = dict()\n",
        "  history['loss_history'], history['grad_history'] = list(), list()\n",
        "  history['test_acc_history'], history['train_acc_history'] = list(), list()\n",
        "  #Note that we have activated shuffling. When iterator advances to the end\n",
        "  #of the batches reshuffles. This is effectively shuffling the batch\n",
        "  #before every batch.\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_grad_norm = 0\n",
        "    lr = scheduler(epoch+1)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr \n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):    \n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      normalizer = labels.size(0) / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "      total_loss += loss.item() * normalizer;\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      \n",
        "      #Measure grad_square\n",
        "      for p in model.parameters():\n",
        "          param_norm = p.grad.detach().data.norm(2)\n",
        "          total_grad_norm += param_norm.item() ** 2 * normalizer\n",
        "      \n",
        "\n",
        "    history['grad_history'].append(total_grad_norm)\n",
        "    history['loss_history'].append(total_loss)\n",
        "\n",
        "    train_acc, test_acc = train_and_test_accuracy(model, train_loader, test_loader)\n",
        "    history['train_acc_history'].append(train_acc)\n",
        "    history['test_acc_history'].append(test_acc)\n",
        "    loss_history = history['loss_history']\n",
        "    if verbose: print(f'Epoch {epoch+1} / {epochs}: avg. loss of last epoch {total_loss}')\n",
        "    if verbose: print(f'Epoch {epoch+1} / {epochs}: avg. grad_norm of last epoch {total_grad_norm}')\n",
        "    if verbose: print(f'Current train acc: {train_acc}%, test acc: {test_acc}%')  \n",
        "\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adNgUKsMgUfP"
      },
      "source": [
        "# Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkeBHzqmgZCP"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "#-------------------------(LeNet5 for Cifar10)-------------------------------\n",
        "class LeNet5 (nn.Module):\n",
        "    def __init__ (self):\n",
        "        super().__init__()\n",
        "\n",
        "        # This network is for images of size 32x32, with 3 color channels  (Cifar10 dataset)\n",
        "        self.conv1 = nn.Conv2d (3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d (2,2)\n",
        "        self.conv2 = nn.Conv2d (6, 16, 5)\n",
        "        self.fc1 = nn.Linear (16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear (120, 84)\n",
        "        self.fc3 = nn.Linear (84, 10)\n",
        "    \n",
        "    def forward (self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #Flatten before passing through the fc layers.\n",
        "        x = x.view(-1, 16* 5* 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#---------------(LeNet_300_100 for (Fashion) MNIST)-----------------------------\n",
        "class LeNet_300_100 (nn.Module):\n",
        "    def __init__ (self):\n",
        "        super().__init__()\n",
        "\n",
        "        # This network is for images of size 28x28, with 1 color channels \n",
        "        self.fc1 = nn.Linear (28* 28, 300)\n",
        "        self.fc2 = nn.Linear (300, 100)\n",
        "        self.fc3 = nn.Linear (100, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward (self, x):\n",
        "        #Flatten\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "#-------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJVbMu75iipV"
      },
      "source": [
        "# Get GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWGtfpOmkH6r",
        "outputId": "4298d2c1-3177-4611-f4a9-d85b13c1206d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda (GPU support) is available and enabled!\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8zNx_61i-zd"
      },
      "source": [
        "\n",
        "# Retrieve Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4lGWiJ-jWlA"
      },
      "source": [
        "-Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "baba8200128446eb8c8de1c46af5b601",
            "8d42a77b92e446139584c80f90905f5e",
            "7086157374414258aa605af32d91a144",
            "dc211171e56d4f68bfd2b396259a0135",
            "0166bc1ed3814b5cbac22d19212824fd",
            "806f16bad58b4e1b87252ebde54a339f",
            "eda1f7d73ee6427b817aecb293c5a3b4",
            "d9664d37767d47d896007f4c18cf2251",
            "29e9d00f16ec45a5a90c6aa7e1c4f8c1",
            "b920cbaf17c34dfa8764b6ad3601a794",
            "586fb1a3e5854706a72d847eb3b7c950"
          ]
        },
        "id": "00gyAEg5jCW7",
        "outputId": "51062745-d6ab-4d4b-a968-fb3ae813dab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baba8200128446eb8c8de1c46af5b601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_train_loader, cifar_test_loader = cifar10_loader(256, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUEfXJtMjYno"
      },
      "source": [
        "-Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "7c9025c173334de9a3a461f122d60469",
            "ba4b74560aab4fdbb84ae0edaa997e42",
            "3e3fb749a2d244b9935742d0e09f722a",
            "57dcef63a63e44a7a5eae363934269b1",
            "da78a3406b5246b3af72c0db9d75b8ba",
            "1b4be9afe692446b8302471476798784",
            "5053b4e60ca44465afea6b0cfcd22c44",
            "1269fae892f6472b99f79ab7401b3c6d",
            "bd1e73f96b7440b48ab414c750c90cb8",
            "d2cdc548298346c99b402be463b7bd9d",
            "9ff2a7d676ea48229f18a86db397351b",
            "1faaec9c51b3496bb0861321a6c385c1",
            "ce499b47beaa44c4b9136cd376b593f4",
            "dd472c69660b44aea8c6694cd934f31a",
            "6f10245b0b404934a44e1e73163753e5",
            "6c00908f37b7474c874f0b263fa8648f",
            "4458430668b040a0bb078ebecfabfbb7",
            "83328625bf9d480a8c169a71023cddb3",
            "57aa421bd57643d282f5b755cb847d1b",
            "e4f59186d1ea4366a2c0cd3b41ae70eb",
            "1ee8ab9fcba24c17aee2e014868125e6",
            "0ad831ebe6a64351ada239d4a2b030a4",
            "d141005b30c64596b118686eb461c55d",
            "78fc9c75521d4d2b82764ec01ca1fa65",
            "771a406c6088407f8c55c5c11e8f9ebd",
            "9ed0121747dc454b941b97cad73c9356",
            "a87d53fcc7094eb7bdc23eea3ce3b408",
            "72f5cf0606e442a4a709e916f701dbd8",
            "1afe2f54c0e3477e932e7e7c2ff50809",
            "69d22b375a574294a58a876aea4617a9",
            "eaf55fcff17b45d2907aa40768edaffb",
            "d058a7be54634e90b7400f09c46177a3",
            "ca2da4e25dd741c6b79fcb30aca020ef",
            "e442f6c9f8a04572bb068fc0c4d344ed",
            "34cc73abcbf04692a84cbcbac82c4525",
            "949b412c80d54d43b74dce81b213b5a4",
            "0c22ab15b6d84c8d8f778ebe6a108f1f",
            "13dc90490d874e44be4bc3f212a30e37",
            "8dd9b30c406845229f6d3ee2598fefa5",
            "839531b462204439965448be1f0b8c6f",
            "0b45be6936fe416b954120e63d5a4c2f",
            "811f3931e2e44131ba9c39f6af742c73",
            "89616fd9e49e4175bf302214286e02d7",
            "a8448180d8e84221adab466c8382f9ad"
          ]
        },
        "id": "VXefq22sjaV-",
        "outputId": "34a90d00-df40-4fd5-d9e7-eb6949fd80df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c9025c173334de9a3a461f122d60469"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1faaec9c51b3496bb0861321a6c385c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d141005b30c64596b118686eb461c55d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e442f6c9f8a04572bb068fc0c4d344ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "fashion_train_loader, fashion_test_loader = fashionmnist_loader(128, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYm5YiYZS7o_"
      },
      "source": [
        "# 1- Train and Plot Different Learning Schedulers over SMG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIySQZ_IiIbT"
      },
      "source": [
        "## SMG with Constant Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y6OhithTBWu",
        "outputId": "e59039ea-9d13-4886-e869-91a88943c671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.6661217845280965\n",
            "avg. grad_norm of last epoch 3.392758872083561\n",
            "Current train acc: 81.78166666666667%, test acc: 80.98%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.42256548759142537\n",
            "avg. grad_norm of last epoch 2.6710406523145287\n",
            "Current train acc: 86.64666666666666%, test acc: 85.36%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.3548604269504546\n",
            "avg. grad_norm of last epoch 1.7961944311298734\n",
            "Current train acc: 87.57333333333334%, test acc: 86.04%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.3181741418202717\n",
            "avg. grad_norm of last epoch 1.8628070763973246\n",
            "Current train acc: 88.57666666666667%, test acc: 86.5%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.29067653000354776\n",
            "avg. grad_norm of last epoch 1.6711818020718578\n",
            "Current train acc: 89.89%, test acc: 87.48%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.27248399482568125\n",
            "avg. grad_norm of last epoch 1.9624789570109649\n",
            "Current train acc: 89.69166666666666%, test acc: 87.28%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.2551148830890656\n",
            "avg. grad_norm of last epoch 1.8573255046036818\n",
            "Current train acc: 91.075%, test acc: 87.99%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.24248241984049482\n",
            "avg. grad_norm of last epoch 2.1282299921894485\n",
            "Current train acc: 91.86166666666666%, test acc: 88.66%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.22833362049261738\n",
            "avg. grad_norm of last epoch 2.062097907670683\n",
            "Current train acc: 92.38166666666666%, test acc: 88.87%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.21723898468812297\n",
            "avg. grad_norm of last epoch 2.274414390190416\n",
            "Current train acc: 92.56333333333333%, test acc: 88.8%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.20488703077634177\n",
            "avg. grad_norm of last epoch 2.1602863835446997\n",
            "Current train acc: 92.75833333333334%, test acc: 88.55%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.19581919410228735\n",
            "avg. grad_norm of last epoch 2.3830011430943827\n",
            "Current train acc: 92.78166666666667%, test acc: 88.43%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.1860783648252487\n",
            "avg. grad_norm of last epoch 2.3546157878816496\n",
            "Current train acc: 94.01833333333333%, test acc: 89.39%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.1780251774708431\n",
            "avg. grad_norm of last epoch 2.598825865311174\n",
            "Current train acc: 94.27833333333334%, test acc: 89.4%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.16919403593540203\n",
            "avg. grad_norm of last epoch 2.5751351498216515\n",
            "Current train acc: 94.04833333333333%, test acc: 88.58%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.1605473576704659\n",
            "avg. grad_norm of last epoch 2.69565448405514\n",
            "Current train acc: 94.615%, test acc: 89.42%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.15242309727668762\n",
            "avg. grad_norm of last epoch 2.6600249246868537\n",
            "Current train acc: 93.7%, test acc: 88.22%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.1454050253629683\n",
            "avg. grad_norm of last epoch 2.7989510995416116\n",
            "Current train acc: 94.37333333333333%, test acc: 88.25%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.1398696137110393\n",
            "avg. grad_norm of last epoch 2.840655532718304\n",
            "Current train acc: 95.30833333333334%, test acc: 89.15%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.13101805065472935\n",
            "avg. grad_norm of last epoch 2.8616156508453154\n",
            "Current train acc: 95.51166666666667%, test acc: 89.17%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.12580724595387768\n",
            "avg. grad_norm of last epoch 2.912098625653833\n",
            "Current train acc: 94.47666666666667%, test acc: 88.07%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.12108327172199891\n",
            "avg. grad_norm of last epoch 3.042407861644988\n",
            "Current train acc: 94.93166666666667%, test acc: 88.54%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.11304366815487542\n",
            "avg. grad_norm of last epoch 2.8560194520038853\n",
            "Current train acc: 95.45833333333333%, test acc: 88.86%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.1086096750100454\n",
            "avg. grad_norm of last epoch 3.108794644139613\n",
            "Current train acc: 95.87333333333333%, test acc: 88.94%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.10220594221353534\n",
            "avg. grad_norm of last epoch 2.891612246005305\n",
            "Current train acc: 96.45833333333333%, test acc: 89.04%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.09897889720201494\n",
            "avg. grad_norm of last epoch 3.014511958820097\n",
            "Current train acc: 96.23833333333333%, test acc: 88.97%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.09195738670229897\n",
            "avg. grad_norm of last epoch 2.89945782044081\n",
            "Current train acc: 96.84166666666667%, test acc: 89.03%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.08938567614356674\n",
            "avg. grad_norm of last epoch 3.0441423721933254\n",
            "Current train acc: 97.18666666666667%, test acc: 89.24%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.08278944544394809\n",
            "avg. grad_norm of last epoch 2.777554010517853\n",
            "Current train acc: 95.74666666666667%, test acc: 88.58%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.08347635823488235\n",
            "avg. grad_norm of last epoch 3.264868083326351\n",
            "Current train acc: 97.21166666666667%, test acc: 89.18%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.07631191763480509\n",
            "avg. grad_norm of last epoch 2.931766256605572\n",
            "Current train acc: 97.44333333333333%, test acc: 89.3%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.0746898441433907\n",
            "avg. grad_norm of last epoch 3.0392999994453485\n",
            "Current train acc: 97.63333333333334%, test acc: 89.37%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.06947861552437144\n",
            "avg. grad_norm of last epoch 2.864836165052486\n",
            "Current train acc: 96.67833333333333%, test acc: 88.26%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.06813555255929636\n",
            "avg. grad_norm of last epoch 3.019078609385538\n",
            "Current train acc: 97.98%, test acc: 89.12%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.06185344389478367\n",
            "avg. grad_norm of last epoch 2.608054404135344\n",
            "Current train acc: 96.02166666666666%, test acc: 87.65%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.060324503590663256\n",
            "avg. grad_norm of last epoch 2.850996226395189\n",
            "Current train acc: 97.70166666666667%, test acc: 88.91%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.059497502651810634\n",
            "avg. grad_norm of last epoch 2.9117633450182\n",
            "Current train acc: 98.08333333333333%, test acc: 88.98%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.055392570215463635\n",
            "avg. grad_norm of last epoch 2.78220280342344\n",
            "Current train acc: 98.31%, test acc: 88.92%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.0548116546551387\n",
            "avg. grad_norm of last epoch 2.8502670326535697\n",
            "Current train acc: 97.65%, test acc: 89.06%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.05113768183986344\n",
            "avg. grad_norm of last epoch 2.704248248086546\n",
            "Current train acc: 98.12666666666667%, test acc: 89.06%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.04599661776721478\n",
            "avg. grad_norm of last epoch 2.358514877054206\n",
            "Current train acc: 98.66333333333333%, test acc: 89.51%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.046791326598326355\n",
            "avg. grad_norm of last epoch 2.6110798920863068\n",
            "Current train acc: 97.64%, test acc: 88.31%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.0436234277755022\n",
            "avg. grad_norm of last epoch 2.509962365889149\n",
            "Current train acc: 98.745%, test acc: 89.24%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.04061454813679059\n",
            "avg. grad_norm of last epoch 2.324526790110946\n",
            "Current train acc: 98.50333333333333%, test acc: 89.0%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.03797204322318234\n",
            "avg. grad_norm of last epoch 2.1992856048902696\n",
            "Current train acc: 98.75166666666667%, test acc: 89.13%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.03842867091099418\n",
            "avg. grad_norm of last epoch 2.4778685743684026\n",
            "Current train acc: 98.96166666666667%, test acc: 89.26%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.034474282605946045\n",
            "avg. grad_norm of last epoch 2.1560339622192957\n",
            "Current train acc: 97.775%, test acc: 88.08%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.0357981588572264\n",
            "avg. grad_norm of last epoch 2.3992578664163586\n",
            "Current train acc: 99.07666666666667%, test acc: 89.11%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.03293050590207181\n",
            "avg. grad_norm of last epoch 2.157260691010711\n",
            "Current train acc: 98.86666666666666%, test acc: 89.3%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.030046990969280422\n",
            "avg. grad_norm of last epoch 2.0538163591765364\n",
            "Current train acc: 99.31333333333333%, test acc: 89.42%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.029880717246731105\n",
            "avg. grad_norm of last epoch 2.0730797844793836\n",
            "Current train acc: 98.895%, test acc: 88.96%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.029115520742038874\n",
            "avg. grad_norm of last epoch 2.0955698157646316\n",
            "Current train acc: 98.99666666666667%, test acc: 89.65%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.027210278497139605\n",
            "avg. grad_norm of last epoch 1.9484805031777068\n",
            "Current train acc: 99.00666666666666%, test acc: 88.77%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.02553171536177396\n",
            "avg. grad_norm of last epoch 1.9615056951096888\n",
            "Current train acc: 99.16166666666666%, test acc: 89.5%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.02247125659137963\n",
            "avg. grad_norm of last epoch 1.6042154089135299\n",
            "Current train acc: 99.41333333333333%, test acc: 89.2%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.024387898329148686\n",
            "avg. grad_norm of last epoch 1.9876944348451415\n",
            "Current train acc: 98.84666666666666%, test acc: 89.08%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.018227564819405472\n",
            "avg. grad_norm of last epoch 1.253054677763725\n",
            "Current train acc: 99.47%, test acc: 89.36%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.0186422359533608\n",
            "avg. grad_norm of last epoch 1.4429515378210402\n",
            "Current train acc: 98.835%, test acc: 88.92%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.019472827262928077\n",
            "avg. grad_norm of last epoch 1.5737911510019085\n",
            "Current train acc: 98.79%, test acc: 89.06%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.016794387479374798\n",
            "avg. grad_norm of last epoch 1.325818353737707\n",
            "Current train acc: 99.64333333333333%, test acc: 89.38%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.020527397066106387\n",
            "avg. grad_norm of last epoch 1.84355601877987\n",
            "Current train acc: 99.48166666666667%, test acc: 89.3%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.014908614864945428\n",
            "avg. grad_norm of last epoch 1.195477884320921\n",
            "Current train acc: 99.535%, test acc: 89.16%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.015166078021377325\n",
            "avg. grad_norm of last epoch 1.3168796589100187\n",
            "Current train acc: 99.63833333333334%, test acc: 89.44%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.02084909155070783\n",
            "avg. grad_norm of last epoch 2.2217154831952057\n",
            "Current train acc: 99.05333333333333%, test acc: 88.84%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.016825276838491367\n",
            "avg. grad_norm of last epoch 1.457573302286033\n",
            "Current train acc: 99.61666666666666%, test acc: 89.18%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.0151452763694028\n",
            "avg. grad_norm of last epoch 1.402576744214212\n",
            "Current train acc: 99.05833333333334%, test acc: 89.25%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.020618175380428642\n",
            "avg. grad_norm of last epoch 2.102736135908575\n",
            "Current train acc: 99.215%, test acc: 88.75%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.018963033629457133\n",
            "avg. grad_norm of last epoch 1.8893291985333138\n",
            "Current train acc: 99.38833333333334%, test acc: 88.96%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.01934405737767618\n",
            "avg. grad_norm of last epoch 1.985359368877245\n",
            "Current train acc: 98.69333333333333%, test acc: 88.47%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.01711516618629296\n",
            "avg. grad_norm of last epoch 1.5945681629695063\n",
            "Current train acc: 99.33833333333334%, test acc: 88.89%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.01678466225725911\n",
            "avg. grad_norm of last epoch 1.6767475233610254\n",
            "Current train acc: 99.47333333333333%, test acc: 89.09%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.015087676138430844\n",
            "avg. grad_norm of last epoch 1.5276142201426102\n",
            "Current train acc: 98.98833333333333%, test acc: 89.18%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.011825658907492957\n",
            "avg. grad_norm of last epoch 1.149764848200687\n",
            "Current train acc: 99.70333333333333%, test acc: 89.28%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.011472700353463493\n",
            "avg. grad_norm of last epoch 1.188796704719541\n",
            "Current train acc: 99.70666666666666%, test acc: 88.93%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.01051748265819624\n",
            "avg. grad_norm of last epoch 1.0741624917030823\n",
            "Current train acc: 99.065%, test acc: 88.87%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.011772707553269956\n",
            "avg. grad_norm of last epoch 1.1964273506095087\n",
            "Current train acc: 99.765%, test acc: 88.97%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.01951053969611724\n",
            "avg. grad_norm of last epoch 2.259985493640817\n",
            "Current train acc: 99.73166666666667%, test acc: 89.13%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.009600515322138877\n",
            "avg. grad_norm of last epoch 0.9800951722662399\n",
            "Current train acc: 99.625%, test acc: 88.96%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.009713373135030267\n",
            "avg. grad_norm of last epoch 1.0116128790214165\n",
            "Current train acc: 99.74833333333333%, test acc: 89.29%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.012808058259077373\n",
            "avg. grad_norm of last epoch 1.382819647507943\n",
            "Current train acc: 99.86666666666666%, test acc: 89.12%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.0075621946066618045\n",
            "avg. grad_norm of last epoch 0.6951676671599972\n",
            "Current train acc: 99.83833333333334%, test acc: 89.13%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.006413432084148135\n",
            "avg. grad_norm of last epoch 0.5948945809000148\n",
            "Current train acc: 99.885%, test acc: 89.26%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.005427147779862084\n",
            "avg. grad_norm of last epoch 0.47062196130743006\n",
            "Current train acc: 99.61833333333334%, test acc: 88.9%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.004036808329758548\n",
            "avg. grad_norm of last epoch 0.3194709097296677\n",
            "Current train acc: 99.95333333333333%, test acc: 89.46%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.003332971191514902\n",
            "avg. grad_norm of last epoch 0.2358570739600542\n",
            "Current train acc: 99.98333333333333%, test acc: 89.38%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.0022945672375150016\n",
            "avg. grad_norm of last epoch 0.12350869218278246\n",
            "Current train acc: 99.97666666666667%, test acc: 89.36%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.0019434047777516152\n",
            "avg. grad_norm of last epoch 0.09732103095177981\n",
            "Current train acc: 99.995%, test acc: 89.43%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.0015054048062612614\n",
            "avg. grad_norm of last epoch 0.058271366198796914\n",
            "Current train acc: 99.98833333333333%, test acc: 89.47%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.001121498767410716\n",
            "avg. grad_norm of last epoch 0.028219372842393047\n",
            "Current train acc: 99.99666666666667%, test acc: 89.45%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.0009192848688146725\n",
            "avg. grad_norm of last epoch 0.019230927144743188\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.0007861469796393067\n",
            "avg. grad_norm of last epoch 0.013845276931701943\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.0007044043344911196\n",
            "avg. grad_norm of last epoch 0.011101484641817908\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.0006556544934865089\n",
            "avg. grad_norm of last epoch 0.012455566756480825\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.0005740953455989561\n",
            "avg. grad_norm of last epoch 0.006343361797018894\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.00054166980132771\n",
            "avg. grad_norm of last epoch 0.0073974505268804835\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.000520859855925664\n",
            "avg. grad_norm of last epoch 0.005997108375479117\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.00048626016052439805\n",
            "avg. grad_norm of last epoch 0.004608145755407783\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.0004546080510132017\n",
            "avg. grad_norm of last epoch 0.003492618754717934\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.0004403320798805604\n",
            "avg. grad_norm of last epoch 0.0037498352696490275\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.000417711847803245\n",
            "avg. grad_norm of last epoch 0.0029834445547469875\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.000406297189136967\n",
            "avg. grad_norm of last epoch 0.002760866066076649\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.00038442553730371105\n",
            "avg. grad_norm of last epoch 0.0022954917015837045\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.00037120548076539645\n",
            "avg. grad_norm of last epoch 0.0020874565952177138\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.00035792322610504924\n",
            "avg. grad_norm of last epoch 0.001819614591057302\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.0003488515392683135\n",
            "avg. grad_norm of last epoch 0.0016813404885212967\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.0003372956569927435\n",
            "avg. grad_norm of last epoch 0.0016064213240487965\n",
            "Current train acc: 100.0%, test acc: 89.44%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.00032896691358958694\n",
            "avg. grad_norm of last epoch 0.0014417183857869812\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.0003238883288810031\n",
            "avg. grad_norm of last epoch 0.0016964327067006523\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.00031203474209954315\n",
            "avg. grad_norm of last epoch 0.0012816717013779946\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.0003068217626229549\n",
            "avg. grad_norm of last epoch 0.0013416778514370232\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.0002992106863142303\n",
            "avg. grad_norm of last epoch 0.0011654985649628114\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.00029504177413570385\n",
            "avg. grad_norm of last epoch 0.0012599469989686717\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.0002878623543113162\n",
            "avg. grad_norm of last epoch 0.0010430074775465317\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.0002815324497409164\n",
            "avg. grad_norm of last epoch 0.0010481360966364112\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.00027557463040187334\n",
            "avg. grad_norm of last epoch 0.00098913238406323\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.0002712983765096092\n",
            "avg. grad_norm of last epoch 0.0009846791396046475\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.0002647668327748155\n",
            "avg. grad_norm of last epoch 0.0009216112718928438\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.00026125453393906336\n",
            "avg. grad_norm of last epoch 0.0008502870394815396\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.00025714319263740146\n",
            "avg. grad_norm of last epoch 0.0008315709693990426\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.00025273015270164853\n",
            "avg. grad_norm of last epoch 0.0008409093527568582\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.00024857501295239963\n",
            "avg. grad_norm of last epoch 0.0008013232142246532\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.0002433983431197703\n",
            "avg. grad_norm of last epoch 0.0007532975980566729\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.00024242303357459617\n",
            "avg. grad_norm of last epoch 0.0008196514195973061\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 124 / 200: avg. loss of last epoch 0.00023631297316945463\n",
            "avg. grad_norm of last epoch 0.0007082542584398857\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 125 / 200: avg. loss of last epoch 0.0002334526511995741\n",
            "avg. grad_norm of last epoch 0.0007148267249406394\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 126 / 200: avg. loss of last epoch 0.0002291421849746258\n",
            "avg. grad_norm of last epoch 0.0006654480267541013\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 127 / 200: avg. loss of last epoch 0.00022558115080464645\n",
            "avg. grad_norm of last epoch 0.0006511420543984502\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 128 / 200: avg. loss of last epoch 0.00022178595223619276\n",
            "avg. grad_norm of last epoch 0.0006062575311353559\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 129 / 200: avg. loss of last epoch 0.0002194072212403019\n",
            "avg. grad_norm of last epoch 0.0006517470274566433\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 130 / 200: avg. loss of last epoch 0.00021644750396565852\n",
            "avg. grad_norm of last epoch 0.0005775142942511418\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 131 / 200: avg. loss of last epoch 0.0002125833562885721\n",
            "avg. grad_norm of last epoch 0.0005908748869166822\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 132 / 200: avg. loss of last epoch 0.0002107268549579504\n",
            "avg. grad_norm of last epoch 0.0005768987869174243\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 133 / 200: avg. loss of last epoch 0.00020783090080755455\n",
            "avg. grad_norm of last epoch 0.0005423728025800289\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 134 / 200: avg. loss of last epoch 0.00020541973412036913\n",
            "avg. grad_norm of last epoch 0.0005452159786267281\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 135 / 200: avg. loss of last epoch 0.00020218454866359638\n",
            "avg. grad_norm of last epoch 0.0005330907773113144\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 136 / 200: avg. loss of last epoch 0.00019797242613664518\n",
            "avg. grad_norm of last epoch 0.00047612943569915546\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 137 / 200: avg. loss of last epoch 0.00019679663422672705\n",
            "avg. grad_norm of last epoch 0.0004893878126694454\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 138 / 200: avg. loss of last epoch 0.00019365801755338917\n",
            "avg. grad_norm of last epoch 0.0004666120362118559\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 139 / 200: avg. loss of last epoch 0.0001921839213464411\n",
            "avg. grad_norm of last epoch 0.00047741429641134746\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 140 / 200: avg. loss of last epoch 0.00018875904446855803\n",
            "avg. grad_norm of last epoch 0.00044095948229304116\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 141 / 200: avg. loss of last epoch 0.00018678413766901928\n",
            "avg. grad_norm of last epoch 0.0004421982857797372\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 142 / 200: avg. loss of last epoch 0.00018517070636153222\n",
            "avg. grad_norm of last epoch 0.00043778354785778444\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 143 / 200: avg. loss of last epoch 0.00018288216503181806\n",
            "avg. grad_norm of last epoch 0.00042763872737640784\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 144 / 200: avg. loss of last epoch 0.00018037518664107966\n",
            "avg. grad_norm of last epoch 0.00040476563903259536\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 145 / 200: avg. loss of last epoch 0.00017911426374145488\n",
            "avg. grad_norm of last epoch 0.00042801106653748603\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 146 / 200: avg. loss of last epoch 0.00017719583156673862\n",
            "avg. grad_norm of last epoch 0.0003886040342715972\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 147 / 200: avg. loss of last epoch 0.0001744981882123587\n",
            "avg. grad_norm of last epoch 0.0003923747104874904\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 148 / 200: avg. loss of last epoch 0.0001728643888452401\n",
            "avg. grad_norm of last epoch 0.0003798720146919039\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 149 / 200: avg. loss of last epoch 0.00017045876501748958\n",
            "avg. grad_norm of last epoch 0.00037135770810067293\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 150 / 200: avg. loss of last epoch 0.0001684058689395896\n",
            "avg. grad_norm of last epoch 0.00035309206478630463\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 151 / 200: avg. loss of last epoch 0.00016723151199209187\n",
            "avg. grad_norm of last epoch 0.00035600869921206476\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 152 / 200: avg. loss of last epoch 0.0001655141601571814\n",
            "avg. grad_norm of last epoch 0.00036638322034883046\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 153 / 200: avg. loss of last epoch 0.00016338279426175462\n",
            "avg. grad_norm of last epoch 0.0003354649069745518\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 154 / 200: avg. loss of last epoch 0.00016181679348616575\n",
            "avg. grad_norm of last epoch 0.0003313807058247399\n",
            "Current train acc: 100.0%, test acc: 89.39%\n",
            "Epoch 155 / 200: avg. loss of last epoch 0.00016035324676971275\n",
            "avg. grad_norm of last epoch 0.0003264055157062004\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 156 / 200: avg. loss of last epoch 0.00015878569974253593\n",
            "avg. grad_norm of last epoch 0.0003233068033176314\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 157 / 200: avg. loss of last epoch 0.00015637480011791905\n",
            "avg. grad_norm of last epoch 0.00029611794125774285\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 158 / 200: avg. loss of last epoch 0.0001553738784704669\n",
            "avg. grad_norm of last epoch 0.00031396637300502893\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 159 / 200: avg. loss of last epoch 0.00015376296173005052\n",
            "avg. grad_norm of last epoch 0.0003043696088508711\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 160 / 200: avg. loss of last epoch 0.0001524913837357114\n",
            "avg. grad_norm of last epoch 0.00029030784927911384\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 161 / 200: avg. loss of last epoch 0.00015042519129735096\n",
            "avg. grad_norm of last epoch 0.0002854609346874734\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 162 / 200: avg. loss of last epoch 0.00014951582728341847\n",
            "avg. grad_norm of last epoch 0.00028714877429384164\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 163 / 200: avg. loss of last epoch 0.00014828738356785227\n",
            "avg. grad_norm of last epoch 0.0002825199921105848\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 164 / 200: avg. loss of last epoch 0.00014646583630237734\n",
            "avg. grad_norm of last epoch 0.00027082738129289663\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 165 / 200: avg. loss of last epoch 0.00014551468950230634\n",
            "avg. grad_norm of last epoch 0.0002778224145148178\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 166 / 200: avg. loss of last epoch 0.00014424418973115589\n",
            "avg. grad_norm of last epoch 0.0002580484894075425\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 167 / 200: avg. loss of last epoch 0.00014261774867385\n",
            "avg. grad_norm of last epoch 0.00026630791190257144\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 168 / 200: avg. loss of last epoch 0.00014123088611910737\n",
            "avg. grad_norm of last epoch 0.0002470316747523849\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 169 / 200: avg. loss of last epoch 0.0001401929380527386\n",
            "avg. grad_norm of last epoch 0.0002551609659750105\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 170 / 200: avg. loss of last epoch 0.00013911528060367952\n",
            "avg. grad_norm of last epoch 0.00024686943954315164\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 171 / 200: avg. loss of last epoch 0.0001379203101464858\n",
            "avg. grad_norm of last epoch 0.00024447501636095737\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 172 / 200: avg. loss of last epoch 0.00013629603184526796\n",
            "avg. grad_norm of last epoch 0.0002405906183298703\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 173 / 200: avg. loss of last epoch 0.00013543914035350695\n",
            "avg. grad_norm of last epoch 0.0002334353797383401\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 174 / 200: avg. loss of last epoch 0.00013391961232409825\n",
            "avg. grad_norm of last epoch 0.00022321951275864265\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 175 / 200: avg. loss of last epoch 0.00013333365635092692\n",
            "avg. grad_norm of last epoch 0.00022887228370104202\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 176 / 200: avg. loss of last epoch 0.0001316744486025225\n",
            "avg. grad_norm of last epoch 0.00022305694444577654\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 177 / 200: avg. loss of last epoch 0.00013049423162592568\n",
            "avg. grad_norm of last epoch 0.00021339142282133182\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 178 / 200: avg. loss of last epoch 0.00012973443945714591\n",
            "avg. grad_norm of last epoch 0.0002117495867393428\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 179 / 200: avg. loss of last epoch 0.000128266614380603\n",
            "avg. grad_norm of last epoch 0.00020737188025604235\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 180 / 200: avg. loss of last epoch 0.00012748635397292663\n",
            "avg. grad_norm of last epoch 0.00020710946136187687\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 181 / 200: avg. loss of last epoch 0.00012628889954648917\n",
            "avg. grad_norm of last epoch 0.0002011404911528549\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 182 / 200: avg. loss of last epoch 0.00012545896543888374\n",
            "avg. grad_norm of last epoch 0.00019875287707716633\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 183 / 200: avg. loss of last epoch 0.00012449895585499082\n",
            "avg. grad_norm of last epoch 0.0002012176548827994\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 184 / 200: avg. loss of last epoch 0.0001234471594332717\n",
            "avg. grad_norm of last epoch 0.00019381159719154392\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 185 / 200: avg. loss of last epoch 0.00012270467246805009\n",
            "avg. grad_norm of last epoch 0.0001901180899065224\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 186 / 200: avg. loss of last epoch 0.00012138948758171556\n",
            "avg. grad_norm of last epoch 0.00018646232584028515\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 187 / 200: avg. loss of last epoch 0.00012027364115541185\n",
            "avg. grad_norm of last epoch 0.00018456454699225647\n",
            "Current train acc: 100.0%, test acc: 89.44%\n",
            "Epoch 188 / 200: avg. loss of last epoch 0.00011964675593383927\n",
            "avg. grad_norm of last epoch 0.00018009844276969546\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 189 / 200: avg. loss of last epoch 0.00011899053396579496\n",
            "avg. grad_norm of last epoch 0.00018556518841310706\n",
            "Current train acc: 100.0%, test acc: 89.44%\n",
            "Epoch 190 / 200: avg. loss of last epoch 0.00011800510131288307\n",
            "avg. grad_norm of last epoch 0.00017864151392532683\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 191 / 200: avg. loss of last epoch 0.00011661621597595505\n",
            "avg. grad_norm of last epoch 0.00017169631542836774\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 192 / 200: avg. loss of last epoch 0.00011603037759196006\n",
            "avg. grad_norm of last epoch 0.00017263409513382734\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 193 / 200: avg. loss of last epoch 0.00011520273329612495\n",
            "avg. grad_norm of last epoch 0.00017196200049749991\n",
            "Current train acc: 100.0%, test acc: 89.43%\n",
            "Epoch 194 / 200: avg. loss of last epoch 0.00011465563692230112\n",
            "avg. grad_norm of last epoch 0.00016930395381410408\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 195 / 200: avg. loss of last epoch 0.00011315843287156896\n",
            "avg. grad_norm of last epoch 0.00015927933746650826\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 196 / 200: avg. loss of last epoch 0.00011264413100628484\n",
            "avg. grad_norm of last epoch 0.0001615662269392645\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 197 / 200: avg. loss of last epoch 0.00011209983914159234\n",
            "avg. grad_norm of last epoch 0.00016397585009939877\n",
            "Current train acc: 100.0%, test acc: 89.45%\n",
            "Epoch 198 / 200: avg. loss of last epoch 0.00011115505786146967\n",
            "avg. grad_norm of last epoch 0.00015841358491107012\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 199 / 200: avg. loss of last epoch 0.00011013004757696769\n",
            "avg. grad_norm of last epoch 0.00015038818461365918\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 200 / 200: avg. loss of last epoch 0.00010968183982962126\n",
            "avg. grad_norm of last epoch 0.00015511266700208415\n",
            "Current train acc: 100.0%, test acc: 89.45%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epoch_count = 200\n",
        "\n",
        "\n",
        "scheduler = constant_learning_rate_scheduler(0.1)\n",
        "\n",
        "# beta is proposed in paper and epoch_count is inferenced from the graphs\n",
        "history = SMG_train(model, criterion, epoch_count, fashion_train_loader, fashion_test_loader, \n",
        "                    scheduler, beta=0.5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHZMGaTtANnM"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/SMG-Fashion-History/SMG_constantLR.json\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "xXv_SJ_3B1yf",
        "outputId": "59b906a9-0615-44aa-e3cd-fe75c6e94f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jInRr6VKiOgS"
      },
      "source": [
        "## SMG with Diminishing Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Z3-siOiRVg",
        "outputId": "71f3c9c5-d9d9-422f-9b86-93fa185b49da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.5894082794348398\n",
            "avg. grad_norm of last epoch 2.3874413855381813\n",
            "Current train acc: 84.73666666666666%, test acc: 83.11%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.3776697783946996\n",
            "avg. grad_norm of last epoch 1.5184543741233723\n",
            "Current train acc: 87.61333333333333%, test acc: 85.9%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.3194019393761953\n",
            "avg. grad_norm of last epoch 1.2073727563911911\n",
            "Current train acc: 87.55333333333333%, test acc: 85.38%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.28482826221783974\n",
            "avg. grad_norm of last epoch 1.2577542319134813\n",
            "Current train acc: 88.22166666666666%, test acc: 85.97%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.25837258192698137\n",
            "avg. grad_norm of last epoch 1.201577858403576\n",
            "Current train acc: 91.21666666666667%, test acc: 87.97%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.23959880392551416\n",
            "avg. grad_norm of last epoch 1.2593490437158128\n",
            "Current train acc: 91.26166666666667%, test acc: 87.55%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.22115943868955004\n",
            "avg. grad_norm of last epoch 1.2736456282677127\n",
            "Current train acc: 92.37666666666667%, test acc: 88.46%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.20770981295903534\n",
            "avg. grad_norm of last epoch 1.3572836829551564\n",
            "Current train acc: 92.375%, test acc: 88.36%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.1955285380442938\n",
            "avg. grad_norm of last epoch 1.4396138431114667\n",
            "Current train acc: 92.93833333333333%, test acc: 88.59%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.1843005987485249\n",
            "avg. grad_norm of last epoch 1.5107726192359165\n",
            "Current train acc: 93.545%, test acc: 89.11%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.17209090928236653\n",
            "avg. grad_norm of last epoch 1.5253219093574701\n",
            "Current train acc: 93.46333333333334%, test acc: 88.35%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.1617827860116958\n",
            "avg. grad_norm of last epoch 1.5982698959140424\n",
            "Current train acc: 94.47166666666666%, test acc: 89.04%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.15186575036048894\n",
            "avg. grad_norm of last epoch 1.6057751409400591\n",
            "Current train acc: 94.81%, test acc: 89.15%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.1425959270358087\n",
            "avg. grad_norm of last epoch 1.7180751332384816\n",
            "Current train acc: 95.19%, test acc: 89.19%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.13480031562646239\n",
            "avg. grad_norm of last epoch 1.7107886318068004\n",
            "Current train acc: 94.975%, test acc: 88.65%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.12845110088984166\n",
            "avg. grad_norm of last epoch 1.8635462826971394\n",
            "Current train acc: 95.17833333333333%, test acc: 88.81%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.11965055728356057\n",
            "avg. grad_norm of last epoch 1.8280957244116942\n",
            "Current train acc: 95.635%, test acc: 88.99%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.11176247952381771\n",
            "avg. grad_norm of last epoch 1.756673880660247\n",
            "Current train acc: 95.565%, test acc: 88.48%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.10492894834677387\n",
            "avg. grad_norm of last epoch 1.7851373576888836\n",
            "Current train acc: 95.435%, test acc: 88.33%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.09939538813233371\n",
            "avg. grad_norm of last epoch 1.8718974767206755\n",
            "Current train acc: 96.805%, test acc: 89.26%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.0931252509355546\n",
            "avg. grad_norm of last epoch 1.752641119857243\n",
            "Current train acc: 96.92166666666667%, test acc: 89.44%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.08850445092121761\n",
            "avg. grad_norm of last epoch 1.8892097469138176\n",
            "Current train acc: 94.34666666666666%, test acc: 87.47%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.08539172283013667\n",
            "avg. grad_norm of last epoch 1.9201103430862927\n",
            "Current train acc: 96.69%, test acc: 88.61%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.07923009750843053\n",
            "avg. grad_norm of last epoch 1.9346622674172511\n",
            "Current train acc: 97.66166666666666%, test acc: 89.57%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.07426807184418052\n",
            "avg. grad_norm of last epoch 1.8586790149101342\n",
            "Current train acc: 97.55%, test acc: 89.05%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.06993126254876454\n",
            "avg. grad_norm of last epoch 1.8318428863050435\n",
            "Current train acc: 97.60166666666667%, test acc: 89.1%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.06712371212840078\n",
            "avg. grad_norm of last epoch 1.8890140544176623\n",
            "Current train acc: 96.93666666666667%, test acc: 88.75%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.06248754277030623\n",
            "avg. grad_norm of last epoch 1.770371085681559\n",
            "Current train acc: 98.16166666666666%, test acc: 89.33%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.05998458837072053\n",
            "avg. grad_norm of last epoch 1.910152152858995\n",
            "Current train acc: 97.545%, test acc: 88.69%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.05508721463084225\n",
            "avg. grad_norm of last epoch 1.6420916982991578\n",
            "Current train acc: 98.56%, test acc: 89.29%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.05257606143156685\n",
            "avg. grad_norm of last epoch 1.7478258155694997\n",
            "Current train acc: 98.12333333333333%, test acc: 89.12%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.047553150909145664\n",
            "avg. grad_norm of last epoch 1.6081433688767555\n",
            "Current train acc: 98.48%, test acc: 89.07%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.046104121127724676\n",
            "avg. grad_norm of last epoch 1.711846651380602\n",
            "Current train acc: 97.94166666666666%, test acc: 88.92%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.04210732908348239\n",
            "avg. grad_norm of last epoch 1.5070718092756743\n",
            "Current train acc: 98.61833333333334%, test acc: 89.01%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.04058921534617742\n",
            "avg. grad_norm of last epoch 1.5629893435370383\n",
            "Current train acc: 98.41166666666666%, test acc: 88.99%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.03761081149280075\n",
            "avg. grad_norm of last epoch 1.4762790449440477\n",
            "Current train acc: 98.565%, test acc: 88.91%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.03629286195735135\n",
            "avg. grad_norm of last epoch 1.5204127321163627\n",
            "Current train acc: 98.58833333333334%, test acc: 88.87%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.03289450179487468\n",
            "avg. grad_norm of last epoch 1.3752708169870183\n",
            "Current train acc: 99.01166666666667%, test acc: 89.33%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.03179537306229273\n",
            "avg. grad_norm of last epoch 1.4301175693169412\n",
            "Current train acc: 99.04166666666667%, test acc: 89.0%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.027477612215280528\n",
            "avg. grad_norm of last epoch 1.2281448585121617\n",
            "Current train acc: 99.05666666666667%, test acc: 89.15%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.02862933983753123\n",
            "avg. grad_norm of last epoch 1.4103903249859864\n",
            "Current train acc: 98.73333333333333%, test acc: 88.94%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.02353962080329658\n",
            "avg. grad_norm of last epoch 1.1064670433845563\n",
            "Current train acc: 99.09166666666667%, test acc: 89.21%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.022512321777641765\n",
            "avg. grad_norm of last epoch 1.1918990649306231\n",
            "Current train acc: 98.655%, test acc: 89.18%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.022965801557401813\n",
            "avg. grad_norm of last epoch 1.2147195875884103\n",
            "Current train acc: 99.44%, test acc: 89.14%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.02182785667876401\n",
            "avg. grad_norm of last epoch 1.2304133810740223\n",
            "Current train acc: 98.625%, test acc: 89.08%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.020133498018731665\n",
            "avg. grad_norm of last epoch 1.1341590446340828\n",
            "Current train acc: 99.22166666666666%, test acc: 88.93%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.021132237367331986\n",
            "avg. grad_norm of last epoch 1.2935373953766918\n",
            "Current train acc: 98.87333333333333%, test acc: 89.0%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.018582161515454453\n",
            "avg. grad_norm of last epoch 1.0411784063694336\n",
            "Current train acc: 99.295%, test acc: 89.08%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.01666725818465154\n",
            "avg. grad_norm of last epoch 1.00192362426315\n",
            "Current train acc: 99.4%, test acc: 89.24%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.015654201791683833\n",
            "avg. grad_norm of last epoch 0.9062518370487214\n",
            "Current train acc: 99.445%, test acc: 89.4%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.014571762922716629\n",
            "avg. grad_norm of last epoch 0.8666716935438026\n",
            "Current train acc: 99.81%, test acc: 89.37%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.012743186299999563\n",
            "avg. grad_norm of last epoch 0.7943486024129872\n",
            "Current train acc: 99.32666666666667%, test acc: 89.43%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.011612132061148679\n",
            "avg. grad_norm of last epoch 0.7073649026194344\n",
            "Current train acc: 99.79833333333333%, test acc: 89.36%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.010943139210467539\n",
            "avg. grad_norm of last epoch 0.6783341084145783\n",
            "Current train acc: 99.87333333333333%, test acc: 89.36%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.0086442306876493\n",
            "avg. grad_norm of last epoch 0.4964283012919567\n",
            "Current train acc: 99.80666666666667%, test acc: 89.45%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.0077968976871420894\n",
            "avg. grad_norm of last epoch 0.4858192769480711\n",
            "Current train acc: 99.82%, test acc: 89.24%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.006639525892337159\n",
            "avg. grad_norm of last epoch 0.38933207594363173\n",
            "Current train acc: 99.19833333333334%, test acc: 89.19%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.006710085653762021\n",
            "avg. grad_norm of last epoch 0.41399543477306017\n",
            "Current train acc: 99.85%, test acc: 89.25%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.0059539173460875965\n",
            "avg. grad_norm of last epoch 0.3722355976977829\n",
            "Current train acc: 99.79%, test acc: 89.08%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.00538623787804197\n",
            "avg. grad_norm of last epoch 0.3413839176483373\n",
            "Current train acc: 99.84333333333333%, test acc: 89.34%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.004250585526290041\n",
            "avg. grad_norm of last epoch 0.23184175369004803\n",
            "Current train acc: 99.88%, test acc: 89.48%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.0050192132469577076\n",
            "avg. grad_norm of last epoch 0.3460855184706721\n",
            "Current train acc: 99.96333333333334%, test acc: 89.31%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.003699339534901081\n",
            "avg. grad_norm of last epoch 0.18972573855143768\n",
            "Current train acc: 99.94666666666667%, test acc: 89.37%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.0029425017154154688\n",
            "avg. grad_norm of last epoch 0.13770232859621073\n",
            "Current train acc: 99.96833333333333%, test acc: 89.35%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.0040793734104683\n",
            "avg. grad_norm of last epoch 0.32491357880628485\n",
            "Current train acc: 99.8%, test acc: 89.4%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.0038574980394293855\n",
            "avg. grad_norm of last epoch 0.2371355651280938\n",
            "Current train acc: 99.98333333333333%, test acc: 89.17%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.0023989286570809776\n",
            "avg. grad_norm of last epoch 0.1054510828504085\n",
            "Current train acc: 99.97833333333334%, test acc: 89.6%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.0018450700651543833\n",
            "avg. grad_norm of last epoch 0.0561751756398352\n",
            "Current train acc: 99.98833333333333%, test acc: 89.51%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.0015126568802942828\n",
            "avg. grad_norm of last epoch 0.043082711123560054\n",
            "Current train acc: 99.98333333333333%, test acc: 89.35%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.0013639823282447958\n",
            "avg. grad_norm of last epoch 0.03879463578675945\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.0010550718517974007\n",
            "avg. grad_norm of last epoch 0.018161588883982567\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.0009359671827095251\n",
            "avg. grad_norm of last epoch 0.015335433651504358\n",
            "Current train acc: 99.99833333333333%, test acc: 89.55%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.0007819577593045932\n",
            "avg. grad_norm of last epoch 0.008503968714243621\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.0007034358989990626\n",
            "avg. grad_norm of last epoch 0.006213625412325366\n",
            "Current train acc: 100.0%, test acc: 89.46%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.0006589746759893999\n",
            "avg. grad_norm of last epoch 0.005397350508566674\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.000612865940434858\n",
            "avg. grad_norm of last epoch 0.00459603714734579\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.0005839084353297946\n",
            "avg. grad_norm of last epoch 0.003631285732791104\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.0005706474267101536\n",
            "avg. grad_norm of last epoch 0.0041587047544349755\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.0005437791411920144\n",
            "avg. grad_norm of last epoch 0.0030861512609355844\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.0005220370261153829\n",
            "avg. grad_norm of last epoch 0.0030821210796922022\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.0005030522356585908\n",
            "avg. grad_norm of last epoch 0.002729433830029718\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.0004834927886181206\n",
            "avg. grad_norm of last epoch 0.0024816209334053486\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.00046832232946374775\n",
            "avg. grad_norm of last epoch 0.0021258579232176712\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.00045249857141170665\n",
            "avg. grad_norm of last epoch 0.00208516290437752\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.00043693464750734477\n",
            "avg. grad_norm of last epoch 0.0017126211044093053\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.00042738974871269104\n",
            "avg. grad_norm of last epoch 0.0018883908312920725\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.00041474768614862135\n",
            "avg. grad_norm of last epoch 0.0015809095216357066\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.00040613480344569924\n",
            "avg. grad_norm of last epoch 0.0016181663940522566\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.0003971904208883645\n",
            "avg. grad_norm of last epoch 0.001459325560556412\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.00038532418056080756\n",
            "avg. grad_norm of last epoch 0.0014296622649278353\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.0003770619369577616\n",
            "avg. grad_norm of last epoch 0.001251643125542337\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.0003693304043418416\n",
            "avg. grad_norm of last epoch 0.0012748247986473166\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.0003627655571481836\n",
            "avg. grad_norm of last epoch 0.0011645523953750674\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.00035348605836431156\n",
            "avg. grad_norm of last epoch 0.0011226658928956033\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.00034932984754753595\n",
            "avg. grad_norm of last epoch 0.0010905746418792093\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.0003429898081657788\n",
            "avg. grad_norm of last epoch 0.0011081689183632738\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.0003367058782062186\n",
            "avg. grad_norm of last epoch 0.0010200120602312354\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.0003291134977247566\n",
            "avg. grad_norm of last epoch 0.001014048430747818\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.0003243499086548888\n",
            "avg. grad_norm of last epoch 0.0009571742071235941\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.000317403994174674\n",
            "avg. grad_norm of last epoch 0.0008951833971738915\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.00031234646989032654\n",
            "avg. grad_norm of last epoch 0.0008650902539138418\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.0003081166742835193\n",
            "avg. grad_norm of last epoch 0.0008807981422977054\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.00030323795224539943\n",
            "avg. grad_norm of last epoch 0.0008313940679328891\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.0002975630074429015\n",
            "avg. grad_norm of last epoch 0.0007739177615300678\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.00029284354614404333\n",
            "avg. grad_norm of last epoch 0.0007654880068778524\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.00028825244538020355\n",
            "avg. grad_norm of last epoch 0.000726054950233796\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.00028398421232899004\n",
            "avg. grad_norm of last epoch 0.000709906560262798\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.00027977958595535414\n",
            "avg. grad_norm of last epoch 0.000690722704322724\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.000276374692384464\n",
            "avg. grad_norm of last epoch 0.0006861560973283451\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.0002720823219045997\n",
            "avg. grad_norm of last epoch 0.0006623675409042894\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.0002688638887290533\n",
            "avg. grad_norm of last epoch 0.0006393584715568355\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.0002645076583527652\n",
            "avg. grad_norm of last epoch 0.0006214815075749783\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.00026115325810387727\n",
            "avg. grad_norm of last epoch 0.0006028160303116075\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.0002579951635717104\n",
            "avg. grad_norm of last epoch 0.0005782644657168198\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.00025461289022738734\n",
            "avg. grad_norm of last epoch 0.0005718605872018551\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.00025118238423795766\n",
            "avg. grad_norm of last epoch 0.0005353655446440665\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.000248683889299476\n",
            "avg. grad_norm of last epoch 0.0005613019108130668\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.0002448202030112346\n",
            "avg. grad_norm of last epoch 0.0005146661175925246\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.0002424340559557701\n",
            "avg. grad_norm of last epoch 0.0005264056748475242\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.0002392276929769044\n",
            "avg. grad_norm of last epoch 0.0005074371387671495\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.00023590113761990026\n",
            "avg. grad_norm of last epoch 0.0004878641235985726\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.00023404025960092737\n",
            "avg. grad_norm of last epoch 0.0004832351142398762\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.00023160599320350852\n",
            "avg. grad_norm of last epoch 0.000492066301775136\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 124 / 200: avg. loss of last epoch 0.000228202126120838\n",
            "avg. grad_norm of last epoch 0.0004543040280599882\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 125 / 200: avg. loss of last epoch 0.0002259524546718845\n",
            "avg. grad_norm of last epoch 0.00045033721738101817\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 126 / 200: avg. loss of last epoch 0.00022452802918075294\n",
            "avg. grad_norm of last epoch 0.00046542665882918447\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 127 / 200: avg. loss of last epoch 0.00022146052792668353\n",
            "avg. grad_norm of last epoch 0.00044302704423515853\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 128 / 200: avg. loss of last epoch 0.00021913414914937065\n",
            "avg. grad_norm of last epoch 0.00043258209232801745\n",
            "Current train acc: 100.0%, test acc: 89.47%\n",
            "Epoch 129 / 200: avg. loss of last epoch 0.00021618179565606032\n",
            "avg. grad_norm of last epoch 0.0004261892694848408\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 130 / 200: avg. loss of last epoch 0.00021491894346351421\n",
            "avg. grad_norm of last epoch 0.0004129276859116493\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 131 / 200: avg. loss of last epoch 0.00021243216597164664\n",
            "avg. grad_norm of last epoch 0.00040208327276517944\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 132 / 200: avg. loss of last epoch 0.0002099723813434442\n",
            "avg. grad_norm of last epoch 0.0003856314079397618\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 133 / 200: avg. loss of last epoch 0.00020805851387946562\n",
            "avg. grad_norm of last epoch 0.00039528743205040893\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 134 / 200: avg. loss of last epoch 0.00020570386917485547\n",
            "avg. grad_norm of last epoch 0.000379027198264934\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 135 / 200: avg. loss of last epoch 0.00020407208690885462\n",
            "avg. grad_norm of last epoch 0.00037028357653572856\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 136 / 200: avg. loss of last epoch 0.00020171869848854842\n",
            "avg. grad_norm of last epoch 0.000368892196100852\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 137 / 200: avg. loss of last epoch 0.0002000726725518082\n",
            "avg. grad_norm of last epoch 0.0003561958678036802\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 138 / 200: avg. loss of last epoch 0.00019844434715341773\n",
            "avg. grad_norm of last epoch 0.0003580945571410168\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 139 / 200: avg. loss of last epoch 0.0001965043906355278\n",
            "avg. grad_norm of last epoch 0.000344646641042879\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 140 / 200: avg. loss of last epoch 0.00019489765740387754\n",
            "avg. grad_norm of last epoch 0.0003410764428715709\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 141 / 200: avg. loss of last epoch 0.00019254226638586267\n",
            "avg. grad_norm of last epoch 0.0003281721111447223\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 142 / 200: avg. loss of last epoch 0.00019128713190245155\n",
            "avg. grad_norm of last epoch 0.0003210948790905578\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 143 / 200: avg. loss of last epoch 0.00018953742872302717\n",
            "avg. grad_norm of last epoch 0.0003275864086931079\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 144 / 200: avg. loss of last epoch 0.00018786887947935598\n",
            "avg. grad_norm of last epoch 0.00031635564303628865\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 145 / 200: avg. loss of last epoch 0.0001863748367798204\n",
            "avg. grad_norm of last epoch 0.00031841300142791185\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 146 / 200: avg. loss of last epoch 0.00018439523253667488\n",
            "avg. grad_norm of last epoch 0.00030071424752718613\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 147 / 200: avg. loss of last epoch 0.00018337275140608346\n",
            "avg. grad_norm of last epoch 0.0003123411570387731\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 148 / 200: avg. loss of last epoch 0.00018181852658744898\n",
            "avg. grad_norm of last epoch 0.0002952897539334009\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 149 / 200: avg. loss of last epoch 0.0001797297850251198\n",
            "avg. grad_norm of last epoch 0.0002944388588939535\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 150 / 200: avg. loss of last epoch 0.00017867048596575236\n",
            "avg. grad_norm of last epoch 0.0002895918840909412\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 151 / 200: avg. loss of last epoch 0.00017685499255312609\n",
            "avg. grad_norm of last epoch 0.00028219946819755707\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 152 / 200: avg. loss of last epoch 0.00017545143621197618\n",
            "avg. grad_norm of last epoch 0.00027525699723463746\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 153 / 200: avg. loss of last epoch 0.00017438270810525867\n",
            "avg. grad_norm of last epoch 0.0002851223993670863\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 154 / 200: avg. loss of last epoch 0.00017269583008407317\n",
            "avg. grad_norm of last epoch 0.0002612600443072479\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 155 / 200: avg. loss of last epoch 0.00017171741295217842\n",
            "avg. grad_norm of last epoch 0.0002672589018830454\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 156 / 200: avg. loss of last epoch 0.00017022191543364907\n",
            "avg. grad_norm of last epoch 0.00026982032835280874\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 157 / 200: avg. loss of last epoch 0.00016902281208119058\n",
            "avg. grad_norm of last epoch 0.0002576590980562782\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 158 / 200: avg. loss of last epoch 0.00016782207073410977\n",
            "avg. grad_norm of last epoch 0.0002633649897705128\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 159 / 200: avg. loss of last epoch 0.00016642429384713367\n",
            "avg. grad_norm of last epoch 0.00025489819158047315\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 160 / 200: avg. loss of last epoch 0.00016515804295195262\n",
            "avg. grad_norm of last epoch 0.0002487785341171662\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 161 / 200: avg. loss of last epoch 0.0001639600221222887\n",
            "avg. grad_norm of last epoch 0.0002416727737905053\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 162 / 200: avg. loss of last epoch 0.00016286711923312367\n",
            "avg. grad_norm of last epoch 0.00024340213577699705\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 163 / 200: avg. loss of last epoch 0.00016126747115049512\n",
            "avg. grad_norm of last epoch 0.00023688140692823976\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 164 / 200: avg. loss of last epoch 0.00016040459505359947\n",
            "avg. grad_norm of last epoch 0.00023453478951393386\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 165 / 200: avg. loss of last epoch 0.00015912680483888832\n",
            "avg. grad_norm of last epoch 0.0002330999934993639\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 166 / 200: avg. loss of last epoch 0.00015808059509145092\n",
            "avg. grad_norm of last epoch 0.00022733750214269693\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 167 / 200: avg. loss of last epoch 0.0001568308640892308\n",
            "avg. grad_norm of last epoch 0.0002190919112313242\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 168 / 200: avg. loss of last epoch 0.00015576098992411673\n",
            "avg. grad_norm of last epoch 0.0002207227373860584\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 169 / 200: avg. loss of last epoch 0.00015486286915450677\n",
            "avg. grad_norm of last epoch 0.00021793737492467816\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 170 / 200: avg. loss of last epoch 0.00015363040048784252\n",
            "avg. grad_norm of last epoch 0.00021690275532373944\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 171 / 200: avg. loss of last epoch 0.00015257090646773576\n",
            "avg. grad_norm of last epoch 0.00020784226608913412\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 172 / 200: avg. loss of last epoch 0.00015181006175310648\n",
            "avg. grad_norm of last epoch 0.00021581483151064839\n",
            "Current train acc: 100.0%, test acc: 89.55%\n",
            "Epoch 173 / 200: avg. loss of last epoch 0.00015073833332862697\n",
            "avg. grad_norm of last epoch 0.00020728840617270365\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 174 / 200: avg. loss of last epoch 0.00014950000875784715\n",
            "avg. grad_norm of last epoch 0.00021056523498761735\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 175 / 200: avg. loss of last epoch 0.00014875528917958344\n",
            "avg. grad_norm of last epoch 0.0002035214695533074\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 176 / 200: avg. loss of last epoch 0.00014764028505111722\n",
            "avg. grad_norm of last epoch 0.00020289148544909343\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 177 / 200: avg. loss of last epoch 0.00014695144042683157\n",
            "avg. grad_norm of last epoch 0.00020151375992180632\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 178 / 200: avg. loss of last epoch 0.0001456870555295609\n",
            "avg. grad_norm of last epoch 0.00019409447893339396\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 179 / 200: avg. loss of last epoch 0.00014485037511913088\n",
            "avg. grad_norm of last epoch 0.00018830804530176455\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 180 / 200: avg. loss of last epoch 0.00014362835253899295\n",
            "avg. grad_norm of last epoch 0.00018890751476885855\n",
            "Current train acc: 100.0%, test acc: 89.52%\n",
            "Epoch 181 / 200: avg. loss of last epoch 0.00014318502565147364\n",
            "avg. grad_norm of last epoch 0.00018964569167173058\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 182 / 200: avg. loss of last epoch 0.00014213044833935178\n",
            "avg. grad_norm of last epoch 0.00019240416227172752\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 183 / 200: avg. loss of last epoch 0.00014134567944953824\n",
            "avg. grad_norm of last epoch 0.00018105618211874453\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 184 / 200: avg. loss of last epoch 0.00014055388246973335\n",
            "avg. grad_norm of last epoch 0.00018645061403227734\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 185 / 200: avg. loss of last epoch 0.00013950319701107227\n",
            "avg. grad_norm of last epoch 0.00018183742896480846\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 186 / 200: avg. loss of last epoch 0.00013887128682884696\n",
            "avg. grad_norm of last epoch 0.00017630267704363218\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 187 / 200: avg. loss of last epoch 0.00013787116526703651\n",
            "avg. grad_norm of last epoch 0.0001783667332447831\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 188 / 200: avg. loss of last epoch 0.00013701605575624842\n",
            "avg. grad_norm of last epoch 0.0001722099322688846\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 189 / 200: avg. loss of last epoch 0.00013647358837770294\n",
            "avg. grad_norm of last epoch 0.0001730668519091966\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 190 / 200: avg. loss of last epoch 0.00013549653502025938\n",
            "avg. grad_norm of last epoch 0.0001701199480987271\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 191 / 200: avg. loss of last epoch 0.00013459538945656595\n",
            "avg. grad_norm of last epoch 0.00016688177450899545\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 192 / 200: avg. loss of last epoch 0.0001339077608815084\n",
            "avg. grad_norm of last epoch 0.00016737219149973317\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 193 / 200: avg. loss of last epoch 0.00013333996407842875\n",
            "avg. grad_norm of last epoch 0.0001682449026096042\n",
            "Current train acc: 100.0%, test acc: 89.51%\n",
            "Epoch 194 / 200: avg. loss of last epoch 0.00013252116838702936\n",
            "avg. grad_norm of last epoch 0.00016688857825419766\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 195 / 200: avg. loss of last epoch 0.00013164567455727\n",
            "avg. grad_norm of last epoch 0.00015807010657206555\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 196 / 200: avg. loss of last epoch 0.00013090997524947546\n",
            "avg. grad_norm of last epoch 0.00015821651330981453\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 197 / 200: avg. loss of last epoch 0.00013025325572816658\n",
            "avg. grad_norm of last epoch 0.00016119941042672537\n",
            "Current train acc: 100.0%, test acc: 89.48%\n",
            "Epoch 198 / 200: avg. loss of last epoch 0.00012934387876108912\n",
            "avg. grad_norm of last epoch 0.0001542822812991604\n",
            "Current train acc: 100.0%, test acc: 89.49%\n",
            "Epoch 199 / 200: avg. loss of last epoch 0.0001289915102262359\n",
            "avg. grad_norm of last epoch 0.00015292156879991245\n",
            "Current train acc: 100.0%, test acc: 89.5%\n",
            "Epoch 200 / 200: avg. loss of last epoch 0.00012797970393245734\n",
            "avg. grad_norm of last epoch 0.00015168635359229626\n",
            "Current train acc: 100.0%, test acc: 89.5%\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epoch_count = 200\n",
        "\n",
        "scheduler = diminishing_learning_rate_scheduler(0.5, 8)\n",
        "\n",
        "# beta is proposed in paper and epoch_count is inferenced from the graphs\n",
        "history = SMG_train(model, criterion, epoch_count, fashion_train_loader, fashion_test_loader, \n",
        "                    scheduler, beta=0.5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZOrWx2icjn"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/SMG-Fashion-History/SMG_diminishingLR.json\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "gBSL76rKiiLa",
        "outputId": "29b74774-51f4-4660-a17a-8416a51ab963"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f691dee8550>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_norm_square_grad(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXk_G9eyJjsz"
      },
      "source": [
        "## SMG with Exponential Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2TI22fpJmVX",
        "outputId": "4eac03b3-6217-4a9e-b1f1-9bf817c3ebf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.5841343516667694\n",
            "avg. grad_norm of last epoch 1.7348294259170973\n",
            "Current train acc: 83.71333333333334%, test acc: 82.39%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.37164061287244204\n",
            "avg. grad_norm of last epoch 0.9904368161663547\n",
            "Current train acc: 87.76166666666667%, test acc: 85.97%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.31106686391830446\n",
            "avg. grad_norm of last epoch 0.7456487726347281\n",
            "Current train acc: 89.45333333333333%, test acc: 87.03%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.279557768615087\n",
            "avg. grad_norm of last epoch 0.78593297983633\n",
            "Current train acc: 89.90666666666667%, test acc: 87.19%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.2523863086859387\n",
            "avg. grad_norm of last epoch 0.7426933666597456\n",
            "Current train acc: 90.43166666666667%, test acc: 87.25%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.2368125064611435\n",
            "avg. grad_norm of last epoch 0.8300114979027872\n",
            "Current train acc: 91.7%, test acc: 88.2%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.21770468734105436\n",
            "avg. grad_norm of last epoch 0.8241898383713198\n",
            "Current train acc: 91.39333333333333%, test acc: 87.39%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.20789206398328142\n",
            "avg. grad_norm of last epoch 0.9286596498368193\n",
            "Current train acc: 92.05%, test acc: 88.08%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.19060304088592533\n",
            "avg. grad_norm of last epoch 0.8235326973215202\n",
            "Current train acc: 93.00833333333334%, test acc: 88.87%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.18064077090422306\n",
            "avg. grad_norm of last epoch 0.9161222729144881\n",
            "Current train acc: 92.30333333333333%, test acc: 87.68%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.16945210515658046\n",
            "avg. grad_norm of last epoch 0.9110793098338351\n",
            "Current train acc: 94.42%, test acc: 88.84%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.15983264000415803\n",
            "avg. grad_norm of last epoch 0.9663617297787859\n",
            "Current train acc: 93.68666666666667%, test acc: 88.85%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.15256736439069107\n",
            "avg. grad_norm of last epoch 0.9963633459660922\n",
            "Current train acc: 94.34833333333333%, test acc: 88.38%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.14540000963211058\n",
            "avg. grad_norm of last epoch 1.0257059546375973\n",
            "Current train acc: 94.36%, test acc: 88.32%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.1354645117342472\n",
            "avg. grad_norm of last epoch 0.9711526139488078\n",
            "Current train acc: 95.015%, test acc: 89.09%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.13111878315210337\n",
            "avg. grad_norm of last epoch 1.0938621392597454\n",
            "Current train acc: 95.545%, test acc: 89.09%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.12324678165912631\n",
            "avg. grad_norm of last epoch 1.0277610366707488\n",
            "Current train acc: 94.14833333333333%, test acc: 88.06%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.11934251839717232\n",
            "avg. grad_norm of last epoch 1.075264463566348\n",
            "Current train acc: 95.72666666666667%, test acc: 88.9%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.11015042351086936\n",
            "avg. grad_norm of last epoch 0.9745130901623773\n",
            "Current train acc: 96.02833333333334%, test acc: 88.86%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.10632644800742468\n",
            "avg. grad_norm of last epoch 1.0295536510866587\n",
            "Current train acc: 96.51166666666667%, test acc: 89.34%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.09875915603637694\n",
            "avg. grad_norm of last epoch 0.9722010180283132\n",
            "Current train acc: 95.87%, test acc: 88.58%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.09690894037485122\n",
            "avg. grad_norm of last epoch 1.115570055944568\n",
            "Current train acc: 96.36833333333334%, test acc: 89.11%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.09145162568489713\n",
            "avg. grad_norm of last epoch 1.0392320382403621\n",
            "Current train acc: 96.27166666666666%, test acc: 88.72%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.0889248604734739\n",
            "avg. grad_norm of last epoch 1.0567600703001185\n",
            "Current train acc: 96.66333333333333%, test acc: 88.53%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.08158156412343187\n",
            "avg. grad_norm of last epoch 0.9731532161943065\n",
            "Current train acc: 97.33%, test acc: 89.37%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.07710988324284554\n",
            "avg. grad_norm of last epoch 0.9470444602174986\n",
            "Current train acc: 97.43166666666667%, test acc: 89.25%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.07317483673890438\n",
            "avg. grad_norm of last epoch 1.0114099312080964\n",
            "Current train acc: 97.095%, test acc: 89.03%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.07390392543673516\n",
            "avg. grad_norm of last epoch 1.0550998791484751\n",
            "Current train acc: 97.46833333333333%, test acc: 89.37%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.06852588039040564\n",
            "avg. grad_norm of last epoch 0.9882238508029858\n",
            "Current train acc: 97.39166666666667%, test acc: 88.68%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.07218141875664393\n",
            "avg. grad_norm of last epoch 1.2109537930414633\n",
            "Current train acc: 97.53333333333333%, test acc: 88.82%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.06353404755989706\n",
            "avg. grad_norm of last epoch 1.0703486421804551\n",
            "Current train acc: 97.69333333333333%, test acc: 89.2%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.06152524435917532\n",
            "avg. grad_norm of last epoch 1.046198380597577\n",
            "Current train acc: 97.155%, test acc: 88.54%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.05892891038060192\n",
            "avg. grad_norm of last epoch 1.0319711202333375\n",
            "Current train acc: 97.615%, test acc: 88.48%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.05623174558281896\n",
            "avg. grad_norm of last epoch 1.0259871111844319\n",
            "Current train acc: 97.98333333333333%, test acc: 88.76%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.04913719854156179\n",
            "avg. grad_norm of last epoch 0.8473940935292937\n",
            "Current train acc: 98.03%, test acc: 89.26%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.04725582634607953\n",
            "avg. grad_norm of last epoch 0.8834664369924455\n",
            "Current train acc: 97.73%, test acc: 88.81%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.0458161602367957\n",
            "avg. grad_norm of last epoch 0.9387822954933022\n",
            "Current train acc: 98.11833333333334%, test acc: 88.87%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.04239384059260287\n",
            "avg. grad_norm of last epoch 0.8630731881744589\n",
            "Current train acc: 98.79%, test acc: 89.31%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.04171935678074757\n",
            "avg. grad_norm of last epoch 0.9215995797775736\n",
            "Current train acc: 98.70833333333333%, test acc: 89.0%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.041838435017069145\n",
            "avg. grad_norm of last epoch 0.8892933667196222\n",
            "Current train acc: 98.35666666666667%, test acc: 88.95%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.03933156554251912\n",
            "avg. grad_norm of last epoch 0.9277374756687485\n",
            "Current train acc: 98.74166666666666%, test acc: 89.01%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.03600117640992007\n",
            "avg. grad_norm of last epoch 0.848527285504654\n",
            "Current train acc: 98.45333333333333%, test acc: 88.96%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.035155079470574876\n",
            "avg. grad_norm of last epoch 0.8607214035807617\n",
            "Current train acc: 98.52333333333333%, test acc: 89.03%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.0340119368503491\n",
            "avg. grad_norm of last epoch 0.8772665679100697\n",
            "Current train acc: 98.675%, test acc: 89.16%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.031540252875785026\n",
            "avg. grad_norm of last epoch 0.7984240571739256\n",
            "Current train acc: 98.5%, test acc: 89.09%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.033846828916917246\n",
            "avg. grad_norm of last epoch 0.9148661070824738\n",
            "Current train acc: 98.99166666666666%, test acc: 89.48%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.030490440559883907\n",
            "avg. grad_norm of last epoch 0.823339586634033\n",
            "Current train acc: 99.01333333333334%, test acc: 89.32%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.025630113378663836\n",
            "avg. grad_norm of last epoch 0.6982737871382594\n",
            "Current train acc: 98.92833333333333%, test acc: 89.21%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.027179124467571578\n",
            "avg. grad_norm of last epoch 0.7926279711121761\n",
            "Current train acc: 99.12666666666667%, test acc: 89.16%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.026043027258912714\n",
            "avg. grad_norm of last epoch 0.786209276200791\n",
            "Current train acc: 98.78333333333333%, test acc: 88.84%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.025126548050095628\n",
            "avg. grad_norm of last epoch 0.783297387417344\n",
            "Current train acc: 99.31%, test acc: 89.48%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.023442701911057028\n",
            "avg. grad_norm of last epoch 0.7434271572036615\n",
            "Current train acc: 99.14666666666666%, test acc: 89.28%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.021739276031653088\n",
            "avg. grad_norm of last epoch 0.6629537072686841\n",
            "Current train acc: 99.36833333333334%, test acc: 89.32%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.018285955775684374\n",
            "avg. grad_norm of last epoch 0.5326798261591089\n",
            "Current train acc: 99.24%, test acc: 89.21%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.01687555994316936\n",
            "avg. grad_norm of last epoch 0.5495455139249834\n",
            "Current train acc: 98.10666666666667%, test acc: 88.07%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.014813198921581115\n",
            "avg. grad_norm of last epoch 0.46237705705952253\n",
            "Current train acc: 99.59166666666667%, test acc: 89.38%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.016732961652800447\n",
            "avg. grad_norm of last epoch 0.6246791689886879\n",
            "Current train acc: 99.04333333333334%, test acc: 88.99%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.016914109761702524\n",
            "avg. grad_norm of last epoch 0.6384358192164391\n",
            "Current train acc: 98.93666666666667%, test acc: 89.36%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.018739174073251572\n",
            "avg. grad_norm of last epoch 0.7607876836683871\n",
            "Current train acc: 98.815%, test acc: 88.95%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.013637224380485714\n",
            "avg. grad_norm of last epoch 0.4395080319573612\n",
            "Current train acc: 99.40333333333334%, test acc: 89.09%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.014042869825971633\n",
            "avg. grad_norm of last epoch 0.514149742896646\n",
            "Current train acc: 99.42166666666667%, test acc: 89.31%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.011053121900496385\n",
            "avg. grad_norm of last epoch 0.3891559077243608\n",
            "Current train acc: 99.70833333333333%, test acc: 89.16%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.011454607794061305\n",
            "avg. grad_norm of last epoch 0.4449629602937867\n",
            "Current train acc: 99.64%, test acc: 89.37%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.007165301439507558\n",
            "avg. grad_norm of last epoch 0.22067014341470562\n",
            "Current train acc: 99.68333333333334%, test acc: 89.57%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.008987927579786633\n",
            "avg. grad_norm of last epoch 0.37959480474087837\n",
            "Current train acc: 99.75333333333333%, test acc: 89.65%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.00800195044856519\n",
            "avg. grad_norm of last epoch 0.3042169493001912\n",
            "Current train acc: 99.58333333333333%, test acc: 89.21%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.0065203013527517515\n",
            "avg. grad_norm of last epoch 0.2488079775495863\n",
            "Current train acc: 99.745%, test acc: 89.5%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.005208236024777094\n",
            "avg. grad_norm of last epoch 0.1761531291654535\n",
            "Current train acc: 99.865%, test acc: 89.42%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.005738101869804086\n",
            "avg. grad_norm of last epoch 0.2260157482167936\n",
            "Current train acc: 99.88833333333334%, test acc: 89.6%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.0028461076124028013\n",
            "avg. grad_norm of last epoch 0.07177429302609334\n",
            "Current train acc: 99.80166666666666%, test acc: 89.28%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.003111069378031726\n",
            "avg. grad_norm of last epoch 0.11213184509331893\n",
            "Current train acc: 99.945%, test acc: 89.36%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.002695167628986139\n",
            "avg. grad_norm of last epoch 0.0879891924935426\n",
            "Current train acc: 99.95666666666666%, test acc: 89.51%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.002805643942098444\n",
            "avg. grad_norm of last epoch 0.12984077712866962\n",
            "Current train acc: 99.84%, test acc: 89.6%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.0021703190014076713\n",
            "avg. grad_norm of last epoch 0.05986995015260097\n",
            "Current train acc: 99.96666666666667%, test acc: 89.48%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.0016654230210154002\n",
            "avg. grad_norm of last epoch 0.05016407907405567\n",
            "Current train acc: 99.97%, test acc: 89.43%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.001338496162816105\n",
            "avg. grad_norm of last epoch 0.02993575208941349\n",
            "Current train acc: 99.98166666666667%, test acc: 89.61%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.0012383700199580443\n",
            "avg. grad_norm of last epoch 0.033712679679607706\n",
            "Current train acc: 99.99%, test acc: 89.55%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.0009195618179510346\n",
            "avg. grad_norm of last epoch 0.020667274892128395\n",
            "Current train acc: 99.99666666666667%, test acc: 89.57%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.0006460053753515242\n",
            "avg. grad_norm of last epoch 0.009441639190889507\n",
            "Current train acc: 99.99666666666667%, test acc: 89.51%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.0004878977685041417\n",
            "avg. grad_norm of last epoch 0.004450634100325407\n",
            "Current train acc: 99.99666666666667%, test acc: 89.65%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.0004527744040145383\n",
            "avg. grad_norm of last epoch 0.0056918680489264455\n",
            "Current train acc: 99.99833333333333%, test acc: 89.65%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.0003460932033834978\n",
            "avg. grad_norm of last epoch 0.00195899041072551\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.00028002526906493607\n",
            "avg. grad_norm of last epoch 0.0010487032911754535\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.00025836439031797187\n",
            "avg. grad_norm of last epoch 0.0008567916410830047\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.00023384129170832868\n",
            "avg. grad_norm of last epoch 0.0005922813922394377\n",
            "Current train acc: 100.0%, test acc: 89.64%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.00021650818547932433\n",
            "avg. grad_norm of last epoch 0.0004894739849475467\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.00020584433482921067\n",
            "avg. grad_norm of last epoch 0.00040019173264672344\n",
            "Current train acc: 100.0%, test acc: 89.54%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.00019596919394486269\n",
            "avg. grad_norm of last epoch 0.0003685040025103312\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.00018924151485941057\n",
            "avg. grad_norm of last epoch 0.00035052840143842375\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.00018159050665174912\n",
            "avg. grad_norm of last epoch 0.0002988482956229195\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.00017706444022090503\n",
            "avg. grad_norm of last epoch 0.00030314682858499333\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.0001714987817065169\n",
            "avg. grad_norm of last epoch 0.0002633658514757788\n",
            "Current train acc: 100.0%, test acc: 89.53%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.00016648606620340921\n",
            "avg. grad_norm of last epoch 0.00026152996163166767\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.00016178494015087696\n",
            "avg. grad_norm of last epoch 0.00023821367570798227\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.0001579983369660719\n",
            "avg. grad_norm of last epoch 0.00023121595011486255\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.00015454207065631644\n",
            "avg. grad_norm of last epoch 0.00022766219075841604\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.00015014857250304574\n",
            "avg. grad_norm of last epoch 0.0002046743167109913\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.00014626145998578673\n",
            "avg. grad_norm of last epoch 0.00019616020678478829\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.00014439707879015877\n",
            "avg. grad_norm of last epoch 0.00019278403537382202\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.00014155726904088308\n",
            "avg. grad_norm of last epoch 0.00018806981285790367\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.0001384244588669389\n",
            "avg. grad_norm of last epoch 0.00017491970559622226\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.00013528774549777136\n",
            "avg. grad_norm of last epoch 0.00016574363736484172\n",
            "Current train acc: 100.0%, test acc: 89.64%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.00013295591015582137\n",
            "avg. grad_norm of last epoch 0.00015903801939064585\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.00013045501260494345\n",
            "avg. grad_norm of last epoch 0.0001578693946513681\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.00012770529180561432\n",
            "avg. grad_norm of last epoch 0.00014167743525742309\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.00012577153894332394\n",
            "avg. grad_norm of last epoch 0.00014022390845536852\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.00012334258859821915\n",
            "avg. grad_norm of last epoch 0.00013725666369594425\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.00012214943700091668\n",
            "avg. grad_norm of last epoch 0.0001367035690239586\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.00012015590450998086\n",
            "avg. grad_norm of last epoch 0.0001288301326666078\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.000118241224406908\n",
            "avg. grad_norm of last epoch 0.0001265461566641446\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.00011573717703771165\n",
            "avg. grad_norm of last epoch 0.00011852595757915174\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.00011548173400030163\n",
            "avg. grad_norm of last epoch 0.0001229799221487685\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.00011331264719095402\n",
            "avg. grad_norm of last epoch 0.00011521763138116774\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.00011185974430021214\n",
            "avg. grad_norm of last epoch 0.00010919310669644559\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.00011025245415463953\n",
            "avg. grad_norm of last epoch 0.00010520578502993999\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.00010886660051764917\n",
            "avg. grad_norm of last epoch 0.00010464135164790814\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.00010755660110250272\n",
            "avg. grad_norm of last epoch 0.00010258486642245507\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.00010627635053339564\n",
            "avg. grad_norm of last epoch 0.00010218815997498644\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.00010489623814258575\n",
            "avg. grad_norm of last epoch 9.834952220036437e-05\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.00010399185427425736\n",
            "avg. grad_norm of last epoch 9.7025197165137e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.00010257731079279127\n",
            "avg. grad_norm of last epoch 9.337014734870941e-05\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.00010173589110539378\n",
            "avg. grad_norm of last epoch 9.225468279492561e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.00010051066320835779\n",
            "avg. grad_norm of last epoch 9.12559633762202e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 124 / 200: avg. loss of last epoch 9.934028081285461e-05\n",
            "avg. grad_norm of last epoch 8.543731177556671e-05\n",
            "Current train acc: 100.0%, test acc: 89.57%\n",
            "Epoch 125 / 200: avg. loss of last epoch 9.838395462138571e-05\n",
            "avg. grad_norm of last epoch 8.544378642344483e-05\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 126 / 200: avg. loss of last epoch 9.747582556058967e-05\n",
            "avg. grad_norm of last epoch 8.337622486214024e-05\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 127 / 200: avg. loss of last epoch 9.646514655905778e-05\n",
            "avg. grad_norm of last epoch 8.139345191924637e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 128 / 200: avg. loss of last epoch 9.535496590542613e-05\n",
            "avg. grad_norm of last epoch 8.149765376938856e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 129 / 200: avg. loss of last epoch 9.459763281338389e-05\n",
            "avg. grad_norm of last epoch 8.054895349200723e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 130 / 200: avg. loss of last epoch 9.377801991843938e-05\n",
            "avg. grad_norm of last epoch 7.926841686364518e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 131 / 200: avg. loss of last epoch 9.283831133895251e-05\n",
            "avg. grad_norm of last epoch 7.454906409344105e-05\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 132 / 200: avg. loss of last epoch 9.225779495997505e-05\n",
            "avg. grad_norm of last epoch 7.712196759866758e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 133 / 200: avg. loss of last epoch 9.123698521192038e-05\n",
            "avg. grad_norm of last epoch 7.432435041414725e-05\n",
            "Current train acc: 100.0%, test acc: 89.56%\n",
            "Epoch 134 / 200: avg. loss of last epoch 9.052018548633596e-05\n",
            "avg. grad_norm of last epoch 6.986522346057379e-05\n",
            "Current train acc: 100.0%, test acc: 89.58%\n",
            "Epoch 135 / 200: avg. loss of last epoch 8.971975911214627e-05\n",
            "avg. grad_norm of last epoch 7.021048195882404e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 136 / 200: avg. loss of last epoch 8.893886204653735e-05\n",
            "avg. grad_norm of last epoch 6.893173732262831e-05\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 137 / 200: avg. loss of last epoch 8.833185909509977e-05\n",
            "avg. grad_norm of last epoch 7.063273768302816e-05\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 138 / 200: avg. loss of last epoch 8.756046012325289e-05\n",
            "avg. grad_norm of last epoch 6.723660996537203e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 139 / 200: avg. loss of last epoch 8.695513303779695e-05\n",
            "avg. grad_norm of last epoch 6.760932226414898e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 140 / 200: avg. loss of last epoch 8.623561755036167e-05\n",
            "avg. grad_norm of last epoch 6.613260960889976e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 141 / 200: avg. loss of last epoch 8.557588273251896e-05\n",
            "avg. grad_norm of last epoch 6.429980644881065e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 142 / 200: avg. loss of last epoch 8.508329465597248e-05\n",
            "avg. grad_norm of last epoch 6.355029090600157e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 143 / 200: avg. loss of last epoch 8.447059994505255e-05\n",
            "avg. grad_norm of last epoch 6.325543927515384e-05\n",
            "Current train acc: 100.0%, test acc: 89.59%\n",
            "Epoch 144 / 200: avg. loss of last epoch 8.366620757248423e-05\n",
            "avg. grad_norm of last epoch 6.099725103340359e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 145 / 200: avg. loss of last epoch 8.336310255108406e-05\n",
            "avg. grad_norm of last epoch 6.106436556880054e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 146 / 200: avg. loss of last epoch 8.273791744528956e-05\n",
            "avg. grad_norm of last epoch 6.0732903286734304e-05\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 147 / 200: avg. loss of last epoch 8.207910497343013e-05\n",
            "avg. grad_norm of last epoch 5.961303258623892e-05\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 148 / 200: avg. loss of last epoch 8.157380575721616e-05\n",
            "avg. grad_norm of last epoch 5.786025142416479e-05\n",
            "Current train acc: 100.0%, test acc: 89.6%\n",
            "Epoch 149 / 200: avg. loss of last epoch 8.107759540240904e-05\n",
            "avg. grad_norm of last epoch 5.7586742101945914e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 150 / 200: avg. loss of last epoch 8.040309120551678e-05\n",
            "avg. grad_norm of last epoch 5.500314110319216e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 151 / 200: avg. loss of last epoch 8.005976035007434e-05\n",
            "avg. grad_norm of last epoch 5.6208971147575065e-05\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 152 / 200: avg. loss of last epoch 7.957630028007156e-05\n",
            "avg. grad_norm of last epoch 5.544771839175086e-05\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 153 / 200: avg. loss of last epoch 7.90849901124602e-05\n",
            "avg. grad_norm of last epoch 5.530852356219843e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 154 / 200: avg. loss of last epoch 7.852567177663631e-05\n",
            "avg. grad_norm of last epoch 5.455091743342536e-05\n",
            "Current train acc: 100.0%, test acc: 89.61%\n",
            "Epoch 155 / 200: avg. loss of last epoch 7.808196832435595e-05\n",
            "avg. grad_norm of last epoch 5.370432252675126e-05\n",
            "Current train acc: 100.0%, test acc: 89.62%\n",
            "Epoch 156 / 200: avg. loss of last epoch 7.767135210936736e-05\n",
            "avg. grad_norm of last epoch 5.281140973183497e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 157 / 200: avg. loss of last epoch 7.734817000067167e-05\n",
            "avg. grad_norm of last epoch 5.342124022729887e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 158 / 200: avg. loss of last epoch 7.684615436398115e-05\n",
            "avg. grad_norm of last epoch 5.2506396142307056e-05\n",
            "Current train acc: 100.0%, test acc: 89.64%\n",
            "Epoch 159 / 200: avg. loss of last epoch 7.642289070645341e-05\n",
            "avg. grad_norm of last epoch 5.18884591680462e-05\n",
            "Current train acc: 100.0%, test acc: 89.64%\n",
            "Epoch 160 / 200: avg. loss of last epoch 7.594620833600258e-05\n",
            "avg. grad_norm of last epoch 5.10978234781892e-05\n",
            "Current train acc: 100.0%, test acc: 89.64%\n",
            "Epoch 161 / 200: avg. loss of last epoch 7.563485218852289e-05\n",
            "avg. grad_norm of last epoch 4.963248498286637e-05\n",
            "Current train acc: 100.0%, test acc: 89.64%\n",
            "Epoch 162 / 200: avg. loss of last epoch 7.517548868005786e-05\n",
            "avg. grad_norm of last epoch 4.950678701924349e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 163 / 200: avg. loss of last epoch 7.486002641671808e-05\n",
            "avg. grad_norm of last epoch 5.072164376178943e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 164 / 200: avg. loss of last epoch 7.442527546663773e-05\n",
            "avg. grad_norm of last epoch 4.9269095815840585e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 165 / 200: avg. loss of last epoch 7.412031503772592e-05\n",
            "avg. grad_norm of last epoch 4.801273800099565e-05\n",
            "Current train acc: 100.0%, test acc: 89.65%\n",
            "Epoch 166 / 200: avg. loss of last epoch 7.367036605525451e-05\n",
            "avg. grad_norm of last epoch 4.806797106709186e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 167 / 200: avg. loss of last epoch 7.344632653597121e-05\n",
            "avg. grad_norm of last epoch 4.6710801283676595e-05\n",
            "Current train acc: 100.0%, test acc: 89.63%\n",
            "Epoch 168 / 200: avg. loss of last epoch 7.299735558190148e-05\n",
            "avg. grad_norm of last epoch 4.708243066487113e-05\n",
            "Current train acc: 100.0%, test acc: 89.65%\n",
            "Epoch 169 / 200: avg. loss of last epoch 7.269818996525533e-05\n",
            "avg. grad_norm of last epoch 4.717855098981253e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 170 / 200: avg. loss of last epoch 7.233585464127823e-05\n",
            "avg. grad_norm of last epoch 4.526412763024595e-05\n",
            "Current train acc: 100.0%, test acc: 89.65%\n",
            "Epoch 171 / 200: avg. loss of last epoch 7.205083334702077e-05\n",
            "avg. grad_norm of last epoch 4.521870741807772e-05\n",
            "Current train acc: 100.0%, test acc: 89.65%\n",
            "Epoch 172 / 200: avg. loss of last epoch 7.163379459428444e-05\n",
            "avg. grad_norm of last epoch 4.544107712127963e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 173 / 200: avg. loss of last epoch 7.140811984524288e-05\n",
            "avg. grad_norm of last epoch 4.4705078670730906e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 174 / 200: avg. loss of last epoch 7.106883922291058e-05\n",
            "avg. grad_norm of last epoch 4.4441169435597074e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 175 / 200: avg. loss of last epoch 7.072897783170149e-05\n",
            "avg. grad_norm of last epoch 4.3689281208797555e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 176 / 200: avg. loss of last epoch 7.056877073482608e-05\n",
            "avg. grad_norm of last epoch 4.3831417954026614e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 177 / 200: avg. loss of last epoch 7.018790671621292e-05\n",
            "avg. grad_norm of last epoch 4.221874301178342e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 178 / 200: avg. loss of last epoch 6.994087759812827e-05\n",
            "avg. grad_norm of last epoch 4.372699585452662e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 179 / 200: avg. loss of last epoch 6.94957628914077e-05\n",
            "avg. grad_norm of last epoch 4.246990119626198e-05\n",
            "Current train acc: 100.0%, test acc: 89.69%\n",
            "Epoch 180 / 200: avg. loss of last epoch 6.942148139060018e-05\n",
            "avg. grad_norm of last epoch 4.22246543309511e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 181 / 200: avg. loss of last epoch 6.899060530461907e-05\n",
            "avg. grad_norm of last epoch 4.1335729496986936e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 182 / 200: avg. loss of last epoch 6.889566648945527e-05\n",
            "avg. grad_norm of last epoch 4.2554622015861594e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 183 / 200: avg. loss of last epoch 6.856977465019254e-05\n",
            "avg. grad_norm of last epoch 4.068822949762785e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 184 / 200: avg. loss of last epoch 6.832565538158333e-05\n",
            "avg. grad_norm of last epoch 4.16018647517083e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 185 / 200: avg. loss of last epoch 6.804797221945287e-05\n",
            "avg. grad_norm of last epoch 4.053073272218412e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 186 / 200: avg. loss of last epoch 6.779476623923979e-05\n",
            "avg. grad_norm of last epoch 3.9899918439571e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 187 / 200: avg. loss of last epoch 6.759408738823063e-05\n",
            "avg. grad_norm of last epoch 4.07736876310476e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 188 / 200: avg. loss of last epoch 6.734748935899308e-05\n",
            "avg. grad_norm of last epoch 4.045559675490858e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 189 / 200: avg. loss of last epoch 6.712323377529783e-05\n",
            "avg. grad_norm of last epoch 3.9631456264399384e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 190 / 200: avg. loss of last epoch 6.686239455787775e-05\n",
            "avg. grad_norm of last epoch 3.9426132348987874e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 191 / 200: avg. loss of last epoch 6.664221298221191e-05\n",
            "avg. grad_norm of last epoch 3.907984779983955e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 192 / 200: avg. loss of last epoch 6.642428423995929e-05\n",
            "avg. grad_norm of last epoch 3.810695670548745e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 193 / 200: avg. loss of last epoch 6.62060109132047e-05\n",
            "avg. grad_norm of last epoch 3.882488884076189e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 194 / 200: avg. loss of last epoch 6.596910286655964e-05\n",
            "avg. grad_norm of last epoch 3.7703576878062675e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 195 / 200: avg. loss of last epoch 6.580254856380632e-05\n",
            "avg. grad_norm of last epoch 3.793399498649215e-05\n",
            "Current train acc: 100.0%, test acc: 89.68%\n",
            "Epoch 196 / 200: avg. loss of last epoch 6.555780142431712e-05\n",
            "avg. grad_norm of last epoch 3.762687672056305e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 197 / 200: avg. loss of last epoch 6.5345590520883e-05\n",
            "avg. grad_norm of last epoch 3.647843787983222e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n",
            "Epoch 198 / 200: avg. loss of last epoch 6.517707541982719e-05\n",
            "avg. grad_norm of last epoch 3.895545261491431e-05\n",
            "Current train acc: 100.0%, test acc: 89.69%\n",
            "Epoch 199 / 200: avg. loss of last epoch 6.494307759276125e-05\n",
            "avg. grad_norm of last epoch 3.6366204629053384e-05\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 200 / 200: avg. loss of last epoch 6.477995006522785e-05\n",
            "avg. grad_norm of last epoch 3.59317532845653e-05\n",
            "Current train acc: 100.0%, test acc: 89.66%\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epoch_count = 200\n",
        "\n",
        "scheduler = exponential_learning_rate_scheduler(0.5, 0.99)\n",
        "\n",
        "# beta is proposed in paper and epoch_count is inferenced from the graphs\n",
        "history = SMG_train(model, criterion, epoch_count, fashion_train_loader, fashion_test_loader, \n",
        "                    scheduler, beta=0.5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQmbIBhMKMMh"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/SMG-Fashion-History/SMG_ExponentialLR.json\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "jckCrMuOSrW1",
        "outputId": "650950f0-e9f0-4bef-a6fd-33a009be2b0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f42ebe8ee90>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_norm_square_grad(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNz4DgN7S2cT"
      },
      "source": [
        "## SMG with Cosine Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIRHm21HS7Em",
        "outputId": "a8d7464f-ceb5-4911-8020-4fbbde65c126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.5730958459218347\n",
            "avg. grad_norm of last epoch 1.8773445127527044\n",
            "Current train acc: 84.785%, test acc: 83.56%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.3728693809032445\n",
            "avg. grad_norm of last epoch 1.142103092769356\n",
            "Current train acc: 86.885%, test acc: 85.29%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.312507641855876\n",
            "avg. grad_norm of last epoch 0.8864043559914895\n",
            "Current train acc: 88.01333333333334%, test acc: 85.45%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.2786109353383382\n",
            "avg. grad_norm of last epoch 0.8837874946185255\n",
            "Current train acc: 89.52666666666667%, test acc: 86.73%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.2538440137386323\n",
            "avg. grad_norm of last epoch 0.8519220902015847\n",
            "Current train acc: 89.96833333333333%, test acc: 86.86%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.2354987569173177\n",
            "avg. grad_norm of last epoch 0.9176968464270828\n",
            "Current train acc: 91.515%, test acc: 88.06%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.21642026374340048\n",
            "avg. grad_norm of last epoch 0.901792427760729\n",
            "Current train acc: 92.53166666666667%, test acc: 88.68%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.2075855182647705\n",
            "avg. grad_norm of last epoch 1.015241707842182\n",
            "Current train acc: 91.99833333333333%, test acc: 87.27%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.1936119392077127\n",
            "avg. grad_norm of last epoch 0.9757102557949774\n",
            "Current train acc: 93.495%, test acc: 89.05%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.18011628979841862\n",
            "avg. grad_norm of last epoch 0.9959402128461622\n",
            "Current train acc: 93.24%, test acc: 88.61%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.17012777468760806\n",
            "avg. grad_norm of last epoch 1.0903026001336795\n",
            "Current train acc: 93.31%, test acc: 88.12%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.1629770497878393\n",
            "avg. grad_norm of last epoch 1.0920376486212466\n",
            "Current train acc: 94.02666666666667%, test acc: 88.93%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.15456683516105027\n",
            "avg. grad_norm of last epoch 1.1425328871074663\n",
            "Current train acc: 95.02166666666666%, test acc: 89.24%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.1455789546529453\n",
            "avg. grad_norm of last epoch 1.0983851744025341\n",
            "Current train acc: 94.81%, test acc: 88.79%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.13566550638675687\n",
            "avg. grad_norm of last epoch 1.044506128109281\n",
            "Current train acc: 95.16833333333334%, test acc: 88.84%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.13163630176385252\n",
            "avg. grad_norm of last epoch 1.1597197032797544\n",
            "Current train acc: 95.26%, test acc: 88.87%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.12296826355854669\n",
            "avg. grad_norm of last epoch 1.1060454334116152\n",
            "Current train acc: 95.855%, test acc: 89.39%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.11818831740617751\n",
            "avg. grad_norm of last epoch 1.1351185517892577\n",
            "Current train acc: 95.13%, test acc: 88.58%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.12311119043032336\n",
            "avg. grad_norm of last epoch 1.5230698012264932\n",
            "Current train acc: 95.90833333333333%, test acc: 89.26%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.11489857520461094\n",
            "avg. grad_norm of last epoch 1.259453632380566\n",
            "Current train acc: 96.145%, test acc: 88.96%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.1066227543552716\n",
            "avg. grad_norm of last epoch 1.1926089668014916\n",
            "Current train acc: 96.12333333333333%, test acc: 88.82%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.10159886027971912\n",
            "avg. grad_norm of last epoch 1.1458071252800182\n",
            "Current train acc: 95.48666666666666%, test acc: 88.26%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.09708858933051427\n",
            "avg. grad_norm of last epoch 1.161801720140493\n",
            "Current train acc: 96.07333333333334%, test acc: 88.51%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.09362851987282421\n",
            "avg. grad_norm of last epoch 1.1205049240328449\n",
            "Current train acc: 97.305%, test acc: 89.44%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.08570627498825391\n",
            "avg. grad_norm of last epoch 1.0640698622127007\n",
            "Current train acc: 96.685%, test acc: 88.4%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.0827892059604327\n",
            "avg. grad_norm of last epoch 1.0894375385224524\n",
            "Current train acc: 96.345%, test acc: 88.69%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.0766066126386325\n",
            "avg. grad_norm of last epoch 1.0569787741513603\n",
            "Current train acc: 97.09833333333333%, test acc: 88.72%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.07783983161250754\n",
            "avg. grad_norm of last epoch 1.1776056026879371\n",
            "Current train acc: 97.00666666666666%, test acc: 88.85%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.07256074298818899\n",
            "avg. grad_norm of last epoch 1.0705059647572226\n",
            "Current train acc: 97.14666666666666%, test acc: 88.84%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.06944647239645323\n",
            "avg. grad_norm of last epoch 1.1352864083999363\n",
            "Current train acc: 97.50833333333334%, test acc: 89.14%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.0672788709243139\n",
            "avg. grad_norm of last epoch 1.1007093839216107\n",
            "Current train acc: 96.48833333333333%, test acc: 88.43%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.06553383294741313\n",
            "avg. grad_norm of last epoch 1.0963085364331024\n",
            "Current train acc: 97.80833333333334%, test acc: 88.9%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.06421272892455263\n",
            "avg. grad_norm of last epoch 1.1245224564599983\n",
            "Current train acc: 96.81166666666667%, test acc: 88.3%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.06373229715625446\n",
            "avg. grad_norm of last epoch 1.1772031622794907\n",
            "Current train acc: 97.32%, test acc: 88.49%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.05937664489448069\n",
            "avg. grad_norm of last epoch 1.1507127798746846\n",
            "Current train acc: 97.48833333333333%, test acc: 88.73%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.057790013309319856\n",
            "avg. grad_norm of last epoch 1.1202933264729025\n",
            "Current train acc: 98.00666666666666%, test acc: 88.98%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.054885800622900306\n",
            "avg. grad_norm of last epoch 1.1259706803383396\n",
            "Current train acc: 98.01833333333333%, test acc: 89.15%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.05545400629937644\n",
            "avg. grad_norm of last epoch 1.1756600874799543\n",
            "Current train acc: 96.995%, test acc: 88.58%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.050111455682913426\n",
            "avg. grad_norm of last epoch 0.9961928497053315\n",
            "Current train acc: 97.745%, test acc: 88.7%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.04792257613241673\n",
            "avg. grad_norm of last epoch 1.0342850476957375\n",
            "Current train acc: 97.71833333333333%, test acc: 88.86%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.04734405860702196\n",
            "avg. grad_norm of last epoch 1.0369303490360418\n",
            "Current train acc: 98.545%, test acc: 89.0%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.04832161530901987\n",
            "avg. grad_norm of last epoch 1.1358744164491146\n",
            "Current train acc: 98.34833333333333%, test acc: 89.12%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.041849433574577134\n",
            "avg. grad_norm of last epoch 0.9254898488722048\n",
            "Current train acc: 98.44%, test acc: 89.08%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.04138215177257855\n",
            "avg. grad_norm of last epoch 0.9541682729242239\n",
            "Current train acc: 97.72833333333334%, test acc: 88.58%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.04276420700947447\n",
            "avg. grad_norm of last epoch 1.093078739742426\n",
            "Current train acc: 98.31333333333333%, test acc: 88.56%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.040520306468506635\n",
            "avg. grad_norm of last epoch 1.0402096188184684\n",
            "Current train acc: 98.11166666666666%, test acc: 88.68%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.03750261313815914\n",
            "avg. grad_norm of last epoch 0.9980059607059355\n",
            "Current train acc: 98.24666666666667%, test acc: 88.6%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.040452678574621675\n",
            "avg. grad_norm of last epoch 1.0912916719332033\n",
            "Current train acc: 98.29833333333333%, test acc: 88.64%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.03259201876719789\n",
            "avg. grad_norm of last epoch 0.8298466677403077\n",
            "Current train acc: 98.42666666666666%, test acc: 88.92%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.031801310792565346\n",
            "avg. grad_norm of last epoch 0.8600236319929708\n",
            "Current train acc: 98.22166666666666%, test acc: 88.59%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.0333567266141375\n",
            "avg. grad_norm of last epoch 0.9476998314803975\n",
            "Current train acc: 98.75666666666666%, test acc: 88.82%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.02890038279816509\n",
            "avg. grad_norm of last epoch 0.8097445822235421\n",
            "Current train acc: 98.83666666666667%, test acc: 89.12%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.02920601989937326\n",
            "avg. grad_norm of last epoch 0.8692138654448137\n",
            "Current train acc: 98.04666666666667%, test acc: 88.24%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.03079329716091354\n",
            "avg. grad_norm of last epoch 0.9230425382699591\n",
            "Current train acc: 98.37666666666667%, test acc: 89.14%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.026704123775412612\n",
            "avg. grad_norm of last epoch 0.8186842573180554\n",
            "Current train acc: 98.95666666666666%, test acc: 89.05%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.025883387544999525\n",
            "avg. grad_norm of last epoch 0.8374479029903437\n",
            "Current train acc: 99.31%, test acc: 88.88%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.023683380933478458\n",
            "avg. grad_norm of last epoch 0.7453812206491396\n",
            "Current train acc: 99.12666666666667%, test acc: 88.94%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.02286165078791478\n",
            "avg. grad_norm of last epoch 0.7404120880744823\n",
            "Current train acc: 99.24166666666666%, test acc: 88.87%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.021466083883928767\n",
            "avg. grad_norm of last epoch 0.739974677260865\n",
            "Current train acc: 99.24666666666667%, test acc: 88.97%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.018800501023605472\n",
            "avg. grad_norm of last epoch 0.6218415416656827\n",
            "Current train acc: 98.85%, test acc: 89.03%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.02159919611848891\n",
            "avg. grad_norm of last epoch 0.7615244449409065\n",
            "Current train acc: 99.21%, test acc: 89.17%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.01856897015217691\n",
            "avg. grad_norm of last epoch 0.6450893224727958\n",
            "Current train acc: 99.08666666666667%, test acc: 89.07%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.01936190988949189\n",
            "avg. grad_norm of last epoch 0.7663291816695986\n",
            "Current train acc: 99.05833333333334%, test acc: 89.05%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.017750156483985483\n",
            "avg. grad_norm of last epoch 0.6492797657433081\n",
            "Current train acc: 99.25666666666666%, test acc: 88.93%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.016717814813492198\n",
            "avg. grad_norm of last epoch 0.6145984545817875\n",
            "Current train acc: 99.31%, test acc: 89.1%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.014972046912213169\n",
            "avg. grad_norm of last epoch 0.5484586970441455\n",
            "Current train acc: 99.52%, test acc: 89.49%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.013563369962417814\n",
            "avg. grad_norm of last epoch 0.5368565639845533\n",
            "Current train acc: 99.39666666666666%, test acc: 89.46%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.01501700026749944\n",
            "avg. grad_norm of last epoch 0.6253580649297726\n",
            "Current train acc: 99.61666666666666%, test acc: 89.5%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.010746143819577994\n",
            "avg. grad_norm of last epoch 0.42331359533419116\n",
            "Current train acc: 99.57666666666667%, test acc: 89.36%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.01191113791520086\n",
            "avg. grad_norm of last epoch 0.5060980327840227\n",
            "Current train acc: 99.565%, test acc: 89.36%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.013289930710444858\n",
            "avg. grad_norm of last epoch 0.6201666204916937\n",
            "Current train acc: 99.365%, test acc: 89.05%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.011201873311741906\n",
            "avg. grad_norm of last epoch 0.5008505585288088\n",
            "Current train acc: 99.415%, test acc: 89.17%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.011474553481054797\n",
            "avg. grad_norm of last epoch 0.540613699096851\n",
            "Current train acc: 99.455%, test acc: 89.19%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.011009239508056396\n",
            "avg. grad_norm of last epoch 0.49831078389289385\n",
            "Current train acc: 99.72833333333334%, test acc: 89.56%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.008526302052599693\n",
            "avg. grad_norm of last epoch 0.37938526254306404\n",
            "Current train acc: 99.74666666666667%, test acc: 89.24%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.007870971851795914\n",
            "avg. grad_norm of last epoch 0.3463891675485138\n",
            "Current train acc: 99.71333333333334%, test acc: 89.24%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.006956305046705531\n",
            "avg. grad_norm of last epoch 0.31004996101587795\n",
            "Current train acc: 99.42833333333333%, test acc: 89.23%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.005168438288328857\n",
            "avg. grad_norm of last epoch 0.22640596585603495\n",
            "Current train acc: 99.69%, test acc: 89.41%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.004322649552409225\n",
            "avg. grad_norm of last epoch 0.1811658992940713\n",
            "Current train acc: 99.91833333333334%, test acc: 89.61%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.003781138914978753\n",
            "avg. grad_norm of last epoch 0.16999811563350223\n",
            "Current train acc: 99.84333333333333%, test acc: 89.53%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.002871291808401778\n",
            "avg. grad_norm of last epoch 0.12539628643219222\n",
            "Current train acc: 99.94333333333333%, test acc: 89.69%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.0024054369041579785\n",
            "avg. grad_norm of last epoch 0.09943766886623334\n",
            "Current train acc: 99.95666666666666%, test acc: 89.31%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.0022515869554442683\n",
            "avg. grad_norm of last epoch 0.09846188484858752\n",
            "Current train acc: 99.975%, test acc: 89.57%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.001921168206593332\n",
            "avg. grad_norm of last epoch 0.08117604570154484\n",
            "Current train acc: 99.985%, test acc: 89.75%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.0012677760474810692\n",
            "avg. grad_norm of last epoch 0.03561624988038551\n",
            "Current train acc: 99.95666666666666%, test acc: 89.45%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.0009051672273625926\n",
            "avg. grad_norm of last epoch 0.021201870662096854\n",
            "Current train acc: 99.995%, test acc: 89.72%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.0006875150165947473\n",
            "avg. grad_norm of last epoch 0.01618902040921787\n",
            "Current train acc: 99.995%, test acc: 89.7%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.0006556283924748031\n",
            "avg. grad_norm of last epoch 0.021318709956631213\n",
            "Current train acc: 99.995%, test acc: 89.77%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.00042594959984805123\n",
            "avg. grad_norm of last epoch 0.006754691756077294\n",
            "Current train acc: 99.99833333333333%, test acc: 89.52%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.0003148973870556802\n",
            "avg. grad_norm of last epoch 0.0035679429947137508\n",
            "Current train acc: 100.0%, test acc: 89.67%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.00023837698129354975\n",
            "avg. grad_norm of last epoch 0.001428025451777473\n",
            "Current train acc: 100.0%, test acc: 89.65%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.0001842776261580487\n",
            "avg. grad_norm of last epoch 0.0006875496989945876\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.00015004101988646052\n",
            "avg. grad_norm of last epoch 0.00030747834886270855\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.0001351268407481257\n",
            "avg. grad_norm of last epoch 0.0002677543055665649\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.00013257149576384117\n",
            "avg. grad_norm of last epoch 0.0006663261920268586\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.00013927376489106474\n",
            "avg. grad_norm of last epoch 0.0008258587036565766\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.00012127924416417964\n",
            "avg. grad_norm of last epoch 0.0003313622899675464\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.00011203751694314031\n",
            "avg. grad_norm of last epoch 0.00013095983325683725\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.0001069255896659646\n",
            "avg. grad_norm of last epoch 0.00011477030120808612\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.00010293590555666014\n",
            "avg. grad_norm of last epoch 0.0001061358965283748\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 101 / 200: avg. loss of last epoch 9.914136042377027e-05\n",
            "avg. grad_norm of last epoch 9.824131142554584e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 102 / 200: avg. loss of last epoch 9.667683337950924e-05\n",
            "avg. grad_norm of last epoch 8.803199563540368e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 103 / 200: avg. loss of last epoch 9.435364758440599e-05\n",
            "avg. grad_norm of last epoch 8.687638818649873e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 104 / 200: avg. loss of last epoch 9.20593977789395e-05\n",
            "avg. grad_norm of last epoch 8.281277895547303e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 105 / 200: avg. loss of last epoch 8.963474753642606e-05\n",
            "avg. grad_norm of last epoch 7.656699590105634e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 106 / 200: avg. loss of last epoch 8.78899856150383e-05\n",
            "avg. grad_norm of last epoch 7.194467856942889e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 107 / 200: avg. loss of last epoch 8.637382012190452e-05\n",
            "avg. grad_norm of last epoch 7.084045725994075e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 108 / 200: avg. loss of last epoch 8.476745228108473e-05\n",
            "avg. grad_norm of last epoch 6.756410626980686e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 109 / 200: avg. loss of last epoch 8.303653311401536e-05\n",
            "avg. grad_norm of last epoch 6.529245762161497e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 110 / 200: avg. loss of last epoch 8.176047065450489e-05\n",
            "avg. grad_norm of last epoch 6.161931320545743e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 111 / 200: avg. loss of last epoch 8.016063769367374e-05\n",
            "avg. grad_norm of last epoch 5.884050893981272e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 112 / 200: avg. loss of last epoch 7.929600521456452e-05\n",
            "avg. grad_norm of last epoch 5.923957837656329e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 113 / 200: avg. loss of last epoch 7.783092971561316e-05\n",
            "avg. grad_norm of last epoch 5.8431424096472184e-05\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 114 / 200: avg. loss of last epoch 7.698857177795918e-05\n",
            "avg. grad_norm of last epoch 5.424484793149999e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 115 / 200: avg. loss of last epoch 7.575950360624127e-05\n",
            "avg. grad_norm of last epoch 5.4354852968212746e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 116 / 200: avg. loss of last epoch 7.476049794446826e-05\n",
            "avg. grad_norm of last epoch 5.199249907889178e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 117 / 200: avg. loss of last epoch 7.378450515000929e-05\n",
            "avg. grad_norm of last epoch 5.145210105721498e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 118 / 200: avg. loss of last epoch 7.293156437420591e-05\n",
            "avg. grad_norm of last epoch 5.08602971931483e-05\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 119 / 200: avg. loss of last epoch 7.20965559485194e-05\n",
            "avg. grad_norm of last epoch 4.9259070135983566e-05\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 120 / 200: avg. loss of last epoch 7.116953951820803e-05\n",
            "avg. grad_norm of last epoch 4.768899226536805e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 121 / 200: avg. loss of last epoch 7.043954549347593e-05\n",
            "avg. grad_norm of last epoch 4.582713329753642e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 122 / 200: avg. loss of last epoch 6.95210514367014e-05\n",
            "avg. grad_norm of last epoch 4.458579320912827e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 123 / 200: avg. loss of last epoch 6.89566553298695e-05\n",
            "avg. grad_norm of last epoch 4.458353148047972e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 124 / 200: avg. loss of last epoch 6.818554280374278e-05\n",
            "avg. grad_norm of last epoch 4.4382761281266856e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 125 / 200: avg. loss of last epoch 6.75728622367994e-05\n",
            "avg. grad_norm of last epoch 4.129007663060818e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 126 / 200: avg. loss of last epoch 6.690704276261379e-05\n",
            "avg. grad_norm of last epoch 4.075216381873732e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 127 / 200: avg. loss of last epoch 6.63604814859961e-05\n",
            "avg. grad_norm of last epoch 4.120488560109831e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 128 / 200: avg. loss of last epoch 6.581522694129187e-05\n",
            "avg. grad_norm of last epoch 3.9217157605411056e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 129 / 200: avg. loss of last epoch 6.520159204374072e-05\n",
            "avg. grad_norm of last epoch 3.87531924639376e-05\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 130 / 200: avg. loss of last epoch 6.474228342704012e-05\n",
            "avg. grad_norm of last epoch 3.87706229881994e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 131 / 200: avg. loss of last epoch 6.419328616733164e-05\n",
            "avg. grad_norm of last epoch 3.800003825888832e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 132 / 200: avg. loss of last epoch 6.37255676735852e-05\n",
            "avg. grad_norm of last epoch 3.7849665871294365e-05\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 133 / 200: avg. loss of last epoch 6.33586830857287e-05\n",
            "avg. grad_norm of last epoch 3.6923047951147256e-05\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 134 / 200: avg. loss of last epoch 6.290336822178995e-05\n",
            "avg. grad_norm of last epoch 3.728834434595875e-05\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 135 / 200: avg. loss of last epoch 6.243314509192712e-05\n",
            "avg. grad_norm of last epoch 3.583440466955021e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 136 / 200: avg. loss of last epoch 6.20305801887298e-05\n",
            "avg. grad_norm of last epoch 3.550717261632962e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 137 / 200: avg. loss of last epoch 6.159900611091873e-05\n",
            "avg. grad_norm of last epoch 3.412184660659636e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 138 / 200: avg. loss of last epoch 6.130371559702317e-05\n",
            "avg. grad_norm of last epoch 3.494705146176087e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 139 / 200: avg. loss of last epoch 6.091118583353816e-05\n",
            "avg. grad_norm of last epoch 3.418671029884391e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 140 / 200: avg. loss of last epoch 6.055380146572134e-05\n",
            "avg. grad_norm of last epoch 3.291811702565277e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 141 / 200: avg. loss of last epoch 6.0258106122879966e-05\n",
            "avg. grad_norm of last epoch 3.466306698154278e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 142 / 200: avg. loss of last epoch 5.993117466956994e-05\n",
            "avg. grad_norm of last epoch 3.308080583860896e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 143 / 200: avg. loss of last epoch 5.960742137588871e-05\n",
            "avg. grad_norm of last epoch 3.225562920336463e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 144 / 200: avg. loss of last epoch 5.936697477688236e-05\n",
            "avg. grad_norm of last epoch 3.291440777438717e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 145 / 200: avg. loss of last epoch 5.9079851605929406e-05\n",
            "avg. grad_norm of last epoch 3.215866579137066e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 146 / 200: avg. loss of last epoch 5.882962174073326e-05\n",
            "avg. grad_norm of last epoch 3.24194424577985e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 147 / 200: avg. loss of last epoch 5.8549159418907916e-05\n",
            "avg. grad_norm of last epoch 3.1915366128590846e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 148 / 200: avg. loss of last epoch 5.829041984300909e-05\n",
            "avg. grad_norm of last epoch 3.045561649798196e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 149 / 200: avg. loss of last epoch 5.80555598945163e-05\n",
            "avg. grad_norm of last epoch 3.045754424411319e-05\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 150 / 200: avg. loss of last epoch 5.786479128049298e-05\n",
            "avg. grad_norm of last epoch 3.137150886591323e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 151 / 200: avg. loss of last epoch 5.762933156608296e-05\n",
            "avg. grad_norm of last epoch 3.0213153578435956e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 152 / 200: avg. loss of last epoch 5.7440373712840187e-05\n",
            "avg. grad_norm of last epoch 3.0067455635975115e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 153 / 200: avg. loss of last epoch 5.721683342708278e-05\n",
            "avg. grad_norm of last epoch 2.9907548006978863e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 154 / 200: avg. loss of last epoch 5.7056068769694966e-05\n",
            "avg. grad_norm of last epoch 2.9640493953799664e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 155 / 200: avg. loss of last epoch 5.6881387197548356e-05\n",
            "avg. grad_norm of last epoch 3.030744760380371e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 156 / 200: avg. loss of last epoch 5.671304072020577e-05\n",
            "avg. grad_norm of last epoch 2.936756261991113e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 157 / 200: avg. loss of last epoch 5.655513835178381e-05\n",
            "avg. grad_norm of last epoch 2.9429481062407868e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 158 / 200: avg. loss of last epoch 5.6414300171309174e-05\n",
            "avg. grad_norm of last epoch 2.986372965602434e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 159 / 200: avg. loss of last epoch 5.625356330322874e-05\n",
            "avg. grad_norm of last epoch 2.900551116428727e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 160 / 200: avg. loss of last epoch 5.610684668790782e-05\n",
            "avg. grad_norm of last epoch 2.894917534254027e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 161 / 200: avg. loss of last epoch 5.598504675872389e-05\n",
            "avg. grad_norm of last epoch 2.854333282557007e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 162 / 200: avg. loss of last epoch 5.587498742728106e-05\n",
            "avg. grad_norm of last epoch 2.941492954627556e-05\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 163 / 200: avg. loss of last epoch 5.574719956881988e-05\n",
            "avg. grad_norm of last epoch 2.856774475614516e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 164 / 200: avg. loss of last epoch 5.563859456451611e-05\n",
            "avg. grad_norm of last epoch 2.8190799977122712e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 165 / 200: avg. loss of last epoch 5.553082930321886e-05\n",
            "avg. grad_norm of last epoch 2.827177200612978e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 166 / 200: avg. loss of last epoch 5.543819533971452e-05\n",
            "avg. grad_norm of last epoch 2.8407809182325767e-05\n",
            "Current train acc: 100.0%, test acc: 89.75%\n",
            "Epoch 167 / 200: avg. loss of last epoch 5.534149189964709e-05\n",
            "avg. grad_norm of last epoch 2.831930144915051e-05\n",
            "Current train acc: 100.0%, test acc: 89.73%\n",
            "Epoch 168 / 200: avg. loss of last epoch 5.526075218707169e-05\n",
            "avg. grad_norm of last epoch 2.8041750258360797e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 169 / 200: avg. loss of last epoch 5.517240054274831e-05\n",
            "avg. grad_norm of last epoch 2.7614017146465583e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 170 / 200: avg. loss of last epoch 5.50939054626118e-05\n",
            "avg. grad_norm of last epoch 2.7772785264842566e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 171 / 200: avg. loss of last epoch 5.5032841526068865e-05\n",
            "avg. grad_norm of last epoch 2.827538735871941e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 172 / 200: avg. loss of last epoch 5.495955366156219e-05\n",
            "avg. grad_norm of last epoch 2.751298709986912e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 173 / 200: avg. loss of last epoch 5.490193308602703e-05\n",
            "avg. grad_norm of last epoch 2.7481828198183106e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 174 / 200: avg. loss of last epoch 5.484469398070358e-05\n",
            "avg. grad_norm of last epoch 2.7585926108436115e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 175 / 200: avg. loss of last epoch 5.479066439681147e-05\n",
            "avg. grad_norm of last epoch 2.7343918314972522e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 176 / 200: avg. loss of last epoch 5.47404148843877e-05\n",
            "avg. grad_norm of last epoch 2.76037133961927e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 177 / 200: avg. loss of last epoch 5.470132297511254e-05\n",
            "avg. grad_norm of last epoch 2.758919400497733e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 178 / 200: avg. loss of last epoch 5.465647771440369e-05\n",
            "avg. grad_norm of last epoch 2.693807955877075e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 179 / 200: avg. loss of last epoch 5.4618028633315904e-05\n",
            "avg. grad_norm of last epoch 2.7154721953428424e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 180 / 200: avg. loss of last epoch 5.458585035521538e-05\n",
            "avg. grad_norm of last epoch 2.6992046976226984e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 181 / 200: avg. loss of last epoch 5.455482249332519e-05\n",
            "avg. grad_norm of last epoch 2.7291559807615747e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 182 / 200: avg. loss of last epoch 5.452798103797244e-05\n",
            "avg. grad_norm of last epoch 2.7274650009222523e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 183 / 200: avg. loss of last epoch 5.450371418070668e-05\n",
            "avg. grad_norm of last epoch 2.707556809161108e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 184 / 200: avg. loss of last epoch 5.448087898597204e-05\n",
            "avg. grad_norm of last epoch 2.6507239082833367e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 185 / 200: avg. loss of last epoch 5.446193428336605e-05\n",
            "avg. grad_norm of last epoch 2.7159481387069064e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 186 / 200: avg. loss of last epoch 5.444529463517633e-05\n",
            "avg. grad_norm of last epoch 2.691234949759823e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 187 / 200: avg. loss of last epoch 5.4430147275949525e-05\n",
            "avg. grad_norm of last epoch 2.719467135932382e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 188 / 200: avg. loss of last epoch 5.441706089574537e-05\n",
            "avg. grad_norm of last epoch 2.7259598424506666e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 189 / 200: avg. loss of last epoch 5.440544927308413e-05\n",
            "avg. grad_norm of last epoch 2.628821178165019e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 190 / 200: avg. loss of last epoch 5.439707922420593e-05\n",
            "avg. grad_norm of last epoch 2.7125308226875323e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 191 / 200: avg. loss of last epoch 5.438903234074436e-05\n",
            "avg. grad_norm of last epoch 2.6744379083190663e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 192 / 200: avg. loss of last epoch 5.438238801192106e-05\n",
            "avg. grad_norm of last epoch 2.6994596168779524e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 193 / 200: avg. loss of last epoch 5.43772901408374e-05\n",
            "avg. grad_norm of last epoch 2.6851424832994597e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 194 / 200: avg. loss of last epoch 5.4373186959613436e-05\n",
            "avg. grad_norm of last epoch 2.7218262151996335e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 195 / 200: avg. loss of last epoch 5.437000808936622e-05\n",
            "avg. grad_norm of last epoch 2.7232974291432555e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 196 / 200: avg. loss of last epoch 5.436766985803845e-05\n",
            "avg. grad_norm of last epoch 2.6209498505388227e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 197 / 200: avg. loss of last epoch 5.436619609245105e-05\n",
            "avg. grad_norm of last epoch 2.659348589266826e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 198 / 200: avg. loss of last epoch 5.436514169171766e-05\n",
            "avg. grad_norm of last epoch 2.693451730700455e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 199 / 200: avg. loss of last epoch 5.436472233074404e-05\n",
            "avg. grad_norm of last epoch 2.5772266956832152e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 200 / 200: avg. loss of last epoch 5.4364724725019156e-05\n",
            "avg. grad_norm of last epoch 2.650271529233359e-05\n",
            "Current train acc: 100.0%, test acc: 89.74%\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epoch_count = 200\n",
        "\n",
        "scheduler = cosine_learning_rate_scheduler(0.2, epoch_count)\n",
        "\n",
        "# beta is proposed in paper and epoch_count is inferred from the graphs\n",
        "history = SMG_train(model, criterion, epoch_count, fashion_train_loader, fashion_test_loader, \n",
        "                    scheduler, beta=0.5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIjFJ4ksp41j"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/SMG-Fashion-History/SMG_CosineLR.json\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Bdw0uIk1p9IF",
        "outputId": "cfe12d90-8156-4e37-faec-f175896c3264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f42eb64e890>]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_norm_square_grad(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5hXrGcp4DjH"
      },
      "source": [
        "# 2- Train Other Models and Compare over SMG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hoJ2dww4HL0"
      },
      "source": [
        "## Training with Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA5Ge3jJ4G5K",
        "outputId": "f8f07e5b-a478-4640-81ec-9923c411be95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.48673670961062077\n",
            "Epoch 1 / 200: avg. grad_norm of last epoch 4.26902308308329\n",
            "Current train acc: 86.565%, test acc: 84.89%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.3453824382623037\n",
            "Epoch 2 / 200: avg. grad_norm of last epoch 1.7487252241015345\n",
            "Current train acc: 88.24166666666666%, test acc: 86.36%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.3066909615993498\n",
            "Epoch 3 / 200: avg. grad_norm of last epoch 1.4216633813913202\n",
            "Current train acc: 89.49%, test acc: 87.12%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.2856005764166516\n",
            "Epoch 4 / 200: avg. grad_norm of last epoch 1.25135683471796\n",
            "Current train acc: 89.815%, test acc: 87.28%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.26643116269111633\n",
            "Epoch 5 / 200: avg. grad_norm of last epoch 1.1628374063389804\n",
            "Current train acc: 90.575%, test acc: 87.74%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.2494454373995463\n",
            "Epoch 6 / 200: avg. grad_norm of last epoch 1.015888019488301\n",
            "Current train acc: 91.55666666666667%, test acc: 88.33%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.23889825722376512\n",
            "Epoch 7 / 200: avg. grad_norm of last epoch 1.051600375188032\n",
            "Current train acc: 91.75833333333334%, test acc: 88.21%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.22379357542991637\n",
            "Epoch 8 / 200: avg. grad_norm of last epoch 0.9829593368255393\n",
            "Current train acc: 92.24333333333334%, test acc: 88.47%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.2140942257324855\n",
            "Epoch 9 / 200: avg. grad_norm of last epoch 1.001517185518867\n",
            "Current train acc: 92.09333333333333%, test acc: 88.39%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.20322702444394422\n",
            "Epoch 10 / 200: avg. grad_norm of last epoch 0.9600468689592517\n",
            "Current train acc: 92.56166666666667%, test acc: 88.42%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.1934442209561666\n",
            "Epoch 11 / 200: avg. grad_norm of last epoch 0.9248525456513635\n",
            "Current train acc: 93.38666666666667%, test acc: 89.03%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.18268370593388872\n",
            "Epoch 12 / 200: avg. grad_norm of last epoch 0.8610411165754471\n",
            "Current train acc: 93.625%, test acc: 88.9%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.1754592172225318\n",
            "Epoch 13 / 200: avg. grad_norm of last epoch 0.8690961257385931\n",
            "Current train acc: 93.93333333333334%, test acc: 88.87%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.16481022294362385\n",
            "Epoch 14 / 200: avg. grad_norm of last epoch 0.8613405236597991\n",
            "Current train acc: 94.02%, test acc: 88.64%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.16009495034217816\n",
            "Epoch 15 / 200: avg. grad_norm of last epoch 0.8748440785643691\n",
            "Current train acc: 94.70333333333333%, test acc: 89.42%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.1541001615087191\n",
            "Epoch 16 / 200: avg. grad_norm of last epoch 0.895009425829675\n",
            "Current train acc: 94.73666666666666%, test acc: 89.12%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.14652893574635198\n",
            "Epoch 17 / 200: avg. grad_norm of last epoch 0.8610986307834496\n",
            "Current train acc: 95.00333333333333%, test acc: 89.06%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.1444465400377908\n",
            "Epoch 18 / 200: avg. grad_norm of last epoch 0.8744542925643684\n",
            "Current train acc: 95.10833333333333%, test acc: 89.0%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.13707692418098455\n",
            "Epoch 19 / 200: avg. grad_norm of last epoch 0.8519329762098353\n",
            "Current train acc: 94.98666666666666%, test acc: 89.15%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.12936690584421165\n",
            "Epoch 20 / 200: avg. grad_norm of last epoch 0.8152730641114307\n",
            "Current train acc: 95.34666666666666%, test acc: 89.07%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.12413557814359667\n",
            "Epoch 21 / 200: avg. grad_norm of last epoch 0.8028454461077347\n",
            "Current train acc: 95.68666666666667%, test acc: 89.22%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.12438443303902945\n",
            "Epoch 22 / 200: avg. grad_norm of last epoch 0.8913018349451529\n",
            "Current train acc: 94.88833333333334%, test acc: 88.76%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.11694766723314934\n",
            "Epoch 23 / 200: avg. grad_norm of last epoch 0.789300588642604\n",
            "Current train acc: 95.71%, test acc: 89.11%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.11852997427781427\n",
            "Epoch 24 / 200: avg. grad_norm of last epoch 0.8993223275859794\n",
            "Current train acc: 95.595%, test acc: 89.23%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.11130432433287299\n",
            "Epoch 25 / 200: avg. grad_norm of last epoch 0.823765759393886\n",
            "Current train acc: 96.01666666666667%, test acc: 88.92%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.10995647061665859\n",
            "Epoch 26 / 200: avg. grad_norm of last epoch 0.8560209771407469\n",
            "Current train acc: 96.11%, test acc: 89.01%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.10371549828449896\n",
            "Epoch 27 / 200: avg. grad_norm of last epoch 0.8095968130468569\n",
            "Current train acc: 96.87166666666667%, test acc: 89.16%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.09770235437949498\n",
            "Epoch 28 / 200: avg. grad_norm of last epoch 0.7794906495380236\n",
            "Current train acc: 96.245%, test acc: 88.95%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.09442334455847748\n",
            "Epoch 29 / 200: avg. grad_norm of last epoch 0.7368890522396215\n",
            "Current train acc: 96.705%, test acc: 89.52%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.09129630810022347\n",
            "Epoch 30 / 200: avg. grad_norm of last epoch 0.7542011225390969\n",
            "Current train acc: 96.27166666666666%, test acc: 88.86%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.09341348214149481\n",
            "Epoch 31 / 200: avg. grad_norm of last epoch 0.8623801765287099\n",
            "Current train acc: 96.305%, test acc: 88.84%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.09510825754006705\n",
            "Epoch 32 / 200: avg. grad_norm of last epoch 0.8781460382896087\n",
            "Current train acc: 97.31333333333333%, test acc: 89.21%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.08264024974703786\n",
            "Epoch 33 / 200: avg. grad_norm of last epoch 0.7399005085002329\n",
            "Current train acc: 97.42833333333333%, test acc: 89.62%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.07904950347940139\n",
            "Epoch 34 / 200: avg. grad_norm of last epoch 0.7174857438257515\n",
            "Current train acc: 96.91333333333333%, test acc: 89.27%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.08695739151636757\n",
            "Epoch 35 / 200: avg. grad_norm of last epoch 0.8813718951763715\n",
            "Current train acc: 96.915%, test acc: 88.82%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.07911759505867952\n",
            "Epoch 36 / 200: avg. grad_norm of last epoch 0.760799060720327\n",
            "Current train acc: 97.35166666666667%, test acc: 89.37%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.07636841479341198\n",
            "Epoch 37 / 200: avg. grad_norm of last epoch 0.7669346021301484\n",
            "Current train acc: 97.38333333333334%, test acc: 89.57%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.06835905625621476\n",
            "Epoch 38 / 200: avg. grad_norm of last epoch 0.6869117538620803\n",
            "Current train acc: 97.33333333333333%, test acc: 89.26%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.0737775429974\n",
            "Epoch 39 / 200: avg. grad_norm of last epoch 0.7778687204717243\n",
            "Current train acc: 97.54833333333333%, test acc: 89.09%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.07395536701281867\n",
            "Epoch 40 / 200: avg. grad_norm of last epoch 0.8545841873107999\n",
            "Current train acc: 97.38666666666667%, test acc: 88.76%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.06544651767810186\n",
            "Epoch 41 / 200: avg. grad_norm of last epoch 0.6742421267649318\n",
            "Current train acc: 97.86666666666666%, test acc: 89.22%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.06635971304376916\n",
            "Epoch 42 / 200: avg. grad_norm of last epoch 0.754248777278047\n",
            "Current train acc: 97.50833333333334%, test acc: 88.7%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.06648130100568136\n",
            "Epoch 43 / 200: avg. grad_norm of last epoch 0.7874087166378007\n",
            "Current train acc: 97.655%, test acc: 89.19%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.06629983623822526\n",
            "Epoch 44 / 200: avg. grad_norm of last epoch 0.7683784563457754\n",
            "Current train acc: 97.10666666666667%, test acc: 89.01%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.06189885962307448\n",
            "Epoch 45 / 200: avg. grad_norm of last epoch 0.7186253767144074\n",
            "Current train acc: 97.83666666666667%, test acc: 89.26%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.05745267698963487\n",
            "Epoch 46 / 200: avg. grad_norm of last epoch 0.6871999949254011\n",
            "Current train acc: 97.865%, test acc: 89.25%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.06359128228425975\n",
            "Epoch 47 / 200: avg. grad_norm of last epoch 0.7888726031910586\n",
            "Current train acc: 97.46166666666667%, test acc: 88.88%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.06002877105077104\n",
            "Epoch 48 / 200: avg. grad_norm of last epoch 0.7337913563978098\n",
            "Current train acc: 98.385%, test acc: 89.37%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.06170167748332021\n",
            "Epoch 49 / 200: avg. grad_norm of last epoch 0.8978829012610813\n",
            "Current train acc: 98.435%, test acc: 89.44%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.05860100657790905\n",
            "Epoch 50 / 200: avg. grad_norm of last epoch 0.823495011117885\n",
            "Current train acc: 97.78666666666666%, test acc: 89.27%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.0584187038610379\n",
            "Epoch 51 / 200: avg. grad_norm of last epoch 0.8279822033660533\n",
            "Current train acc: 97.42833333333333%, test acc: 89.31%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.05549801851958036\n",
            "Epoch 52 / 200: avg. grad_norm of last epoch 0.7461943258984806\n",
            "Current train acc: 97.87666666666667%, test acc: 89.15%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.05400103280742965\n",
            "Epoch 53 / 200: avg. grad_norm of last epoch 0.7515313986673647\n",
            "Current train acc: 98.42666666666666%, test acc: 89.45%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.048338948045174294\n",
            "Epoch 54 / 200: avg. grad_norm of last epoch 0.6612258024783768\n",
            "Current train acc: 97.77666666666667%, test acc: 89.08%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.053712312509616195\n",
            "Epoch 55 / 200: avg. grad_norm of last epoch 0.7826429834995718\n",
            "Current train acc: 97.76833333333333%, test acc: 88.98%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.0509259873608748\n",
            "Epoch 56 / 200: avg. grad_norm of last epoch 0.7515019520705029\n",
            "Current train acc: 98.07%, test acc: 89.55%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.04653195331891376\n",
            "Epoch 57 / 200: avg. grad_norm of last epoch 0.6575322589078648\n",
            "Current train acc: 97.99666666666667%, test acc: 89.23%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.05224584980805712\n",
            "Epoch 58 / 200: avg. grad_norm of last epoch 0.7895284116848856\n",
            "Current train acc: 97.98333333333333%, test acc: 89.05%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.04971140934526917\n",
            "Epoch 59 / 200: avg. grad_norm of last epoch 0.808892963633923\n",
            "Current train acc: 98.3%, test acc: 89.2%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.04432469376921656\n",
            "Epoch 60 / 200: avg. grad_norm of last epoch 0.64022024632958\n",
            "Current train acc: 98.02833333333334%, test acc: 88.65%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.04615205664336682\n",
            "Epoch 61 / 200: avg. grad_norm of last epoch 0.7401367864772135\n",
            "Current train acc: 97.79333333333334%, test acc: 88.73%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.04519354976614315\n",
            "Epoch 62 / 200: avg. grad_norm of last epoch 0.7582263912269486\n",
            "Current train acc: 98.23666666666666%, test acc: 88.86%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.04225433669288959\n",
            "Epoch 63 / 200: avg. grad_norm of last epoch 0.6596460252846612\n",
            "Current train acc: 98.725%, test acc: 89.34%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.05440480399926506\n",
            "Epoch 64 / 200: avg. grad_norm of last epoch 0.9878500371170161\n",
            "Current train acc: 98.045%, test acc: 89.1%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.03873888959636291\n",
            "Epoch 65 / 200: avg. grad_norm of last epoch 0.6504961816071537\n",
            "Current train acc: 98.48166666666667%, test acc: 89.14%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.045629393980403714\n",
            "Epoch 66 / 200: avg. grad_norm of last epoch 0.8012708823980954\n",
            "Current train acc: 98.28333333333333%, test acc: 89.13%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.0402323911433419\n",
            "Epoch 67 / 200: avg. grad_norm of last epoch 0.6596514805450128\n",
            "Current train acc: 98.59833333333333%, test acc: 89.21%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.041334432060519836\n",
            "Epoch 68 / 200: avg. grad_norm of last epoch 0.7225097271133688\n",
            "Current train acc: 99.155%, test acc: 89.35%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.03553500172346832\n",
            "Epoch 69 / 200: avg. grad_norm of last epoch 0.6185569389173888\n",
            "Current train acc: 98.57833333333333%, test acc: 89.21%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.04334383977303906\n",
            "Epoch 70 / 200: avg. grad_norm of last epoch 0.7677427801548101\n",
            "Current train acc: 98.74666666666667%, test acc: 88.98%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.03653798480468492\n",
            "Epoch 71 / 200: avg. grad_norm of last epoch 0.6290005539621057\n",
            "Current train acc: 98.60666666666667%, test acc: 89.19%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.04105721991012491\n",
            "Epoch 72 / 200: avg. grad_norm of last epoch 0.7400792816104826\n",
            "Current train acc: 98.83166666666666%, test acc: 89.29%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.0374026430080334\n",
            "Epoch 73 / 200: avg. grad_norm of last epoch 0.6979798710572687\n",
            "Current train acc: 98.65%, test acc: 88.89%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.036802345466117055\n",
            "Epoch 74 / 200: avg. grad_norm of last epoch 0.6967777925134679\n",
            "Current train acc: 98.96%, test acc: 89.38%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.03856867989562458\n",
            "Epoch 75 / 200: avg. grad_norm of last epoch 0.7373508403127567\n",
            "Current train acc: 98.61666666666666%, test acc: 89.1%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.03051213670447469\n",
            "Epoch 76 / 200: avg. grad_norm of last epoch 0.5588460338213385\n",
            "Current train acc: 98.635%, test acc: 89.65%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.039245312111576364\n",
            "Epoch 77 / 200: avg. grad_norm of last epoch 0.8035330782293537\n",
            "Current train acc: 98.70833333333333%, test acc: 89.35%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.04092525122563042\n",
            "Epoch 78 / 200: avg. grad_norm of last epoch 0.789197028557105\n",
            "Current train acc: 98.5%, test acc: 89.06%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.03197829772233962\n",
            "Epoch 79 / 200: avg. grad_norm of last epoch 0.6064358850897958\n",
            "Current train acc: 99.04166666666667%, test acc: 89.15%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.03078011315688489\n",
            "Epoch 80 / 200: avg. grad_norm of last epoch 0.5595290965168856\n",
            "Current train acc: 98.465%, test acc: 89.15%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.04181661527256167\n",
            "Epoch 81 / 200: avg. grad_norm of last epoch 0.8365316222569797\n",
            "Current train acc: 98.36%, test acc: 88.81%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.03313533823639157\n",
            "Epoch 82 / 200: avg. grad_norm of last epoch 0.6485083956311511\n",
            "Current train acc: 98.40166666666667%, test acc: 88.87%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.03328020063688358\n",
            "Epoch 83 / 200: avg. grad_norm of last epoch 0.6997397073152305\n",
            "Current train acc: 98.56666666666666%, test acc: 88.95%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.031718033974866076\n",
            "Epoch 84 / 200: avg. grad_norm of last epoch 0.6411061850189801\n",
            "Current train acc: 98.86666666666666%, test acc: 88.91%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.02941141222367684\n",
            "Epoch 85 / 200: avg. grad_norm of last epoch 0.5622364628168585\n",
            "Current train acc: 98.405%, test acc: 89.42%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.0425792249699434\n",
            "Epoch 86 / 200: avg. grad_norm of last epoch 0.984993435778128\n",
            "Current train acc: 98.62166666666667%, test acc: 88.92%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.031862562203407316\n",
            "Epoch 87 / 200: avg. grad_norm of last epoch 0.7025409345357894\n",
            "Current train acc: 99.175%, test acc: 89.1%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.02688854230766498\n",
            "Epoch 88 / 200: avg. grad_norm of last epoch 0.5451599274568123\n",
            "Current train acc: 98.87666666666667%, test acc: 89.28%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.033044331717242796\n",
            "Epoch 89 / 200: avg. grad_norm of last epoch 0.7179905588528541\n",
            "Current train acc: 99.065%, test acc: 89.16%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.0323636736549437\n",
            "Epoch 90 / 200: avg. grad_norm of last epoch 0.7398729473665416\n",
            "Current train acc: 99.05666666666667%, test acc: 89.48%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.02843783737930158\n",
            "Epoch 91 / 200: avg. grad_norm of last epoch 0.606245570553767\n",
            "Current train acc: 98.85%, test acc: 89.4%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.03340572266156478\n",
            "Epoch 92 / 200: avg. grad_norm of last epoch 0.7196929400020848\n",
            "Current train acc: 99.35%, test acc: 89.78%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.03162422017405427\n",
            "Epoch 93 / 200: avg. grad_norm of last epoch 0.7015987939874172\n",
            "Current train acc: 99.10833333333333%, test acc: 89.47%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.03012333643014233\n",
            "Epoch 94 / 200: avg. grad_norm of last epoch 0.692930880757765\n",
            "Current train acc: 99.09833333333333%, test acc: 89.53%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.0247146449457854\n",
            "Epoch 95 / 200: avg. grad_norm of last epoch 0.5918636893334825\n",
            "Current train acc: 98.84666666666666%, test acc: 89.6%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.03083625859022141\n",
            "Epoch 96 / 200: avg. grad_norm of last epoch 0.6694701602976272\n",
            "Current train acc: 99.35333333333334%, test acc: 89.17%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.027794981223344783\n",
            "Epoch 97 / 200: avg. grad_norm of last epoch 0.6086244862352462\n",
            "Current train acc: 99.11333333333333%, test acc: 89.25%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.032160885472595706\n",
            "Epoch 98 / 200: avg. grad_norm of last epoch 0.7779385758858096\n",
            "Current train acc: 99.09166666666667%, test acc: 88.99%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.03183800872998933\n",
            "Epoch 99 / 200: avg. grad_norm of last epoch 0.7095248055003714\n",
            "Current train acc: 98.945%, test acc: 88.98%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.019331418683752422\n",
            "Epoch 100 / 200: avg. grad_norm of last epoch 0.4145386680120301\n",
            "Current train acc: 99.41666666666667%, test acc: 89.26%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.024185051922717447\n",
            "Epoch 101 / 200: avg. grad_norm of last epoch 0.5441390198771806\n",
            "Current train acc: 98.55166666666666%, test acc: 89.46%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.03976631644020479\n",
            "Epoch 102 / 200: avg. grad_norm of last epoch 0.9385180284699786\n",
            "Current train acc: 99.215%, test acc: 89.39%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.0216391802251339\n",
            "Epoch 103 / 200: avg. grad_norm of last epoch 0.47498856081693025\n",
            "Current train acc: 98.785%, test acc: 88.99%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.026759384512218327\n",
            "Epoch 104 / 200: avg. grad_norm of last epoch 0.6359296102509124\n",
            "Current train acc: 99.12333333333333%, test acc: 89.38%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.03660873386257639\n",
            "Epoch 105 / 200: avg. grad_norm of last epoch 0.9197119985934334\n",
            "Current train acc: 98.98833333333333%, test acc: 89.43%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.023794924046720067\n",
            "Epoch 106 / 200: avg. grad_norm of last epoch 0.5935743824519736\n",
            "Current train acc: 99.17%, test acc: 89.3%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.022657418557753193\n",
            "Epoch 107 / 200: avg. grad_norm of last epoch 0.555562469419093\n",
            "Current train acc: 99.035%, test acc: 88.98%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.03536888133635126\n",
            "Epoch 108 / 200: avg. grad_norm of last epoch 0.8705257123135474\n",
            "Current train acc: 98.58833333333334%, test acc: 88.75%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.029719542463372158\n",
            "Epoch 109 / 200: avg. grad_norm of last epoch 0.7554784056522005\n",
            "Current train acc: 99.06833333333333%, test acc: 89.32%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.01874525250357886\n",
            "Epoch 110 / 200: avg. grad_norm of last epoch 0.4188453059591073\n",
            "Current train acc: 99.08166666666666%, test acc: 89.26%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.02429516227087003\n",
            "Epoch 111 / 200: avg. grad_norm of last epoch 0.579713653519635\n",
            "Current train acc: 98.93166666666667%, test acc: 89.12%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.032746262062216806\n",
            "Epoch 112 / 200: avg. grad_norm of last epoch 0.8921806063427353\n",
            "Current train acc: 99.18333333333334%, test acc: 89.23%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.02468595827526103\n",
            "Epoch 113 / 200: avg. grad_norm of last epoch 0.6060448143154442\n",
            "Current train acc: 99.35166666666667%, test acc: 89.27%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.0159410752263541\n",
            "Epoch 114 / 200: avg. grad_norm of last epoch 0.3628499433144305\n",
            "Current train acc: 99.69333333333333%, test acc: 89.59%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.02386228006972621\n",
            "Epoch 115 / 200: avg. grad_norm of last epoch 0.5788014989597993\n",
            "Current train acc: 99.04166666666667%, test acc: 89.23%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.02267090762834995\n",
            "Epoch 116 / 200: avg. grad_norm of last epoch 0.543956670164661\n",
            "Current train acc: 99.38333333333334%, test acc: 89.54%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.026759071579327172\n",
            "Epoch 117 / 200: avg. grad_norm of last epoch 0.6780442312290405\n",
            "Current train acc: 99.15833333333333%, test acc: 89.26%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.02209674842498109\n",
            "Epoch 118 / 200: avg. grad_norm of last epoch 0.57127776782393\n",
            "Current train acc: 99.295%, test acc: 89.52%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.026745253976372403\n",
            "Epoch 119 / 200: avg. grad_norm of last epoch 0.6913637355452373\n",
            "Current train acc: 99.40833333333333%, test acc: 89.41%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.02025270036344106\n",
            "Epoch 120 / 200: avg. grad_norm of last epoch 0.5107834787757787\n",
            "Current train acc: 99.43%, test acc: 89.2%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.024763783646747466\n",
            "Epoch 121 / 200: avg. grad_norm of last epoch 0.6713078128398877\n",
            "Current train acc: 98.935%, test acc: 89.16%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.030168395946919946\n",
            "Epoch 122 / 200: avg. grad_norm of last epoch 0.8572766972840985\n",
            "Current train acc: 99.39%, test acc: 89.47%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.017422599617671224\n",
            "Epoch 123 / 200: avg. grad_norm of last epoch 0.4588575607333276\n",
            "Current train acc: 99.46%, test acc: 89.31%\n",
            "Epoch 124 / 200: avg. loss of last epoch 0.012294248076031612\n",
            "Epoch 124 / 200: avg. grad_norm of last epoch 0.2995551057373458\n",
            "Current train acc: 99.39%, test acc: 89.25%\n",
            "Epoch 125 / 200: avg. loss of last epoch 0.043149301034181055\n",
            "Epoch 125 / 200: avg. grad_norm of last epoch 1.1945582363218155\n",
            "Current train acc: 98.935%, test acc: 88.97%\n",
            "Epoch 126 / 200: avg. loss of last epoch 0.0195844212030371\n",
            "Epoch 126 / 200: avg. grad_norm of last epoch 0.5069406662893469\n",
            "Current train acc: 99.67666666666666%, test acc: 89.52%\n",
            "Epoch 127 / 200: avg. loss of last epoch 0.012062761595224345\n",
            "Epoch 127 / 200: avg. grad_norm of last epoch 0.3208119286749586\n",
            "Current train acc: 99.40333333333334%, test acc: 89.31%\n",
            "Epoch 128 / 200: avg. loss of last epoch 0.03338184293135998\n",
            "Epoch 128 / 200: avg. grad_norm of last epoch 0.9245471037391344\n",
            "Current train acc: 99.295%, test acc: 89.39%\n",
            "Epoch 129 / 200: avg. loss of last epoch 0.022572551955903547\n",
            "Epoch 129 / 200: avg. grad_norm of last epoch 0.5974220870132524\n",
            "Current train acc: 99.5%, test acc: 89.53%\n",
            "Epoch 130 / 200: avg. loss of last epoch 0.015147938805523656\n",
            "Epoch 130 / 200: avg. grad_norm of last epoch 0.386423501825302\n",
            "Current train acc: 99.37666666666667%, test acc: 89.52%\n",
            "Epoch 131 / 200: avg. loss of last epoch 0.03369473223478221\n",
            "Epoch 131 / 200: avg. grad_norm of last epoch 0.9727826395697287\n",
            "Current train acc: 99.4%, test acc: 89.12%\n",
            "Epoch 132 / 200: avg. loss of last epoch 0.01969702937637145\n",
            "Epoch 132 / 200: avg. grad_norm of last epoch 0.5296915210314889\n",
            "Current train acc: 99.45833333333333%, test acc: 89.76%\n",
            "Epoch 133 / 200: avg. loss of last epoch 0.01978452962526739\n",
            "Epoch 133 / 200: avg. grad_norm of last epoch 0.5443995022578636\n",
            "Current train acc: 98.79166666666667%, test acc: 89.3%\n",
            "Epoch 134 / 200: avg. loss of last epoch 0.027041686898407833\n",
            "Epoch 134 / 200: avg. grad_norm of last epoch 0.7244232074063004\n",
            "Current train acc: 99.27666666666667%, test acc: 89.24%\n",
            "Epoch 135 / 200: avg. loss of last epoch 0.029338077587013456\n",
            "Epoch 135 / 200: avg. grad_norm of last epoch 0.8741886022674736\n",
            "Current train acc: 99.51%, test acc: 89.35%\n",
            "Epoch 136 / 200: avg. loss of last epoch 0.01149656766137729\n",
            "Epoch 136 / 200: avg. grad_norm of last epoch 0.306207479116278\n",
            "Current train acc: 99.25%, test acc: 89.49%\n",
            "Epoch 137 / 200: avg. loss of last epoch 0.019392014456850792\n",
            "Epoch 137 / 200: avg. grad_norm of last epoch 0.512676488487659\n",
            "Current train acc: 99.32666666666667%, test acc: 89.28%\n",
            "Epoch 138 / 200: avg. loss of last epoch 0.029953028830327067\n",
            "Epoch 138 / 200: avg. grad_norm of last epoch 0.7935532186065539\n",
            "Current train acc: 99.40333333333334%, test acc: 89.35%\n",
            "Epoch 139 / 200: avg. loss of last epoch 0.012185926307908568\n",
            "Epoch 139 / 200: avg. grad_norm of last epoch 0.32080148869261393\n",
            "Current train acc: 99.34333333333333%, test acc: 89.05%\n",
            "Epoch 140 / 200: avg. loss of last epoch 0.02304354543127119\n",
            "Epoch 140 / 200: avg. grad_norm of last epoch 0.6071234536239148\n",
            "Current train acc: 99.72166666666666%, test acc: 89.5%\n",
            "Epoch 141 / 200: avg. loss of last epoch 0.017042233336747932\n",
            "Epoch 141 / 200: avg. grad_norm of last epoch 0.4853985087815266\n",
            "Current train acc: 98.84%, test acc: 88.72%\n",
            "Epoch 142 / 200: avg. loss of last epoch 0.02809161256067455\n",
            "Epoch 142 / 200: avg. grad_norm of last epoch 0.7984143512002089\n",
            "Current train acc: 99.40166666666667%, test acc: 88.97%\n",
            "Epoch 143 / 200: avg. loss of last epoch 0.025422531120603293\n",
            "Epoch 143 / 200: avg. grad_norm of last epoch 0.7051148737398021\n",
            "Current train acc: 99.47666666666667%, test acc: 89.39%\n",
            "Epoch 144 / 200: avg. loss of last epoch 0.023409509606597316\n",
            "Epoch 144 / 200: avg. grad_norm of last epoch 0.6684089595914245\n",
            "Current train acc: 99.32833333333333%, test acc: 89.57%\n",
            "Epoch 145 / 200: avg. loss of last epoch 0.014759655887059239\n",
            "Epoch 145 / 200: avg. grad_norm of last epoch 0.4306023539163281\n",
            "Current train acc: 99.49333333333334%, test acc: 89.31%\n",
            "Epoch 146 / 200: avg. loss of last epoch 0.011563830574524273\n",
            "Epoch 146 / 200: avg. grad_norm of last epoch 0.35249265447855116\n",
            "Current train acc: 98.66333333333333%, test acc: 88.91%\n",
            "Epoch 147 / 200: avg. loss of last epoch 0.030626091035827988\n",
            "Epoch 147 / 200: avg. grad_norm of last epoch 0.9326095550702637\n",
            "Current train acc: 99.41166666666666%, test acc: 89.47%\n",
            "Epoch 148 / 200: avg. loss of last epoch 0.023093510228022914\n",
            "Epoch 148 / 200: avg. grad_norm of last epoch 0.7175251668137645\n",
            "Current train acc: 98.91333333333333%, test acc: 89.0%\n",
            "Epoch 149 / 200: avg. loss of last epoch 0.02771138987083302\n",
            "Epoch 149 / 200: avg. grad_norm of last epoch 0.8334928390743791\n",
            "Current train acc: 99.25%, test acc: 88.77%\n",
            "Epoch 150 / 200: avg. loss of last epoch 0.010319365529545273\n",
            "Epoch 150 / 200: avg. grad_norm of last epoch 0.2720474697948939\n",
            "Current train acc: 99.795%, test acc: 89.6%\n",
            "Epoch 151 / 200: avg. loss of last epoch 0.011809090156868719\n",
            "Epoch 151 / 200: avg. grad_norm of last epoch 0.32074494727610087\n",
            "Current train acc: 99.5%, test acc: 88.94%\n",
            "Epoch 152 / 200: avg. loss of last epoch 0.030287904698370654\n",
            "Epoch 152 / 200: avg. grad_norm of last epoch 0.8576416401262342\n",
            "Current train acc: 99.17166666666667%, test acc: 89.19%\n",
            "Epoch 153 / 200: avg. loss of last epoch 0.019961020242360728\n",
            "Epoch 153 / 200: avg. grad_norm of last epoch 0.5943749667050486\n",
            "Current train acc: 99.70166666666667%, test acc: 89.28%\n",
            "Epoch 154 / 200: avg. loss of last epoch 0.017767885592347005\n",
            "Epoch 154 / 200: avg. grad_norm of last epoch 0.5107016200946254\n",
            "Current train acc: 99.59666666666666%, test acc: 89.24%\n",
            "Epoch 155 / 200: avg. loss of last epoch 0.022599976226314905\n",
            "Epoch 155 / 200: avg. grad_norm of last epoch 0.6636967031565545\n",
            "Current train acc: 99.43666666666667%, test acc: 89.23%\n",
            "Epoch 156 / 200: avg. loss of last epoch 0.015310157966893171\n",
            "Epoch 156 / 200: avg. grad_norm of last epoch 0.4699666588435516\n",
            "Current train acc: 99.24166666666666%, test acc: 89.12%\n",
            "Epoch 157 / 200: avg. loss of last epoch 0.017724044889941174\n",
            "Epoch 157 / 200: avg. grad_norm of last epoch 0.5489661578348513\n",
            "Current train acc: 99.57833333333333%, test acc: 88.95%\n",
            "Epoch 158 / 200: avg. loss of last epoch 0.024355359588935945\n",
            "Epoch 158 / 200: avg. grad_norm of last epoch 0.7378001462772134\n",
            "Current train acc: 99.63%, test acc: 89.29%\n",
            "Epoch 159 / 200: avg. loss of last epoch 0.014845560420847819\n",
            "Epoch 159 / 200: avg. grad_norm of last epoch 0.43827326030055325\n",
            "Current train acc: 99.11833333333334%, test acc: 88.98%\n",
            "Epoch 160 / 200: avg. loss of last epoch 0.025022293864532055\n",
            "Epoch 160 / 200: avg. grad_norm of last epoch 0.7917166405181896\n",
            "Current train acc: 99.48666666666666%, test acc: 88.93%\n",
            "Epoch 161 / 200: avg. loss of last epoch 0.0165488300185185\n",
            "Epoch 161 / 200: avg. grad_norm of last epoch 0.4582356111375113\n",
            "Current train acc: 99.36166666666666%, test acc: 89.02%\n",
            "Epoch 162 / 200: avg. loss of last epoch 0.028163386748234435\n",
            "Epoch 162 / 200: avg. grad_norm of last epoch 0.815637663169809\n",
            "Current train acc: 98.49833333333333%, test acc: 88.37%\n",
            "Epoch 163 / 200: avg. loss of last epoch 0.01431394835695004\n",
            "Epoch 163 / 200: avg. grad_norm of last epoch 0.4021920302856233\n",
            "Current train acc: 99.515%, test acc: 89.49%\n",
            "Epoch 164 / 200: avg. loss of last epoch 0.016864195082491887\n",
            "Epoch 164 / 200: avg. grad_norm of last epoch 0.5517630152791368\n",
            "Current train acc: 99.28%, test acc: 88.99%\n",
            "Epoch 165 / 200: avg. loss of last epoch 0.020252611361506082\n",
            "Epoch 165 / 200: avg. grad_norm of last epoch 0.5927317918309146\n",
            "Current train acc: 99.55666666666667%, test acc: 89.54%\n",
            "Epoch 166 / 200: avg. loss of last epoch 0.015327749778136295\n",
            "Epoch 166 / 200: avg. grad_norm of last epoch 0.4883693263662916\n",
            "Current train acc: 99.47333333333333%, test acc: 88.9%\n",
            "Epoch 167 / 200: avg. loss of last epoch 0.022635902496689238\n",
            "Epoch 167 / 200: avg. grad_norm of last epoch 0.7914481758720524\n",
            "Current train acc: 99.11166666666666%, test acc: 89.1%\n",
            "Epoch 168 / 200: avg. loss of last epoch 0.022457207935846688\n",
            "Epoch 168 / 200: avg. grad_norm of last epoch 0.6985550823802168\n",
            "Current train acc: 99.38833333333334%, test acc: 89.37%\n",
            "Epoch 169 / 200: avg. loss of last epoch 0.013985714736348027\n",
            "Epoch 169 / 200: avg. grad_norm of last epoch 0.4500595749514897\n",
            "Current train acc: 99.40333333333334%, test acc: 89.12%\n",
            "Epoch 170 / 200: avg. loss of last epoch 0.022577248842828003\n",
            "Epoch 170 / 200: avg. grad_norm of last epoch 0.7166635101305532\n",
            "Current train acc: 99.48833333333333%, test acc: 89.1%\n",
            "Epoch 171 / 200: avg. loss of last epoch 0.0163027988645869\n",
            "Epoch 171 / 200: avg. grad_norm of last epoch 0.5168379609630906\n",
            "Current train acc: 99.68666666666667%, test acc: 89.22%\n",
            "Epoch 172 / 200: avg. loss of last epoch 0.017440308141397933\n",
            "Epoch 172 / 200: avg. grad_norm of last epoch 0.5771428596878857\n",
            "Current train acc: 99.41833333333334%, test acc: 89.06%\n",
            "Epoch 173 / 200: avg. loss of last epoch 0.016082350830081867\n",
            "Epoch 173 / 200: avg. grad_norm of last epoch 0.5257029901832294\n",
            "Current train acc: 99.68%, test acc: 89.25%\n",
            "Epoch 174 / 200: avg. loss of last epoch 0.018055209826414162\n",
            "Epoch 174 / 200: avg. grad_norm of last epoch 0.7466995403794795\n",
            "Current train acc: 99.57333333333334%, test acc: 89.18%\n",
            "Epoch 175 / 200: avg. loss of last epoch 0.026137714376579954\n",
            "Epoch 175 / 200: avg. grad_norm of last epoch 0.8776675090531076\n",
            "Current train acc: 99.42%, test acc: 89.42%\n",
            "Epoch 176 / 200: avg. loss of last epoch 0.0117894727828602\n",
            "Epoch 176 / 200: avg. grad_norm of last epoch 0.3659094134322605\n",
            "Current train acc: 99.865%, test acc: 89.51%\n",
            "Epoch 177 / 200: avg. loss of last epoch 0.016988548882243527\n",
            "Epoch 177 / 200: avg. grad_norm of last epoch 0.5359031131793176\n",
            "Current train acc: 99.575%, test acc: 89.18%\n",
            "Epoch 178 / 200: avg. loss of last epoch 0.013640255653993029\n",
            "Epoch 178 / 200: avg. grad_norm of last epoch 0.4484278998709246\n",
            "Current train acc: 99.42166666666667%, test acc: 89.18%\n",
            "Epoch 179 / 200: avg. loss of last epoch 0.02161085355768058\n",
            "Epoch 179 / 200: avg. grad_norm of last epoch 0.7040317627264343\n",
            "Current train acc: 99.74333333333334%, test acc: 89.31%\n",
            "Epoch 180 / 200: avg. loss of last epoch 0.01243347606382642\n",
            "Epoch 180 / 200: avg. grad_norm of last epoch 0.43446067930460325\n",
            "Current train acc: 99.62333333333333%, test acc: 88.99%\n",
            "Epoch 181 / 200: avg. loss of last epoch 0.023562333398902156\n",
            "Epoch 181 / 200: avg. grad_norm of last epoch 0.7526864170904565\n",
            "Current train acc: 99.54833333333333%, test acc: 89.41%\n",
            "Epoch 182 / 200: avg. loss of last epoch 0.01794045234867372\n",
            "Epoch 182 / 200: avg. grad_norm of last epoch 0.6257474028042865\n",
            "Current train acc: 99.70666666666666%, test acc: 89.3%\n",
            "Epoch 183 / 200: avg. loss of last epoch 0.01153983057242197\n",
            "Epoch 183 / 200: avg. grad_norm of last epoch 0.37020113514365927\n",
            "Current train acc: 99.43%, test acc: 89.0%\n",
            "Epoch 184 / 200: avg. loss of last epoch 0.008348390091753873\n",
            "Epoch 184 / 200: avg. grad_norm of last epoch 0.24615768159084211\n",
            "Current train acc: 99.87166666666667%, test acc: 89.54%\n",
            "Epoch 185 / 200: avg. loss of last epoch 0.003971797561230293\n",
            "Epoch 185 / 200: avg. grad_norm of last epoch 0.11985030838739541\n",
            "Current train acc: 98.98166666666667%, test acc: 88.66%\n",
            "Epoch 186 / 200: avg. loss of last epoch 0.04743950937244422\n",
            "Epoch 186 / 200: avg. grad_norm of last epoch 1.4902412712969804\n",
            "Current train acc: 99.4%, test acc: 88.99%\n",
            "Epoch 187 / 200: avg. loss of last epoch 0.012083853381806217\n",
            "Epoch 187 / 200: avg. grad_norm of last epoch 0.3862818670818387\n",
            "Current train acc: 99.50166666666667%, test acc: 89.11%\n",
            "Epoch 188 / 200: avg. loss of last epoch 0.013002111307361832\n",
            "Epoch 188 / 200: avg. grad_norm of last epoch 0.4172436521455824\n",
            "Current train acc: 99.415%, test acc: 89.11%\n",
            "Epoch 189 / 200: avg. loss of last epoch 0.021762784445084025\n",
            "Epoch 189 / 200: avg. grad_norm of last epoch 0.664361994467753\n",
            "Current train acc: 99.52333333333333%, test acc: 89.13%\n",
            "Epoch 190 / 200: avg. loss of last epoch 0.016182490690851887\n",
            "Epoch 190 / 200: avg. grad_norm of last epoch 0.517179565816892\n",
            "Current train acc: 99.43666666666667%, test acc: 89.32%\n",
            "Epoch 191 / 200: avg. loss of last epoch 0.013352130676712827\n",
            "Epoch 191 / 200: avg. grad_norm of last epoch 0.44477107378169334\n",
            "Current train acc: 99.64833333333333%, test acc: 89.36%\n",
            "Epoch 192 / 200: avg. loss of last epoch 0.020708068614872184\n",
            "Epoch 192 / 200: avg. grad_norm of last epoch 0.6529484397255085\n",
            "Current train acc: 99.15333333333334%, test acc: 89.16%\n",
            "Epoch 193 / 200: avg. loss of last epoch 0.022321485525416213\n",
            "Epoch 193 / 200: avg. grad_norm of last epoch 0.8191145549558522\n",
            "Current train acc: 99.16%, test acc: 89.19%\n",
            "Epoch 194 / 200: avg. loss of last epoch 0.014075048300918816\n",
            "Epoch 194 / 200: avg. grad_norm of last epoch 0.46402659965139426\n",
            "Current train acc: 99.77%, test acc: 89.45%\n",
            "Epoch 195 / 200: avg. loss of last epoch 0.01091816155165434\n",
            "Epoch 195 / 200: avg. grad_norm of last epoch 0.3493076817259603\n",
            "Current train acc: 99.78333333333333%, test acc: 89.06%\n",
            "Epoch 196 / 200: avg. loss of last epoch 0.01287294766485963\n",
            "Epoch 196 / 200: avg. grad_norm of last epoch 0.41545877590176167\n",
            "Current train acc: 99.65666666666667%, test acc: 88.98%\n",
            "Epoch 197 / 200: avg. loss of last epoch 0.01951080964632952\n",
            "Epoch 197 / 200: avg. grad_norm of last epoch 0.6433542930911583\n",
            "Current train acc: 99.38333333333334%, test acc: 88.96%\n",
            "Epoch 198 / 200: avg. loss of last epoch 0.016020320729236107\n",
            "Epoch 198 / 200: avg. grad_norm of last epoch 0.5412225292216435\n",
            "Current train acc: 99.42833333333333%, test acc: 88.97%\n",
            "Epoch 199 / 200: avg. loss of last epoch 0.008620308763250553\n",
            "Epoch 199 / 200: avg. grad_norm of last epoch 0.25942516839803925\n",
            "Current train acc: 99.825%, test acc: 89.41%\n",
            "Epoch 200 / 200: avg. loss of last epoch 0.02167654773099346\n",
            "Epoch 200 / 200: avg. grad_norm of last epoch 0.70873668229519\n",
            "Current train acc: 98.96%, test acc: 88.77%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epochs = 200\n",
        "\n",
        "scheduler = constant_learning_rate_scheduler(0.001)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "adam_history = train(model, criterion, optimizer, epochs, fashion_train_loader, fashion_test_loader, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS1ORThnPSsJ"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/Fashion-Other-Optimizers/ADAM_constantLR.json\", adam_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "7FRkaNRKPjQW",
        "outputId": "6ffaf750-c4f4-4842-df7b-94caff6ba678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2cd3ae2990>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEWCAYAAAAtuzN2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7wU1fnH8c9DF1Qigl24KhZsiYiKxIJGjSVooglGr70gUWOJLYoFUSwx/mKLUVQEFaMhVoxGsRCxoGDsLQhSFAvSBKnC+f3xzJVh7+69u/fu7uze/b5fr30te+bszMPs3nl25pw5x0IIiIiIlIpmSQcgIiISp8QkIiIlRYlJRERKihKTiIiUFCUmEREpKS2SDqCcdezYMVRVVSUdhohIWXnjjTe+CSF0yrRciakRqqqqmDBhQtJhiIiUFTObWtdyXcoTEZGSosQkIiIlRYlJRERKihKTiIiUFCWmBjCzPmY2ZN68eUmHIiLS5CgxNUAIYVQIoV/79u1zf/OIEVBVBc2a+fOIEfkOT0SkrKm7eDGNGAH9+sHChf566lR/DVBdnVxcIiIlRGdMxTRgwMqkVGPhQi8XERFAiam4pk3LrVxEpAIpMRVT5865lYuIVCAlpmIaPBjatl21rG1bLxcREUCJqbiqq2HIEOjSZWXZn/+sjg8iIjFKTMVWXQ1TpsAHH/jr+fMTDUdEpNQoMSWlWzfYYw+4/XZYsSLpaERESoYSU5L694fJk+G555KORESkZCgxJenQQ6FjR7jttqQjEREpGUpMSWrdGo4/Hh57DGbMSDoaEZGSoMSUtH79YPlyGDo06UhEREqCElPSunaFffbxbuTLlycdjYhI4pSYSkH//jB9Ojz1VNKRiIgkTompFBx8MKy3nncdFxGpcEpMpaBlSzjxRHjySQ3oKiIVT4mpVJx8MoQAd96ZdCQiIolSYioVXbrAAQd4Ylq2LOloREQSo8RUSvr3hy++gFGjko5ERCQxSkyl5MADYeON1QlCRCqaElMpad4cTjoJnnkGJk1KOhoRkUQoMZWaE0/0BDVkSNKRiIgkQomp1Gy4IfTpA3ffDUuWJB2NiEjRKTGVov79YeZMeOSRpCMRESk6JaZStO++sMkm6gQhIhVJiakUNWvmo46PGQMffZR0NCIiRaXE1ABm1sfMhsybN69wGzn+eB+qSGdNIlJhlJgaIIQwKoTQr3379oXbyLrr+gy3w4fDokWF246ISIlRYiplp5wCc+bAyJFJRyIiUjRKTKWsd2/YYgu47bakIxERKRolplJm5mdNr74K77yTdDQiIkWhxFTqjj0WWrdWJwgRqRhKTKVu7bWhb1+4915YsCDpaERECk6JqRyccgrMnw8PPJB0JCIiBafEVA569YJtt1UnCBGpCEpM5cDMx8974w2YMCHpaERECkqJqVwcdRS0batOECLS5CkxlYv27eGII+D++6GQQyGJiCRMiamc9O8PCxfCiBFJRyIiUjBKTOWkRw/o0gXOOstHIK+qUpISkSanRdIBSA5GjIAvvoBly/z11Kk+PQZAdXVycYmI5JHOmMrJgAGwdOmqZQsXermISBOhxFROpk3LrVxEpAwpMZWTzp1zKxcRKUNKTOVk8GC/lymuZUsvFxFpIpSYykl1NQwZ4j3zzDxJrVjhvfVERJoIJaZyU10NU6Z4Qpo0CVZfHU49FUJIOjIRkbxQYipn660H11wDzz8P992XdDQiInmhxFTu+vWDnj3hD3+AWbOSjkZEpNGUmMpds2Y+sOucOXDBBUlHIyLSaEpMTcH228PZZ8Ndd8HYsUlHIyLSKEpMTcXAgX4/U//+tUeHEBEpI0pMTUW7dvDXv8IHH8D11ycdjYhIgykxNSW/+AUceigMGgSTJycdjYhIgygxNTU33ggtWsBpp+neJhEpS0pMTc1GG8GVV8K//w0jRyYdjYhIzpSYmqLTT4fu3eHMMzUNu4iUHSWmpqh5c7+36euvNVeTiJQdJaamqkcPb2e69VZ4/fWkoxERyZoSU1N25ZWw/vpwyinw/fdJRyMikhUlpqZszTXhppvgrbf8WUSkDCgxNXWHHgoHHQSXXqop2EWkLGSdmMysq5ntn1K2i5mNMrOXzaxf/sOTRjODW27x+ZvOOCPpaERE6pXLGdO1wA/DV5tZR+Ap4OfAtsDfzOyX+Q1P8qKqysfSe+wxf4iIlLBcElMP4NnY6yOANYHuQCfgNeDM/IUmeXX22bDddvD738OCBUlHIyKSUS6JqRMwI/Z6f+DlEMJ7IYSlwAPA1vkMTvKoZUu47TaYPh022MDncaqqghEjko5MRGQVuSSm74AfAZhZc2A34MXY8kX4GVRZMbO+ZvaSmS0wsylJx1NQn37q4+jNn+/j6E2d6jPgKjmJSAnJJTG9DxxjZmsDJwOrA6Njy7sAM/MYW7HMAW4Bmv4QCQMG1L6faeFCjQ4hIiWlRQ51rwMeA76OXr8JxKdL3Q/4b57iKpoQwmiAiui4kam7uLqRi0gJyfqMKYTwL2Bv4AbgcmC/EHxehegs6jNgWK4BmNmFZjbSzCabWajrcpqZNTOzs83sIzNbbGbTzex6M2uX63YrUufOuZWLiCQgpxtsQwgvhhDOCSEMCiHMjpXPCiEcGkJ4tAExXIUnvEn4ZbW6/AX4P+AD4PfASOAMYJSZrfJ/MbMHokSX6dG7AbGWt8GDoW3b2uUnnVT8WEREMsjlUl4tZtYCOAToAIwKIXzZgNVsFkKYHK3vPbztKt22tsGT0cMhhMNi5Z8CNwG/Be6PveVk4PQ6tlt580FUV/vzgAF++W7DDb2N6a674NRToUOHZOMTESG3kR/+ZGbjY68Nv6/pH8DtwLtmtlmuAdQkpSwcARh+KTHuDmAhcFTKeueHEL6p47Es11ibhOpqmDLFR4KYPh2efBI+/xyOPtrLREQSlsulvP1ZtbNDH2APvFPEkVHZH/MUVzo7ASuAVeZwCCEsBt6KlufMzJqbWRugpb+0NmbWurHBlo1ddoEbbvAEddVVSUcjIpLTpbyNgYmx132AT0MIf4QfLrVV5zG2VBsA34QQlqRZ9jnQy8xaRTf75uJo4O7Y60XAVKAqXeVoTMB+AJ2bSqeB3/0OXnnFB3rdZRfYd9+kIxKRCpbLGVMrIH4TzF6sOkTRZGD9fASVQVsgXVICWByrk5MQwrAQgqU8quqoPySE0COE0KNTp065bq40mfmMt1tvDUccoe7jIpKoXBLTdGBX+OHsaFPgP7Hl6wCFHIRtIZDpElubWB1piHbt4KGHYOlS+M1vYEmm3wAiIoWVS2J6ADjWzJ4AngC+BZ6MLd8B7/JdKDOAjhnafzbEL/PlehlP4rbcEu6+26diP+ecpKMRkQqVS2K6Gr+BdlcgAMeEEOYCmFl74GDguXwHGDMej3fneGHUceEnwIQCbrtyHHaYJ6W//lVj6IlIInIZ+WFJCOHEEMLaIYRNQwiPxxbPx9uXBuY7wJgH8YR4Vkr5yXjbko6i+XL11bD77j7A63vvJR2NiFSYRt1gWyOEsIIG3rBqZkfjA8CCT63Ryswujl5PDSHcG23jXTP7K3C6mT2MX0bsho/88B9WvblWGqNlS3jwQdhhBz+DGj8e1iy7geNFpExZNNxddpV9TLrzgV/hnR/Ae+M9DFwXQvgu5wDMxgB7Zlj8nxBC71jd5vgZUz+8O/c3+JnUpSGEos1+Z2Z9gD5du3Y9eeLEifXWL1svvgh77w2//CWMHOm990REGsnM3ggh9Mi4PNvEZGYd8Btsu+HTW/wvWrQFfqbzIbB7fAy9pq5Hjx5hwoQm3rT15z/DeefB9dfDH/6QdDQi0gTUl5hy6fwwCNgKH39ugxDC7iGE3fEbX08DtqSwbUyShHPOgUMPhfPPh7Fj668vItJIuSSmg4E7Qwi3hhCW1xSGEJaHEP4GDAWa/pxGlcYMhg6FTTeFww+HLxsyTq+ISPZySUzr4pMDZvLfqI40Ne3b+823c+fCXntBly7QrBlUValLuYjkXS6J6Sv8JtpMdojqSFO03XZw7LHw0Uc+ZFEIMHWqdylXchKRPMolMY0CTjSzU+KT8kWzyvYDTgAez/huKX9PPVW7bOFCn99JRCRPcumVtzbwKrAZ3ivv42jRlnivvE+AXiGEWQWIsyRVRK+8uGbN/EwplZnmchKRrOWtV16UcHoA1wCz8PmPdsLvJboa2KlSkpKZ9TGzIfPmVdgkuJmm+Wgq03+ISEnI5VIeIYRvQwgDQgjbhBDaRo9tQwgXhxC+LVSQpSaEMCqE0K99+/ZJh1JcgwdD25SZRczgrNRRokREGi6nxCQVrroahgzxXnlmsP760KaND/j69ddJRyciTUTGNiYz26MhKwwhvNioiMpIxbUxpfPKK7DPPrDVVjBmjMbUE5F61dfGVNcgrmPw0byz3lZUv3kO75Fy16uX3+N08MFwyCHec69Nm/rfJyKSQV2J6fiiRSHl7YADYNgwOOoon5p95EhokZeB60WkAmU8eoQQhhczEClz1dUwaxaceSb07w933KHRyEWkQfSzVvLnjDNg5ky48kro2BGuuSbpiESkDCkxSX4NGuTJ6dproVMnH51cRCQHSkwNEJsoMOlQSo+Zdx+fNQvOPdfPnI49NumoRKSM6D6mBqjYG2yz1bw53HefdyM/8UQYNSrpiESkjCgxSWG0bg0PPwzdu0Pfvj5Nu4hIFpSYpHDWWAOefNJHiujTB956K+mIRKQMKDFJYXXsCM884yNC7L8/TJqUdEQiUuJy6vxgZu2AI4HNgbXx0R7iQgjhxDzFJk1F586enHbfHXr29Mt8M2Z4+eDBfg+UiEgk68RkZjsDTwAd66gWACUmqa1bN7/P6bLLVpbVzIALSk4i8oNcLuX9H9AK6At0DCE0S/PQOHmS2dChtcs0A66IpMjlUt6OwFUhhH8WKhhp4qZNy61cRCpSLmdM3+Iz14o0TKaZbtdZp7hxiEhJyyUxPQz8vFCBSAXINAPuzJlwzz3JxCQiJSeXxHQBsI6Z3Wxmm5lV7tDRZtbHzIbMmzcv6VDKS+oMuF26wG23wZ57+rBFAwdChokrRaRyZJzBtlZFsxXUP3FgCCFUzPh7msE2T5YuhVNO8Tmdjj7ap8xo3TrpqESkQBozg22qe8htRluR7LRq5T32NtsMLrnEO0M88gistVbSkYlIArJOTCGE4woYh1Q6M7j4YthkEzjhBNh1Vx/OaNNNk45MRIpMQxJJaamuhtGjvUNEz54wblzSEYlIkSkxSenZYw949VUfX2+vveCfunVOpJJkTExmtsLMvjezVrHXy+t5fF+80KVJ22ILT07du8NvfgPXXaceeyIVoq42pprODstTXosUR6dO8Nxz3pX8/PN9ZPJbboEWFdPxU6QiZfwLT+3soM4Pkog2beDvf/dOENdc42dRc+bAZ59pdHKRJko/PaX0NWsGV1/tHSLuumtluUYnF2mS1PlBysezz9Yu0+jkIk1OTonJzH5qZk+Y2cyoY4Q6P0jxaHRykYqQdWIysz2AF4BdgNei974AjMdnsn0PuLcAMZYcjZWXkEyjk7dsCVOmFDUUESmcXM6YBgBfAFsDx0VlV4UQegL7A5sAd+Y1uhIVQhgVQujXvn37pEOpLOlGJ2/VytugdtgBHn44mbhEJK9ySUw7A3eGEGYCK+LvDyE8g58tXZHf8ERi0o1OPnQovP8+bL45HHYYnHYaLF6cdKQi0gi5JKbWwOfRv5dEz2vElr+Fz3IrUjjV1X7ZbsUKf66u9q7kL70E554Lt94Ku+wCH32UdKQi0kC5JKYvgI0AQgjfAXOBbWPLNwLU+UGS0aqVjw7xr3/BjBmw444wfHjSUYlIA+SSmMYDP429fgY428yOMbPjgNPxThEiyTnwQHj7bdh5ZzjuODjmGJg/P+moRCQHuSSmu4BvzGy16PVFwCJgGDAUv7x3fl6jE2mIDTbwe54uvxxGjPCzpzffTDoqEclS1okphDA6hFAdQlgUvZ4MbAH8EugDdAshvFeYMEVy1Lw5XHopPP+834TbsyfcfLMnqqoq78lXVeWvRaSkZDUkUXSW9Bvg4xDCD5froramxwsUm0jj7bknvPUWHH88nHGGJ6zl0bjEGtJIpCRle8a0BL9HaYcCxiJSGB07wuOP+1TtNUmphoY0Eik5WSWmEMIKYBqwZmHDESkQM5g7N/0yDWkkUlJy6fwwHDjazFoXKhiRgso0pNGGGxY3DhGpUy6J6RX8PqW3zOz3Zra/me2R+ihQnCKNl25II4AFC2Ds2OLHIyJp5TIf0+jYv2+k9my2FpU1b2xQIgVR08FhwAC/fNe5s3d+GDYMeveGQYPgwgu9x56IJMZCyG629Ogm2norhxAq5nb7Hj16hAkTJiQdhjTW/Plwyik+U+6++8J998E66yQdlUiTZWZvhBB6ZFqe9RlTCGFYXiISKTVrrOH3M+21l3cp/8lP4P77/SxKRIoul/mYhprZLnUs39nMhuYnrNKm+ZiaIDM4+WR47TVYc0342c/80l5q93IRKbhcLqYfB2xWx/JNgGMbFU2Z0HxMTdj228OECXDkkXDZZfDzn8OXXyYdlUhFyWcrbztgWR7XJ5KM1VeHe+6Bu+6CV17xS3vPP590VCIVo87EZGadU7qBb5Wui7iZ/RL4HfBJwSMWKQYzOOEEeP116NAB9tnHz6DuvVdj7YkUWH2dH44HLsN74wV8evV047cYPqvt8XmNTiRp224L48f7zLiDBnlCWhFN4Kyx9kQKos7u4mb2Y+AneOIZCgwBXk2pFoAFwPgQwvQCxVmS1F28wnTsCLNm1S7v0sVn0xWRrDSqu3gI4W3g7WhFXYCHNLWFVKzZs9OXT5sG338PLXK5X11EMsllPqbLlZSkomUaay8EWH996N8fxoxRF3ORRtLYKyLZSjfWXtu2cNZZ3jni3nv9Jt2NNvIbdV9+eWV7lIhkTYlJJFvV1TBkiLcpmfnzkCHwl7/4cEZffw0PPgi9esEdd8Buu3nPvXPP9Q4UIWgGXZEsZD1WntSmzg+S0fz5Pjnhgw/Cv/8Ny5ZBp04wZ463R9Vo29aTm3r1SQWpr/ODzphECmGNNTzZPP44fPUVDB3qySqelEAz6IqkocQkUmhrrQXHHw9LlqRfrhl0RVahxCRSLJl69TVrBv/6V3FjESlhSkwixZKuV1/r1rDeevCLX0DfvvDFF8nEJlJClJhEiiVdr7677oLJk+HKK709qls3uP12dTOXiqZeeY2gXnmSVxMn+ky6L7wAP/2pJ6httkk6KpG8U688kXKx+ebw3HMwbBh89BHssANccgksXpx0ZCJFpcQkUkrM4Nhj4cMP4be/9Ut822/vZ1EiFUKJSaQUderkkxWOHu3tTXvv7fND3X67Ro6QJk9tTA1gZn2APl27dj154sSJSYcjTd2iRXDFFXDNNT6sUZxGjpAyVF8bkxJTI6jzgxTVBhuk707eqZOPxde5s18KFClx6vwg0lR8+WX68pkz/bLemmvCzjv7KBPXXQdPPumz7Ma7nmsQWSkDmtlMpFx07uyJJtW668Lll8P778MHH/igscOGrVzerh1svTW0aQPjxvmAsqCp4aVkKTGJlIvBgz2RLFy4sqxtW7j++tqJZfZsT1Lvv78yYb3wQu0bd2sGkVVikhKixCRSLmqSx4ABPvBr586erNIllQ4dfD6o3XZbWdYsw5V7DSIrJUZtTCLlpLoapkzxM58pU3I706lravirr155iU8kYUpMIpUi3SCyq60GO+0EF10Eu+wCb76ZTGwiMUpMIpUi3SCyd9wBr78O//wnzJjhSWrAAA2DJInSfUyNoPuYpEmZPRvOOcd79G21lY983qtX0lFJE6T7mEQkOx06wN13e3fzhQu948QZZ8CCBUlHJhVGiUlEVvXzn8N778Fpp8Ett8C22/qYfSJFosQkIrWtsQbcfDO8+KLfmLvffj6I7JAhGjlCCk5tTI2gNiapCIsXw6BBGkRW8kZtTCLSOG3awFVX+dBHqRYuhPPOgyVLih+XNFlKTCKSna++Sl/+xRcrx+M7/HCfouPRR+GTT2D58lXrahBZyYKGJBKR7GQaRLZjR+jfH959F954A0aOXHnJb7XVYJttvAPF0qXw0EMrz64aMojsiBHZDckkZU2JSUSyk2kQ2RtuWDU5fPedDxr77rveu+/dd70LerppOxYu9HWOGwfrrbfyse66/rzOOtCqldcdMWLV7Wt09CZLnR8aQZ0fpOI05oylWbPanSdq/OhHMHdu+mVrr+2JatKk9G1ZXbr4uIFSNurr/KAzJhHJXnV1w89OMl0KrEksixd7O9ZXX/nZVfzx1Vd+FpbO1KmeMH/2Mz/LkrKnxCQixZHpUuDgwf7vNm08SXXpkv79VVXpE1uzZnDUUf7v7baDffbxxx57wOqr5/W/IMWhXnkiUhzpBpHN5R6odKOjt20Lw4d7p4trrvFLfrfeCgcd5EMs7bmn9xIcNw6+/169AsuE2pgaQW1MIkWWTRvXokXw8ss+jNKzz/pUHiH4GdmyZat2YdcNwomor41JiakRlJhEysA338Dzz8OJJ6YfkHbttf2MK9MlRMk7jfwgIpWtY0fo29e7sacza5Zf1uva1dvAHngg883EUhRKTCJSGTJNLb/++n4v1jbbwIMPwhFHeO++bbf1aT8efRTmzPG6aqMqCl3KawRdyhMpI6k36ELtNqbvv/c2qeef98fYsd5mVdNZ47PPvE6m90tWdClPRASy6xXYooVPL3/BBfD0036m9OKLcNllPiZgPCmBJ7n+/eHaa+Hhh32Ui3jiS6UzrqzojKkBzKwP0Kdr164nT5w4MelwRKQY6hq5ItVGG3mb1eabr3x8/DFcfrmfgdWo0DMu9corIF3KE6kgmW7w7dIF3n7bR1OfONEf8X9/803d663AIZU0JJGISD7UNXJF+/aw447+SDV3rieqnXZKv95p0woTbxlTG5OISDYaOnLFj34EPXpkvk8qBDjttPSjr1coJSYRkWxVV/tltxUr/DmXtqF0QyqttpoPPjtkiLdJXXopfPttPiMuS0pMIiLFkO6M6447fNikDz+EX/zCx/XbbDO48cbCTFdfJr0C1fmhEdT5QUTy6o034I9/9GRVVQWDBsGRR0Lz5o1fdzb3cRWJ7mMSESkXO+7og88+84yPjn7MMbDDDvDkk9l3Vc/kootq32O1cKEPiltilJhERErNvvvC+PE+bt/ChT6NR+/efh9UXZfili71LupPPw1/+xucdx4cdpgnt0y9/0qwV6Au5TWCLuWJSMEtXQp33gkXXli7Y0TLltCrl7dZTZ4M06evembVujVsuqk/XnwR5s9Pv42+fX0Ei969fV0FphtsC0iJSUSKpnNnTzypmjWDnj1XJqDNNlv57/XW8+WQvo2pTRufTPG11/x+qy228DrHHefTgRSIElMBKTGJSNFkGhLJzLuvZyPTRIuLFsHIkXDbbfDqq36m9etfwymnwG675f0sSp0fRESagkzTdmQqTyfTfVirreYdLV55Bd55B046CUaNgj328Ok/brrJB7QtUndzJSYRkXKQ7gbdmiGR8mm77eCWW2DGDG/batsWzjwT1l0Xjj3WxwsMwZ/79StIclJiEhEpBw0dEqmh2rXz6ejHj4cJE/zy3vLlq9YpUHdztTE1gtqYRKRi5KON64e3qI1JREQaKx9tXFlSYhIRkfoVq40LJSYREclGEdu4NFGgiIhkp7q6KAO+6oxJRERKihKTiIiUFCUmEREpKUpMIiJSUpSYRESkpGjkh0Yws5nA1KTjyKAj8E3SQdRB8TWO4mscxdc4jY2vSwihU6aFSkxNlJlNqGvIj6QpvsZRfI2j+Bqn0PHpUp6IiJQUJSYRESkpSkxN15CkA6iH4mscxdc4iq9xChqf2phERKSk6IxJRERKihKTiIiUFCUmEREpKUpMZcbMtjCzQWY2zsxmmtl8M3vLzAaYWbuUugPNLGR4nFvAGDNtc0Gaulua2aNmNsfMvjOzsWa2dwFjq2ufBDNblmXdRu8/M7vQzEaa2eRonVPqqb+LmT0bfebfmtm/zewnGepuYGb3RN+RRWY2wcx+U4j4zKyNmZ1sZo+Z2ZRoe5PN7O9m1i1N/ao69ut7+Y4vqjusjm3+Ok391tHf2admtsTMJpnZxWbWMt/x1bM/ah7VWdbPZf9lfSyJ6mf9t2pm7c3sZjP73MwWm9n7ZvY7M7NsYtN8TOXnBOA04HFgBLAM2Au4EuhrZj1DCItS3nM2te/SfqPAcY6lds+dZfEXZrYZ8ArwPfAnYB5wMvC0mR0QQni2AHE9DHySpnx74DxgVJplhdp/VwGzgf8CP6qropn1BMYAnwOXRsWnA2PNrFcI4d1Y3Q7AS8A6wP8BnwFHAv8wsxNCCHfnOb4q/LN+CbgLmAFsCvwOONTM9g8hvJDmfY/gn0fc3CxjyyW+uKPTlL2epuxB4BBgKPAqsCtwBdAVOC7P8c3MEBfALcBqwNNpljV2/2V9LMnlb9XMWgGjgR2Am4EPgQOAW4F1gYH1RhZC0KOMHkAPoH2a8iuBAJweKxsYlVUVOcYADMui3j+A5cBPYmWr48M8fUzUa7RIMd8exX1QsfYfsGns3+8BU+qo+zrwLbBhrGzDqOyZlLp/iuLuEytrHq1jFrB6PuMD1o5/hrHyrYElwISU8qoovoFF3H/D/HCX1XoPjOK7PqX8+qi8V77jy/D+XaPtjSzQ/svlWJL13ypwavT+36es9yFgKT4cUZ2x6VJemQkhTAghzEuz6MHoedt07zOzNc2sqGfIZtbKzFbPsKwdcDAwJoTwVk15CGEBcCewBbBTkeJsB/wWP7P4d4Y6ed9/IYTJ2dQzs674vhgZQvg89v7PgZHAPma2XuwtRwKTQgijYnWX479eO+AH3rzFF0KYFf8MY+Uf4AfktN9J+OEyYNtsttPQ+FK2Z9FnWdex78jo+YaU8prXRxUqvhQnRc93ZqrQyP2X1bGkAX+rRwILgTtS1nsD0BI4vL7YlJiajo2i56/SLHsHP/VebGavmNkBRYjn1/iXc76ZfR1db24fW7490Bq/TJJqXPRclJncyLEAABEISURBVMQE/AZYEz/LW55meRL7L65mP2TaVwbsCGBm6+NnUuMy1I2vr6Cig//6pP9OApyDf0e+M7PpUXtH6wKHNS96LDKz0Wa2S5o6OwGfhxCmxwuj1zMowv6LftD1xc9IRmeoVqj9l3osyfpvNfrMuwNvhhAWp9R9HT+Tqnf/qY2pCTCz5sAl+PXf+2OL5uLX/l8B5gBbAmcB/4raGoYVKKTX8V/yn+AH/APx9pA9o/aQBcAGUd3P07y/pmzDAsWX6kT8D2ZoSnlS+y9VLvuqlPZrfzwxXZFSvgJ4HngUP/B2wg/ClwC7Rm1S6X4gNMaXwF/wtsHvgB/jn+VYMzswrNqeuQHwQYb1fM7KA3chHY5fKvtzCGFFyrKC7b8Mx5JcvlNr4W1iteqGEJaY2Tdk8/1rzDVKPUrjgV+iCcCFWdRdG/gCP9Bm1daQpxgvimIcEL0+Onp9Qpq6m0bLbihCXFtG23o2y/oF2X/U3YZzSRTj3mmW7R0tOyt6vXv0elCaus2iZY/mM74M9XsBi4G3gDZZvmdIFF91oeOL3rM5nqQmppQvB17M8J4XgblF2H+vRnF0zuE9Dd5/sXXUOpbk8rcKbBy9vifD+qcBb9UXhy7llTkzuwI/GxkSQri6vvohhFnAbXgvoV4FDi/uOrzh86Do9cLoOd2lhzYpdQrpxOg543X8uIT2Xy77KvH9amY7Av/CL3sdFGpf0slkcPR8UJ218iSEMBFv1O9qZlvEFi0k/f4D34eF3n9bAz2B0SGEaTm8tVH7r45jSb6+fzX1691/SkxlzMwGAhcDd+OXTbI1JXrumOeQMgohLMMPVDXbnBE9pzutrylLd+kgb6LODMfgPdUeyeGtU6LnYu2/XPZVovvVzLrjbSLzgL1CrLNGFqbjZwlF+16S/rOcQebLTRtS4O8lOf5Yimnw/qvnWJLLd2oOsChd3aj9qyNZ7D8lpjIVfZEuA4YDJ4XoPDlLm0fPmRql887M2uDX5mu2+S7elXjXNNV7Rs8TChxWH/y+ivtCCEtyeF+x99/46DnTvgpE91WFEL7A//B7ZqgLBdqvUVJ6FpiPJ6VcZ3feFO/WXrTvJek/y/HAhma2cbxi9HoDCvi9jO4BOhq/t+mxHN/eoP2XxbEk67/V4O1h/wV2SNMRY2e8o079+6+h1yL1SO6B32AZgHuAZhnqtCD9PQob42cI3wCrFSC2tTOUXxfFfH6sbCT+C+/HsbKaeyP+R4HvYwKeiGLaLun9R/334YzH71naIFa2QVT2bErdmn2d7j6mOcAaBYhvh2i/TCN2/0623xH8R/IDUdx98xkf0I407VxRzEuAD1LKD6Lu+5h2y/f+i9X7dbptF2r/ZXMsiepl/beK37Sb6T6mZWRxX6CmvSgzZnYafjf4NLxRPLXHzlchhNFm9iPgU7znzoes7FV2Ev6FOiKEMLIA8f0F/xX1QhTj6nivvL2A1/Bf0jV3k3fFD5bL8B5T3+J3k2+Ht02ku9s9X3FuEMX3RgihVpfhYuw/Mzsa6BK9/D3QCj/4AUwNIdwbq9sL36ef4Q3UNe9ZF/hpCOHtWN218TOotfGRHz4HjgB647+I78pnfGbWJdpeB+ByYFKa1T0SQvguqv8w3lvzFfzyU0fgMLzL+2PAoaF2T7TGxPcT4Cn8s5zIyl55J+B/P/uFEF5KWfco4Bf4SBY1Iz+ciJ9dZxqloUHxpbznKWB/YOsQwocZ1puv/ZfVsSSqm/XfanTW9wq+j2/C/34OBH4FXBlCuKS+2Br9S0+P4j6I7mCv4zEmqtcav0b9Ln5QXYb3JvsnsHMB4zsEHz7lc7xX1nd4z6yLSP+rtRv+xzQXbxR9CdinCPuxppfgyRmWF3z/4UMM1fk5ptTfFXgOWIBfLnsa6J5h3RsC9+JndovxyyuHFyI+POHV9Z0MxH4l4wf4MXgX7qXR/2UcPmJAxl/tjYhvvWhffIQfUJfhB+PhwFYZ1t0GHwFhCn5WNRk/eLcs4Oe7MX5W8nI9683X/htWz2c2JqV+1n+reOegW/D2qSV49/vTyfIqiM6YRESkpKjzg4iIlBQlJhERKSlKTCIiUlKUmEREpKQoMYmISElRYhIRkZKixCQiIiVFiUlKkpkFMxuWdBwNYWZtzewmM5tmZsvNbEoe193MzAaa2WQz+97MQmzZr83sbTNbFO2/3vnabg7xHZfUtqXpUGKqIGbWOzpoBDM7OUOdYGZPFDu2JuYCfAiaB4Hj8Anp8uVYfMDNF/ARAI4GiKZt+Ds+qvfpUXnaIW0aK/oeDYyGbRLJO81gW7kGmtl9IRq3TvJqX+DdEMJ5BVr3PGqPAt0b/3s+K4Tw3wJsN643nhyH4cPTxN2LDya6tMAxSBOmM6bKNAEfmTqfv+TLlpk1N7O2eVzlesDsPK4vdd1zQ+2xxNaLngu13ayEEJaHEBaHLAYRFclEiaky/QMfDfqCaCTqOmVq70nXnhBd4glmtrWZ3WBmX5jZQjN7zsy2jOocamb/jdpCpphZvzq2vY+ZjYvW8aWZ3Whmq6ep197MrjWzT8xsiZnNNLO/m9mmGWLex8wuMbNJ+CCnfevZBy3M7AIz+8DMFpvZLDN7xMy2S103sAmwZ+yy6cC61h2993Aze8nM5kf/19fM7Nex5b2jde8FdImte1hUfnlU9dOofEqu+yaq28rMzjezt6I45pnZBDM7PVo+DD9bim/rh/9j6nfCzA6IXp+R4f/9ahRPy1jZ5mZ2b/TdWRp9R64zs3b17cfo/VPMbIyZdTez581sgZnNNrPhZrZOSt01zOzKaH9/E+2fT8zsmtQfK+bte2eZ2TvR5/StmX1sZnelxN/LzJ6Kvq+LzexzM3vSzHqmrC/b72wb87+rj6PPZK6ZvWtm12WzP8qRLuVVpgD8EZ9pdADwhwJsYzg+CvZVQCfgHOBpM7sE+BPwN2Ao3k5yu5l9EFKmHgC64/PT3IHPF7MXcAawrZntW/Or3Mza48Psd47W+T6wPj7a8mtm1iPUnrTuz0DLaN3fAh/X8/8ZgSev0VHs6+HzzrxqZruHEN4EXsTbdv6Cj+pdM9X1O3Wt2MyuxD+Hf7Ny+oFfASPN7PQQwl/x9qKjo3odgbOjt0/CJ+c7NHrP2dG2F+S6b8ynK3gav1T3DHAfnrS3i9Z/C3A7PuVCfFt1/R+fwUfBPgafAiH+/94cnyLlpuAzHNdMy/48fonwdnyU+h/jn/tPzWzPmrr12Agfif0hfET47vg0Fz3MbKcQQs303hviU5k8BNwPfA/sCZyPz9f089g6BwCDgFHAbfhI4JsAB+Oj0S8z//E1Ovo/34hP2rcusFv0/xgX/T9z+c7+NYr9Hnwakxb4BId7Z7EfylM+hu/XozwerJye4Nzo9TP4gadLrE4Ankh5XwCGpVnfcdGy3rGygVHZKFadPOyMqPxbYONYeacohr+n2WYAfplSfmNU/tuUskXEJjGLyrtE2xuWJuaPgbZZ7rd9o/c8mPJ/+jF+IBubUn8KaaY1yLDu7tG6r0qz7NEo/jViZWNIM+FcbL9Xpdlf2e6b8+uIpVl926rjO1EzceHWKXWviMq7x8rexqenWCOl7q+iusdlsU+nRHXPSik/Oyr/Y6ysFWmmsojFtnOs7L+kTCqY5n1npL4vQ71cPpfZwJPZfJ+aykOX8irbBfgf5hUFWPdNIfqrioyNnh8PIUyvKQwhzMSTxObU9nEI4dGUsmui518BmJkB1fjZyudm1rHmgc8FNQ7YL826/xZW/mquz6+i58Hx/1PwyflGAbuZWacs15WqGj+QDY/HHsX/OLAG6ae0rlcD9k01PvfUoNR1hca1GQ2Pno9Jie0o4L0QddYwvyy6PX7m0jol3peimNN9lul8C9yaUnZrVF7zeRJCWBpWnq21MLO1ou09G1WJTyI5D59yfbc6tjsvej7EzNqkq9CAz2UesI2ZbVvHdpsUJaYKFvzy09+BajPbPs+rn5zyek70/GmaunPw2VZT1eruHEL4Ar/MU3MdvlP03v2AmWke++KXUlL9r+7wV7EJfnktXffr92N1GqIbYPhZQmrsNTPNpos/G7num82Bj0IIixu4vbRCCO/hZxvVZlZzzNkDqMIvT9XoFj1fnibWr/Ep0rPdF5NDCKv0DAwh1Ez4l9qGc6qZvYNPaDc72t6YaPFasaoX4Wf3Y6N2oxFmdmR0CbTGA3hSuwiYHbVxXWA+y2+NXD+Xs6I43jWzSWZ2p5kdEtuXTY7amORivB3nWuCAHN9b1/dneY7lluO2U9/3LP5/yFa2Z0uFZvgZ0wFk3jfvZyjPZt2Q+74phHuAG/B2kWfxs6fleDtWjZp4r8fb29KZk6G8QczsD9H2nsHbwGbgXd03xLvD/3DwDyG8amab4e1Oe0WPI4GLzWy3EMLsKPnta2Y7R/X2wM9AB5rZkSGER8jxcwkhPGZmVfj05HsC++Bts2PNbJ/UBNwUKDFVuBDCp2b2N+BMy3y3/mygQ5ryWr268qxbaoGZrY9P21xzRjYTP4NaM4TwbGr9PJmMH6C6UbuRf+voOd2ZYDYmAvsD00II+b4hNtd98z9gKzNrHR1gM2nItNf3421Nx5jZy/iPodHRGXCNidHz8jx8lpuaWav4QdvMWuPf2Y9i9Y7G26QOiF+uNLP90600hLAA7yjxUFTvVLxzwon4/6+m3uvA61GdjYE38anaH6EB39kQwmw8id8XXQq8Bm8TPAQYmc06ykmTPRWUnFyJX3v/U4bl/wN2jXefNbO1gOMLHNeWZvbLlLILoudH4Ye2jxHAzhbrXh2X2kW4AWrauS6MDgo1690W75H1UtRW1hD3Rs9XmVnz1IVm1tDLeA3ZNyPwS0YXp6kXP6NdED2n+7GSKZaZwFN4775qvGff8JRqbwLvAf1Tu0xHMbQws2y3uSbewy3u1Kg83m65HE+08c+1Bd5rNXX7HdNsp+Zm5g511PkMT0YdILfPxfweu1VG2IjaOd+Mb7ep0RmTEEL4JronIlMniFvwX2vPm9m9+BnLycBUVt7YWQjv4r8Q78B/Te+F/9L+D95DrsYA4KfAP8zsH3jj8VK8h9OB+D1bxzU0iBDC6Gi9vwXWMh+yqaa7+GK8J1ZD1z3e/B6ggcBbZjYSv5y0PrBjFH+rjCuoXy775kagD35paidW9trcBtgSv4REtA6Aa81sRFTnvagtqS7D8UR+Pd6gv0rHlhBCMLOj8e7i75hZTTfqtkBXPKldiF9iq88k4LLox8Mb+L48AT9bindb/ydwNfCUmT2MJ64jgXRd0j80s3HAa6z8jPrh+/OBqM7FZrYf8AR+Fm34Pt2KVX/4Zfu5rAF8YWaP48noa7w983f4Zc1RWeyL8pN0t0A9ivcgpbt4yrK2+B9bre7i0fLz8ES0BO8EcAJ1dxevSnl/VVQ+MM26x5DSBTqqOww/GL6Gd639CriZlK7EsfgvwZPZImB+FOcdwC6xerViznLftcDP1j5kZSP5o8B2aepOIcvu4rH3HITfQzQ7Wv90/Ayjf337qq79nsu+ieq2wQ+a7+MJZy4wHjg1pd75+CXOZfHPta79iyfYWdHyO+rYF13w+4Sm4AfrWfiB+mpitxrU8f4p0X7qjie57/CD+L3Auil1m+PJ7pNov0/FE0i31O8rfhb1Ip4caj6jkaza3b03/qNpSrSvZ0ff35OI3WqQ7ecS7bOr8cuCs6LtTsHvfdo8ieNIMR4W/edFRJoE81EvpoQQeiccijSQ2phERKSkKDGJiEhJUWISEZGSojYmEREpKTpjEhGRkqLEJCIiJUWJSURESooSk4iIlBQlJhERKSn/D5TFneXrZqlIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss(adam_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKnwTD6sQC99"
      },
      "source": [
        "## Training with SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrMqmwfLQF2Z",
        "outputId": "68359773-3ce4-45a6-bd23-4986ae777059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.5965861408392584\n",
            "Epoch 1 / 200: avg. grad_norm of last epoch 2.564945111934229\n",
            "Current train acc: 83.90666666666667%, test acc: 82.77%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.3984734286944068\n",
            "Epoch 2 / 200: avg. grad_norm of last epoch 1.8134560962129436\n",
            "Current train acc: 85.07666666666667%, test acc: 83.65%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.35636524116198226\n",
            "Epoch 3 / 200: avg. grad_norm of last epoch 1.7143495102947484\n",
            "Current train acc: 87.70333333333333%, test acc: 85.95%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.3262043552875518\n",
            "Epoch 4 / 200: avg. grad_norm of last epoch 1.6463634237883817\n",
            "Current train acc: 87.94%, test acc: 86.14%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.3044315915902455\n",
            "Epoch 5 / 200: avg. grad_norm of last epoch 1.6019350966056554\n",
            "Current train acc: 90.07333333333334%, test acc: 87.48%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.28832117958068826\n",
            "Epoch 6 / 200: avg. grad_norm of last epoch 1.6336430958064616\n",
            "Current train acc: 88.97333333333333%, test acc: 86.03%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.27439113985697416\n",
            "Epoch 7 / 200: avg. grad_norm of last epoch 1.6622908622374186\n",
            "Current train acc: 90.38%, test acc: 87.5%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.26133968969980875\n",
            "Epoch 8 / 200: avg. grad_norm of last epoch 1.6600293482055835\n",
            "Current train acc: 91.12166666666667%, test acc: 87.82%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.24948184971809378\n",
            "Epoch 9 / 200: avg. grad_norm of last epoch 1.6296281017763912\n",
            "Current train acc: 90.72333333333333%, test acc: 87.07%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.24089982286294312\n",
            "Epoch 10 / 200: avg. grad_norm of last epoch 1.6881225412622292\n",
            "Current train acc: 90.905%, test acc: 87.37%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.2295749745051067\n",
            "Epoch 11 / 200: avg. grad_norm of last epoch 1.6853107756315377\n",
            "Current train acc: 91.79666666666667%, test acc: 88.2%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.22128349575996398\n",
            "Epoch 12 / 200: avg. grad_norm of last epoch 1.7067389322701636\n",
            "Current train acc: 91.945%, test acc: 88.34%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.21292274836699163\n",
            "Epoch 13 / 200: avg. grad_norm of last epoch 1.6851177531950614\n",
            "Current train acc: 92.085%, test acc: 87.8%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.20726624542077382\n",
            "Epoch 14 / 200: avg. grad_norm of last epoch 1.7685565234813672\n",
            "Current train acc: 92.23666666666666%, test acc: 88.35%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.19780178498824444\n",
            "Epoch 15 / 200: avg. grad_norm of last epoch 1.742892240323855\n",
            "Current train acc: 93.80166666666666%, test acc: 89.15%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.19084590483506544\n",
            "Epoch 16 / 200: avg. grad_norm of last epoch 1.7461016529088147\n",
            "Current train acc: 93.59333333333333%, test acc: 89.25%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.18452066464424138\n",
            "Epoch 17 / 200: avg. grad_norm of last epoch 1.7956528264322023\n",
            "Current train acc: 92.00333333333333%, test acc: 87.16%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.17858505937258418\n",
            "Epoch 18 / 200: avg. grad_norm of last epoch 1.8384969022319764\n",
            "Current train acc: 93.97666666666667%, test acc: 89.18%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.17204387830893192\n",
            "Epoch 19 / 200: avg. grad_norm of last epoch 1.8334514807416977\n",
            "Current train acc: 94.28166666666667%, test acc: 89.02%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.1664683995485305\n",
            "Epoch 20 / 200: avg. grad_norm of last epoch 1.8699967860951228\n",
            "Current train acc: 94.51666666666667%, test acc: 89.23%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.1603419117848079\n",
            "Epoch 21 / 200: avg. grad_norm of last epoch 1.8658317181348583\n",
            "Current train acc: 94.275%, test acc: 88.79%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.15448308459917717\n",
            "Epoch 22 / 200: avg. grad_norm of last epoch 1.8789036705557216\n",
            "Current train acc: 92.425%, test acc: 87.64%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.14961442239681894\n",
            "Epoch 23 / 200: avg. grad_norm of last epoch 1.9233753274812353\n",
            "Current train acc: 94.58833333333334%, test acc: 88.75%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.1455423181454342\n",
            "Epoch 24 / 200: avg. grad_norm of last epoch 1.9990976091033659\n",
            "Current train acc: 92.59333333333333%, test acc: 87.6%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.14060727765162787\n",
            "Epoch 25 / 200: avg. grad_norm of last epoch 1.9662181064638085\n",
            "Current train acc: 95.19666666666667%, test acc: 89.58%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.13649827031294517\n",
            "Epoch 26 / 200: avg. grad_norm of last epoch 1.9577113887457716\n",
            "Current train acc: 95.14166666666667%, test acc: 88.98%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.1315577396114666\n",
            "Epoch 27 / 200: avg. grad_norm of last epoch 1.960247383076847\n",
            "Current train acc: 95.68%, test acc: 89.54%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.1278279988606771\n",
            "Epoch 28 / 200: avg. grad_norm of last epoch 2.0184847001686044\n",
            "Current train acc: 95.33166666666666%, test acc: 89.03%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.1229567843198777\n",
            "Epoch 29 / 200: avg. grad_norm of last epoch 1.9708339934275876\n",
            "Current train acc: 95.98333333333333%, test acc: 89.61%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.11889423038959503\n",
            "Epoch 30 / 200: avg. grad_norm of last epoch 1.9860335146130328\n",
            "Current train acc: 94.96%, test acc: 88.42%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.11438047105073924\n",
            "Epoch 31 / 200: avg. grad_norm of last epoch 1.9168337268788678\n",
            "Current train acc: 95.26666666666667%, test acc: 88.53%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.11235982134342201\n",
            "Epoch 32 / 200: avg. grad_norm of last epoch 2.0396739190086626\n",
            "Current train acc: 96.08833333333334%, test acc: 89.14%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.10558852631251019\n",
            "Epoch 33 / 200: avg. grad_norm of last epoch 1.918762769339643\n",
            "Current train acc: 96.30833333333334%, test acc: 89.52%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.10482427904208505\n",
            "Epoch 34 / 200: avg. grad_norm of last epoch 2.025147346667639\n",
            "Current train acc: 95.88666666666667%, test acc: 88.6%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.10023485825061797\n",
            "Epoch 35 / 200: avg. grad_norm of last epoch 1.896020325874009\n",
            "Current train acc: 95.45166666666667%, test acc: 88.54%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.10042788989941279\n",
            "Epoch 36 / 200: avg. grad_norm of last epoch 2.187865204133764\n",
            "Current train acc: 96.91%, test acc: 89.67%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.09824913563330973\n",
            "Epoch 37 / 200: avg. grad_norm of last epoch 2.0701582072130376\n",
            "Current train acc: 95.58%, test acc: 88.31%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.09081974439223606\n",
            "Epoch 38 / 200: avg. grad_norm of last epoch 1.9633057402568985\n",
            "Current train acc: 95.83333333333333%, test acc: 88.93%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.08846500917275743\n",
            "Epoch 39 / 200: avg. grad_norm of last epoch 1.9611858958236017\n",
            "Current train acc: 96.96%, test acc: 89.27%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.0855450982014339\n",
            "Epoch 40 / 200: avg. grad_norm of last epoch 1.8974656812380932\n",
            "Current train acc: 96.5%, test acc: 88.63%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.08191900913914042\n",
            "Epoch 41 / 200: avg. grad_norm of last epoch 1.8467781743636402\n",
            "Current train acc: 96.54%, test acc: 89.24%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.0798805560648441\n",
            "Epoch 42 / 200: avg. grad_norm of last epoch 1.8530685809593324\n",
            "Current train acc: 96.82666666666667%, test acc: 89.0%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.07795054769118624\n",
            "Epoch 43 / 200: avg. grad_norm of last epoch 1.8776832135748716\n",
            "Current train acc: 97.26333333333334%, test acc: 88.95%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.07726227248112358\n",
            "Epoch 44 / 200: avg. grad_norm of last epoch 1.9441058347242486\n",
            "Current train acc: 96.00166666666667%, test acc: 88.06%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.0692129466056824\n",
            "Epoch 45 / 200: avg. grad_norm of last epoch 1.7167728726388494\n",
            "Current train acc: 96.97333333333333%, test acc: 89.21%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.07059000827074052\n",
            "Epoch 46 / 200: avg. grad_norm of last epoch 1.9076562505486951\n",
            "Current train acc: 97.71666666666667%, test acc: 89.21%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.0692534430642923\n",
            "Epoch 47 / 200: avg. grad_norm of last epoch 1.838958993400643\n",
            "Current train acc: 97.99833333333333%, test acc: 89.74%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.06568134996195636\n",
            "Epoch 48 / 200: avg. grad_norm of last epoch 1.795452047154098\n",
            "Current train acc: 97.87333333333333%, test acc: 89.15%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.0643505525926749\n",
            "Epoch 49 / 200: avg. grad_norm of last epoch 1.8102958149171693\n",
            "Current train acc: 94.53666666666666%, test acc: 86.81%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.06304217217763265\n",
            "Epoch 50 / 200: avg. grad_norm of last epoch 1.8044610798477965\n",
            "Current train acc: 96.76166666666667%, test acc: 88.6%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.0625172370195389\n",
            "Epoch 51 / 200: avg. grad_norm of last epoch 1.8780321688476675\n",
            "Current train acc: 97.92166666666667%, test acc: 89.56%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.05867875822186468\n",
            "Epoch 52 / 200: avg. grad_norm of last epoch 1.7580143334167546\n",
            "Current train acc: 96.32%, test acc: 88.22%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.05606009868979453\n",
            "Epoch 53 / 200: avg. grad_norm of last epoch 1.691651146763799\n",
            "Current train acc: 98.08666666666667%, test acc: 89.33%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.05214173295299215\n",
            "Epoch 54 / 200: avg. grad_norm of last epoch 1.6230077110758578\n",
            "Current train acc: 98.01333333333334%, test acc: 89.33%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.05373241696556409\n",
            "Epoch 55 / 200: avg. grad_norm of last epoch 1.7369456842441993\n",
            "Current train acc: 97.89166666666667%, test acc: 88.96%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.05128014615078772\n",
            "Epoch 56 / 200: avg. grad_norm of last epoch 1.6256380274748654\n",
            "Current train acc: 98.28333333333333%, test acc: 89.59%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.04951168171366057\n",
            "Epoch 57 / 200: avg. grad_norm of last epoch 1.7077663730988515\n",
            "Current train acc: 98.04833333333333%, test acc: 89.34%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.047610519603888186\n",
            "Epoch 58 / 200: avg. grad_norm of last epoch 1.6334434024227793\n",
            "Current train acc: 98.63833333333334%, test acc: 89.68%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.04910764649808409\n",
            "Epoch 59 / 200: avg. grad_norm of last epoch 1.7783661204715224\n",
            "Current train acc: 98.05666666666667%, test acc: 88.9%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.047295858944952515\n",
            "Epoch 60 / 200: avg. grad_norm of last epoch 1.6876348584203351\n",
            "Current train acc: 98.815%, test acc: 89.77%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.04794288933177794\n",
            "Epoch 61 / 200: avg. grad_norm of last epoch 1.8955782701293118\n",
            "Current train acc: 98.34666666666666%, test acc: 89.4%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.044037531479696454\n",
            "Epoch 62 / 200: avg. grad_norm of last epoch 1.6362840092402307\n",
            "Current train acc: 97.89666666666666%, test acc: 89.22%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.04344675685788193\n",
            "Epoch 63 / 200: avg. grad_norm of last epoch 1.5652098666585066\n",
            "Current train acc: 98.82166666666667%, test acc: 89.7%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.0375647742127379\n",
            "Epoch 64 / 200: avg. grad_norm of last epoch 1.3399615671573162\n",
            "Current train acc: 98.43166666666667%, test acc: 89.12%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.038750852874914844\n",
            "Epoch 65 / 200: avg. grad_norm of last epoch 1.4907524205858966\n",
            "Current train acc: 98.86666666666666%, test acc: 89.64%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.0380232041373849\n",
            "Epoch 66 / 200: avg. grad_norm of last epoch 1.475254581520046\n",
            "Current train acc: 98.92333333333333%, test acc: 89.46%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.030727942904829962\n",
            "Epoch 67 / 200: avg. grad_norm of last epoch 1.1043689328337243\n",
            "Current train acc: 98.12%, test acc: 88.96%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.03477163400848701\n",
            "Epoch 68 / 200: avg. grad_norm of last epoch 1.423829488040517\n",
            "Current train acc: 98.61833333333334%, test acc: 89.03%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.037082152978579225\n",
            "Epoch 69 / 200: avg. grad_norm of last epoch 1.6467611809851714\n",
            "Current train acc: 96.86166666666666%, test acc: 87.97%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.037264185414711666\n",
            "Epoch 70 / 200: avg. grad_norm of last epoch 1.5799089383015632\n",
            "Current train acc: 98.46333333333334%, test acc: 88.62%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.03697557139794032\n",
            "Epoch 71 / 200: avg. grad_norm of last epoch 1.6695795877093713\n",
            "Current train acc: 98.97333333333333%, test acc: 89.29%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.03155209584236144\n",
            "Epoch 72 / 200: avg. grad_norm of last epoch 1.350039855336963\n",
            "Current train acc: 98.79833333333333%, test acc: 89.24%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.02792166969428459\n",
            "Epoch 73 / 200: avg. grad_norm of last epoch 1.1634501209884476\n",
            "Current train acc: 97.99166666666666%, test acc: 89.05%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.03162422259946666\n",
            "Epoch 74 / 200: avg. grad_norm of last epoch 1.4229886083897823\n",
            "Current train acc: 97.87833333333333%, test acc: 88.77%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.02836946596205233\n",
            "Epoch 75 / 200: avg. grad_norm of last epoch 1.2655971921188862\n",
            "Current train acc: 99.29333333333334%, test acc: 89.64%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.034068773405750596\n",
            "Epoch 76 / 200: avg. grad_norm of last epoch 1.7182333870005164\n",
            "Current train acc: 99.09333333333333%, test acc: 89.37%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.03040239172577855\n",
            "Epoch 77 / 200: avg. grad_norm of last epoch 1.59486306155624\n",
            "Current train acc: 99.03833333333333%, test acc: 89.32%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.03343139463787276\n",
            "Epoch 78 / 200: avg. grad_norm of last epoch 1.7700940633069102\n",
            "Current train acc: 98.65833333333333%, test acc: 89.21%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.03983423165977006\n",
            "Epoch 79 / 200: avg. grad_norm of last epoch 2.1445636844179954\n",
            "Current train acc: 98.95166666666667%, test acc: 89.19%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.036384036753574996\n",
            "Epoch 80 / 200: avg. grad_norm of last epoch 1.900857058319473\n",
            "Current train acc: 97.86333333333333%, test acc: 88.09%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.02464669124645491\n",
            "Epoch 81 / 200: avg. grad_norm of last epoch 1.2175261180151926\n",
            "Current train acc: 98.44166666666666%, test acc: 88.81%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.0270813987279932\n",
            "Epoch 82 / 200: avg. grad_norm of last epoch 1.3643820025988063\n",
            "Current train acc: 99.24333333333334%, test acc: 89.46%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.020204902484019606\n",
            "Epoch 83 / 200: avg. grad_norm of last epoch 0.8949928170106309\n",
            "Current train acc: 99.54333333333334%, test acc: 89.49%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.02008089912558594\n",
            "Epoch 84 / 200: avg. grad_norm of last epoch 1.0496821983986289\n",
            "Current train acc: 99.31333333333333%, test acc: 89.4%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.022459063531458368\n",
            "Epoch 85 / 200: avg. grad_norm of last epoch 1.1320096172146092\n",
            "Current train acc: 98.97833333333334%, test acc: 89.21%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.01752309605826934\n",
            "Epoch 86 / 200: avg. grad_norm of last epoch 0.8459104513032183\n",
            "Current train acc: 99.43666666666667%, test acc: 89.85%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.01572688097481927\n",
            "Epoch 87 / 200: avg. grad_norm of last epoch 0.7481600636185515\n",
            "Current train acc: 98.34%, test acc: 89.23%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.017417219280699885\n",
            "Epoch 88 / 200: avg. grad_norm of last epoch 0.898234065361728\n",
            "Current train acc: 99.64833333333333%, test acc: 89.54%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.01686911781380573\n",
            "Epoch 89 / 200: avg. grad_norm of last epoch 0.883704880228544\n",
            "Current train acc: 98.74833333333333%, test acc: 89.24%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.01854391236851613\n",
            "Epoch 90 / 200: avg. grad_norm of last epoch 0.9804071851590351\n",
            "Current train acc: 99.805%, test acc: 89.82%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.013189024107158193\n",
            "Epoch 91 / 200: avg. grad_norm of last epoch 0.6370298602325396\n",
            "Current train acc: 99.29166666666667%, test acc: 89.66%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.011710451593746745\n",
            "Epoch 92 / 200: avg. grad_norm of last epoch 0.5739645732270816\n",
            "Current train acc: 99.085%, test acc: 89.31%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.026652594082554198\n",
            "Epoch 93 / 200: avg. grad_norm of last epoch 1.6799922580177975\n",
            "Current train acc: 99.62333333333333%, test acc: 89.61%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.008453354681221152\n",
            "Epoch 94 / 200: avg. grad_norm of last epoch 0.35920090167645985\n",
            "Current train acc: 99.88166666666666%, test acc: 89.64%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.008024843133303029\n",
            "Epoch 95 / 200: avg. grad_norm of last epoch 0.35489658428284643\n",
            "Current train acc: 99.84%, test acc: 89.72%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.00922448739670217\n",
            "Epoch 96 / 200: avg. grad_norm of last epoch 0.4683345460631923\n",
            "Current train acc: 99.76%, test acc: 89.55%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.008828380701504646\n",
            "Epoch 97 / 200: avg. grad_norm of last epoch 0.47835100086135596\n",
            "Current train acc: 99.56%, test acc: 89.42%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.006937278826472659\n",
            "Epoch 98 / 200: avg. grad_norm of last epoch 0.33183159518393196\n",
            "Current train acc: 99.61666666666666%, test acc: 89.65%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.018884423434548093\n",
            "Epoch 99 / 200: avg. grad_norm of last epoch 1.2755537927831202\n",
            "Current train acc: 99.52333333333333%, test acc: 89.22%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.03370406227676819\n",
            "Epoch 100 / 200: avg. grad_norm of last epoch 2.2763996887455167\n",
            "Current train acc: 96.675%, test acc: 87.52%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.05519627336959041\n",
            "Epoch 101 / 200: avg. grad_norm of last epoch 3.5407944458301523\n",
            "Current train acc: 99.21833333333333%, test acc: 89.2%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.02893116581266127\n",
            "Epoch 102 / 200: avg. grad_norm of last epoch 1.915791046429177\n",
            "Current train acc: 98.72%, test acc: 89.21%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.01713074644419057\n",
            "Epoch 103 / 200: avg. grad_norm of last epoch 0.9752683245039223\n",
            "Current train acc: 99.78166666666667%, test acc: 89.78%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.006649810953872906\n",
            "Epoch 104 / 200: avg. grad_norm of last epoch 0.2870174391697276\n",
            "Current train acc: 99.89333333333333%, test acc: 89.63%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.0055507842220366\n",
            "Epoch 105 / 200: avg. grad_norm of last epoch 0.2494818267210592\n",
            "Current train acc: 99.685%, test acc: 89.66%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.0035443422023750245\n",
            "Epoch 106 / 200: avg. grad_norm of last epoch 0.11305979448352692\n",
            "Current train acc: 99.98333333333333%, test acc: 89.93%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.00254540888170401\n",
            "Epoch 107 / 200: avg. grad_norm of last epoch 0.061845344704214135\n",
            "Current train acc: 99.99333333333334%, test acc: 89.82%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.0021951912073418503\n",
            "Epoch 108 / 200: avg. grad_norm of last epoch 0.05574292324363212\n",
            "Current train acc: 99.98833333333333%, test acc: 89.87%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.001889938929428656\n",
            "Epoch 109 / 200: avg. grad_norm of last epoch 0.041049705497190794\n",
            "Current train acc: 99.985%, test acc: 89.75%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.0014398735472001133\n",
            "Epoch 110 / 200: avg. grad_norm of last epoch 0.022677228497066614\n",
            "Current train acc: 99.99166666666666%, test acc: 89.92%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.001229816353895392\n",
            "Epoch 111 / 200: avg. grad_norm of last epoch 0.015300135061508856\n",
            "Current train acc: 99.99833333333333%, test acc: 89.85%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.0011039434563058128\n",
            "Epoch 112 / 200: avg. grad_norm of last epoch 0.012307233254810434\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.0034888560519553747\n",
            "Epoch 113 / 200: avg. grad_norm of last epoch 0.17388891949932084\n",
            "Current train acc: 99.99%, test acc: 89.85%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.0010825101476473105\n",
            "Epoch 114 / 200: avg. grad_norm of last epoch 0.012650877679948087\n",
            "Current train acc: 99.99666666666667%, test acc: 89.9%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.0009407432798917087\n",
            "Epoch 115 / 200: avg. grad_norm of last epoch 0.009691858523378104\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.0008653680625371628\n",
            "Epoch 116 / 200: avg. grad_norm of last epoch 0.008052200658457196\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.0007660489862474302\n",
            "Epoch 117 / 200: avg. grad_norm of last epoch 0.005381978197287398\n",
            "Current train acc: 100.0%, test acc: 89.88%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.0007477751234235863\n",
            "Epoch 118 / 200: avg. grad_norm of last epoch 0.005701335594339865\n",
            "Current train acc: 100.0%, test acc: 89.95%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.0007063141719438133\n",
            "Epoch 119 / 200: avg. grad_norm of last epoch 0.0047444524399053\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.0006832831008515015\n",
            "Epoch 120 / 200: avg. grad_norm of last epoch 0.004835735541893443\n",
            "Current train acc: 100.0%, test acc: 89.86%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.0006481459037711224\n",
            "Epoch 121 / 200: avg. grad_norm of last epoch 0.004310011702644658\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.0006198717525694517\n",
            "Epoch 122 / 200: avg. grad_norm of last epoch 0.0037924380468217487\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.0005914329161091394\n",
            "Epoch 123 / 200: avg. grad_norm of last epoch 0.003318298921559149\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 124 / 200: avg. loss of last epoch 0.0005817028335916504\n",
            "Epoch 124 / 200: avg. grad_norm of last epoch 0.0033180927255866345\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 125 / 200: avg. loss of last epoch 0.0005538993090158327\n",
            "Epoch 125 / 200: avg. grad_norm of last epoch 0.0028289285399055205\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 126 / 200: avg. loss of last epoch 0.0005326674545959883\n",
            "Epoch 126 / 200: avg. grad_norm of last epoch 0.0026423253437425106\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 127 / 200: avg. loss of last epoch 0.000509317682504965\n",
            "Epoch 127 / 200: avg. grad_norm of last epoch 0.0022525848643441706\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 128 / 200: avg. loss of last epoch 0.0004993668368183233\n",
            "Epoch 128 / 200: avg. grad_norm of last epoch 0.0023225913398325815\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 129 / 200: avg. loss of last epoch 0.0004825201455891754\n",
            "Epoch 129 / 200: avg. grad_norm of last epoch 0.002065596309608872\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 130 / 200: avg. loss of last epoch 0.0004655821763755132\n",
            "Epoch 130 / 200: avg. grad_norm of last epoch 0.001940964879928577\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 131 / 200: avg. loss of last epoch 0.00045517853518637513\n",
            "Epoch 131 / 200: avg. grad_norm of last epoch 0.0018020960854274416\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 132 / 200: avg. loss of last epoch 0.0004428024059394375\n",
            "Epoch 132 / 200: avg. grad_norm of last epoch 0.0017727066536610343\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 133 / 200: avg. loss of last epoch 0.00042817777955594157\n",
            "Epoch 133 / 200: avg. grad_norm of last epoch 0.001584268694325668\n",
            "Current train acc: 100.0%, test acc: 89.73%\n",
            "Epoch 134 / 200: avg. loss of last epoch 0.00042269446528516726\n",
            "Epoch 134 / 200: avg. grad_norm of last epoch 0.0016006599634387077\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 135 / 200: avg. loss of last epoch 0.0004103659230167975\n",
            "Epoch 135 / 200: avg. grad_norm of last epoch 0.001512036528280654\n",
            "Current train acc: 100.0%, test acc: 89.85%\n",
            "Epoch 136 / 200: avg. loss of last epoch 0.00040241178918319447\n",
            "Epoch 136 / 200: avg. grad_norm of last epoch 0.0015175382910959804\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 137 / 200: avg. loss of last epoch 0.00039511421154796465\n",
            "Epoch 137 / 200: avg. grad_norm of last epoch 0.0014352340141428708\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 138 / 200: avg. loss of last epoch 0.0003802989892506351\n",
            "Epoch 138 / 200: avg. grad_norm of last epoch 0.0012282226233471369\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 139 / 200: avg. loss of last epoch 0.00037548721885153415\n",
            "Epoch 139 / 200: avg. grad_norm of last epoch 0.0012906535697132173\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 140 / 200: avg. loss of last epoch 0.00036456620283424856\n",
            "Epoch 140 / 200: avg. grad_norm of last epoch 0.0011562104002148744\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 141 / 200: avg. loss of last epoch 0.00035971478091863316\n",
            "Epoch 141 / 200: avg. grad_norm of last epoch 0.0011795905017483806\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 142 / 200: avg. loss of last epoch 0.00035077832213137317\n",
            "Epoch 142 / 200: avg. grad_norm of last epoch 0.0011048051161093935\n",
            "Current train acc: 100.0%, test acc: 89.86%\n",
            "Epoch 143 / 200: avg. loss of last epoch 0.0003428058459423484\n",
            "Epoch 143 / 200: avg. grad_norm of last epoch 0.0010703761501596057\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 144 / 200: avg. loss of last epoch 0.00033751892536723345\n",
            "Epoch 144 / 200: avg. grad_norm of last epoch 0.0009745665190461268\n",
            "Current train acc: 100.0%, test acc: 89.81%\n",
            "Epoch 145 / 200: avg. loss of last epoch 0.00033046014187857505\n",
            "Epoch 145 / 200: avg. grad_norm of last epoch 0.0009449988844124895\n",
            "Current train acc: 100.0%, test acc: 89.9%\n",
            "Epoch 146 / 200: avg. loss of last epoch 0.0003250626090060301\n",
            "Epoch 146 / 200: avg. grad_norm of last epoch 0.0009626605492639135\n",
            "Current train acc: 100.0%, test acc: 89.74%\n",
            "Epoch 147 / 200: avg. loss of last epoch 0.0003179246677240976\n",
            "Epoch 147 / 200: avg. grad_norm of last epoch 0.000866199070022364\n",
            "Current train acc: 100.0%, test acc: 89.88%\n",
            "Epoch 148 / 200: avg. loss of last epoch 0.00031479931202096266\n",
            "Epoch 148 / 200: avg. grad_norm of last epoch 0.0008872178452302315\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 149 / 200: avg. loss of last epoch 0.000308176121332993\n",
            "Epoch 149 / 200: avg. grad_norm of last epoch 0.0008425256465223758\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 150 / 200: avg. loss of last epoch 0.00030092898474540534\n",
            "Epoch 150 / 200: avg. grad_norm of last epoch 0.0007880165055746432\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 151 / 200: avg. loss of last epoch 0.0002977563797341037\n",
            "Epoch 151 / 200: avg. grad_norm of last epoch 0.0007934199567148827\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 152 / 200: avg. loss of last epoch 0.0002908498256855332\n",
            "Epoch 152 / 200: avg. grad_norm of last epoch 0.0007524365441937704\n",
            "Current train acc: 100.0%, test acc: 89.73%\n",
            "Epoch 153 / 200: avg. loss of last epoch 0.000287862023594789\n",
            "Epoch 153 / 200: avg. grad_norm of last epoch 0.000707072701228384\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 154 / 200: avg. loss of last epoch 0.0002842788372421637\n",
            "Epoch 154 / 200: avg. grad_norm of last epoch 0.0007226830218597138\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 155 / 200: avg. loss of last epoch 0.00028045162077372266\n",
            "Epoch 155 / 200: avg. grad_norm of last epoch 0.0006949652503831417\n",
            "Current train acc: 100.0%, test acc: 89.85%\n",
            "Epoch 156 / 200: avg. loss of last epoch 0.00027267883704820033\n",
            "Epoch 156 / 200: avg. grad_norm of last epoch 0.0006467274752430698\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 157 / 200: avg. loss of last epoch 0.00027093275416797616\n",
            "Epoch 157 / 200: avg. grad_norm of last epoch 0.0006620453325632648\n",
            "Current train acc: 100.0%, test acc: 89.87%\n",
            "Epoch 158 / 200: avg. loss of last epoch 0.00026581486258655775\n",
            "Epoch 158 / 200: avg. grad_norm of last epoch 0.0006347294808820023\n",
            "Current train acc: 100.0%, test acc: 89.86%\n",
            "Epoch 159 / 200: avg. loss of last epoch 0.00026237196901735546\n",
            "Epoch 159 / 200: avg. grad_norm of last epoch 0.000601839888523788\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 160 / 200: avg. loss of last epoch 0.00025744656084571025\n",
            "Epoch 160 / 200: avg. grad_norm of last epoch 0.0005697911210870039\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 161 / 200: avg. loss of last epoch 0.00025472077888747047\n",
            "Epoch 161 / 200: avg. grad_norm of last epoch 0.00059882599109882\n",
            "Current train acc: 100.0%, test acc: 89.85%\n",
            "Epoch 162 / 200: avg. loss of last epoch 0.0002523140448844062\n",
            "Epoch 162 / 200: avg. grad_norm of last epoch 0.0005749028215927669\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 163 / 200: avg. loss of last epoch 0.0002479287655868879\n",
            "Epoch 163 / 200: avg. grad_norm of last epoch 0.0005311785592421736\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 164 / 200: avg. loss of last epoch 0.0002446494908149664\n",
            "Epoch 164 / 200: avg. grad_norm of last epoch 0.0005552508569727301\n",
            "Current train acc: 100.0%, test acc: 89.77%\n",
            "Epoch 165 / 200: avg. loss of last epoch 0.000240687277726829\n",
            "Epoch 165 / 200: avg. grad_norm of last epoch 0.0005088696868973389\n",
            "Current train acc: 100.0%, test acc: 89.8%\n",
            "Epoch 166 / 200: avg. loss of last epoch 0.00023816425756085653\n",
            "Epoch 166 / 200: avg. grad_norm of last epoch 0.0005035777886172549\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 167 / 200: avg. loss of last epoch 0.00023536731786249834\n",
            "Epoch 167 / 200: avg. grad_norm of last epoch 0.00048414555261353404\n",
            "Current train acc: 100.0%, test acc: 89.76%\n",
            "Epoch 168 / 200: avg. loss of last epoch 0.00023153932286271202\n",
            "Epoch 168 / 200: avg. grad_norm of last epoch 0.0004904004455569823\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 169 / 200: avg. loss of last epoch 0.00022834296939739358\n",
            "Epoch 169 / 200: avg. grad_norm of last epoch 0.00045782775947097776\n",
            "Current train acc: 100.0%, test acc: 89.78%\n",
            "Epoch 170 / 200: avg. loss of last epoch 0.0002252110830430564\n",
            "Epoch 170 / 200: avg. grad_norm of last epoch 0.00044599972795124544\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 171 / 200: avg. loss of last epoch 0.00022221041241039834\n",
            "Epoch 171 / 200: avg. grad_norm of last epoch 0.0004146246973644999\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 172 / 200: avg. loss of last epoch 0.0002197589114812826\n",
            "Epoch 172 / 200: avg. grad_norm of last epoch 0.0004332649941288838\n",
            "Current train acc: 100.0%, test acc: 89.86%\n",
            "Epoch 173 / 200: avg. loss of last epoch 0.00021636449365566165\n",
            "Epoch 173 / 200: avg. grad_norm of last epoch 0.00041070331130718197\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 174 / 200: avg. loss of last epoch 0.0002142253909842111\n",
            "Epoch 174 / 200: avg. grad_norm of last epoch 0.00040806483298728936\n",
            "Current train acc: 100.0%, test acc: 89.91%\n",
            "Epoch 175 / 200: avg. loss of last epoch 0.0002117700505730077\n",
            "Epoch 175 / 200: avg. grad_norm of last epoch 0.000389596161426049\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 176 / 200: avg. loss of last epoch 0.00020987652653905886\n",
            "Epoch 176 / 200: avg. grad_norm of last epoch 0.00038996375498332955\n",
            "Current train acc: 100.0%, test acc: 89.9%\n",
            "Epoch 177 / 200: avg. loss of last epoch 0.000206945409226076\n",
            "Epoch 177 / 200: avg. grad_norm of last epoch 0.000388448043666752\n",
            "Current train acc: 100.0%, test acc: 89.87%\n",
            "Epoch 178 / 200: avg. loss of last epoch 0.00020444642230480275\n",
            "Epoch 178 / 200: avg. grad_norm of last epoch 0.00036449627307545565\n",
            "Current train acc: 100.0%, test acc: 89.91%\n",
            "Epoch 179 / 200: avg. loss of last epoch 0.00020253881691799822\n",
            "Epoch 179 / 200: avg. grad_norm of last epoch 0.00036914348464288886\n",
            "Current train acc: 100.0%, test acc: 89.86%\n",
            "Epoch 180 / 200: avg. loss of last epoch 0.00020066944899347936\n",
            "Epoch 180 / 200: avg. grad_norm of last epoch 0.0003605661700340812\n",
            "Current train acc: 100.0%, test acc: 89.79%\n",
            "Epoch 181 / 200: avg. loss of last epoch 0.00019821991733430562\n",
            "Epoch 181 / 200: avg. grad_norm of last epoch 0.00034513745784736557\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 182 / 200: avg. loss of last epoch 0.00019577727763292702\n",
            "Epoch 182 / 200: avg. grad_norm of last epoch 0.0003414368888007807\n",
            "Current train acc: 100.0%, test acc: 89.88%\n",
            "Epoch 183 / 200: avg. loss of last epoch 0.0001939340742343726\n",
            "Epoch 183 / 200: avg. grad_norm of last epoch 0.0003301216623653111\n",
            "Current train acc: 100.0%, test acc: 89.91%\n",
            "Epoch 184 / 200: avg. loss of last epoch 0.00019132362811748557\n",
            "Epoch 184 / 200: avg. grad_norm of last epoch 0.00032733004588296005\n",
            "Current train acc: 100.0%, test acc: 89.89%\n",
            "Epoch 185 / 200: avg. loss of last epoch 0.00019038452754030008\n",
            "Epoch 185 / 200: avg. grad_norm of last epoch 0.00032930312158811493\n",
            "Current train acc: 100.0%, test acc: 89.87%\n",
            "Epoch 186 / 200: avg. loss of last epoch 0.00018789556483582895\n",
            "Epoch 186 / 200: avg. grad_norm of last epoch 0.0003156040340181184\n",
            "Current train acc: 100.0%, test acc: 89.92%\n",
            "Epoch 187 / 200: avg. loss of last epoch 0.00018596356154885162\n",
            "Epoch 187 / 200: avg. grad_norm of last epoch 0.0003184276871096286\n",
            "Current train acc: 100.0%, test acc: 89.87%\n",
            "Epoch 188 / 200: avg. loss of last epoch 0.0001837429580821965\n",
            "Epoch 188 / 200: avg. grad_norm of last epoch 0.000302495738213674\n",
            "Current train acc: 100.0%, test acc: 89.88%\n",
            "Epoch 189 / 200: avg. loss of last epoch 0.00018168039889618129\n",
            "Epoch 189 / 200: avg. grad_norm of last epoch 0.00029761932920125593\n",
            "Current train acc: 100.0%, test acc: 89.88%\n",
            "Epoch 190 / 200: avg. loss of last epoch 0.00018020761949398258\n",
            "Epoch 190 / 200: avg. grad_norm of last epoch 0.00028492694130082316\n",
            "Current train acc: 100.0%, test acc: 89.9%\n",
            "Epoch 191 / 200: avg. loss of last epoch 0.0001781937195773935\n",
            "Epoch 191 / 200: avg. grad_norm of last epoch 0.00028494148744327675\n",
            "Current train acc: 100.0%, test acc: 89.92%\n",
            "Epoch 192 / 200: avg. loss of last epoch 0.00017731753203164175\n",
            "Epoch 192 / 200: avg. grad_norm of last epoch 0.0002814902009733159\n",
            "Current train acc: 100.0%, test acc: 89.92%\n",
            "Epoch 193 / 200: avg. loss of last epoch 0.00017515206031578883\n",
            "Epoch 193 / 200: avg. grad_norm of last epoch 0.00028090728702284006\n",
            "Current train acc: 100.0%, test acc: 89.92%\n",
            "Epoch 194 / 200: avg. loss of last epoch 0.00017311197217398621\n",
            "Epoch 194 / 200: avg. grad_norm of last epoch 0.0002662584720768681\n",
            "Current train acc: 100.0%, test acc: 89.92%\n",
            "Epoch 195 / 200: avg. loss of last epoch 0.00017087912826876472\n",
            "Epoch 195 / 200: avg. grad_norm of last epoch 0.0002587616049547902\n",
            "Current train acc: 100.0%, test acc: 89.83%\n",
            "Epoch 196 / 200: avg. loss of last epoch 0.00016959155222478627\n",
            "Epoch 196 / 200: avg. grad_norm of last epoch 0.00025501333867678985\n",
            "Current train acc: 100.0%, test acc: 89.93%\n",
            "Epoch 197 / 200: avg. loss of last epoch 0.0001681262666010297\n",
            "Epoch 197 / 200: avg. grad_norm of last epoch 0.00025047351966318984\n",
            "Current train acc: 100.0%, test acc: 89.92%\n",
            "Epoch 198 / 200: avg. loss of last epoch 0.00016629266322900856\n",
            "Epoch 198 / 200: avg. grad_norm of last epoch 0.0002510860149919798\n",
            "Current train acc: 100.0%, test acc: 89.84%\n",
            "Epoch 199 / 200: avg. loss of last epoch 0.00016510256542048103\n",
            "Epoch 199 / 200: avg. grad_norm of last epoch 0.00024211878310551282\n",
            "Current train acc: 100.0%, test acc: 89.82%\n",
            "Epoch 200 / 200: avg. loss of last epoch 0.00016327647393336517\n",
            "Epoch 200 / 200: avg. grad_norm of last epoch 0.00023774368045988153\n",
            "Current train acc: 100.0%, test acc: 89.91%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epochs = 200\n",
        "\n",
        "scheduler = constant_learning_rate_scheduler(0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "sgd_history = train(model, criterion, optimizer, epochs, fashion_train_loader, fashion_test_loader, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k98sqh5UnoNS"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/Fashion-Other-Optimizers/SGD_constantLR.json\", sgd_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Z2JL5qSQ4DtF",
        "outputId": "234471e9-e004-4daf-9b86-d4423317b9ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4906d4ab50>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss(sgd_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQvLPfXvxnCc"
      },
      "source": [
        "## Training with SGD-M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLqpR8vZxovt",
        "outputId": "7694327c-2a64-4792-d02c-a08b39f2fbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.5265689983367925\n",
            "Epoch 1 / 200: avg. grad_norm of last epoch 2.203323254980231\n",
            "Current train acc: 85.255%, test acc: 84.22%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.3649269423484808\n",
            "Epoch 2 / 200: avg. grad_norm of last epoch 1.4324729568200016\n",
            "Current train acc: 87.79333333333334%, test acc: 85.82%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.3279834268252057\n",
            "Epoch 3 / 200: avg. grad_norm of last epoch 1.4087870502289095\n",
            "Current train acc: 88.08333333333333%, test acc: 86.24%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.3004998928070065\n",
            "Epoch 4 / 200: avg. grad_norm of last epoch 1.2846484686092934\n",
            "Current train acc: 89.15%, test acc: 86.82%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.2808242664019266\n",
            "Epoch 5 / 200: avg. grad_norm of last epoch 1.2535945827248853\n",
            "Current train acc: 90.015%, test acc: 87.23%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.26692433131535853\n",
            "Epoch 6 / 200: avg. grad_norm of last epoch 1.30101703815272\n",
            "Current train acc: 91.105%, test acc: 88.11%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.25055265997250886\n",
            "Epoch 7 / 200: avg. grad_norm of last epoch 1.24109574785619\n",
            "Current train acc: 91.56%, test acc: 88.37%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.23729700498580936\n",
            "Epoch 8 / 200: avg. grad_norm of last epoch 1.2135439111098276\n",
            "Current train acc: 90.79166666666667%, test acc: 86.96%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.22751833014488232\n",
            "Epoch 9 / 200: avg. grad_norm of last epoch 1.2413108032848275\n",
            "Current train acc: 91.44666666666667%, test acc: 87.98%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.21862643791834496\n",
            "Epoch 10 / 200: avg. grad_norm of last epoch 1.2506481088335883\n",
            "Current train acc: 91.77%, test acc: 87.92%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.20850328586896258\n",
            "Epoch 11 / 200: avg. grad_norm of last epoch 1.2559524909932234\n",
            "Current train acc: 92.665%, test acc: 88.35%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.20161015208562222\n",
            "Epoch 12 / 200: avg. grad_norm of last epoch 1.290752041243774\n",
            "Current train acc: 93.08666666666667%, test acc: 88.79%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.19038255951404565\n",
            "Epoch 13 / 200: avg. grad_norm of last epoch 1.2324605727985494\n",
            "Current train acc: 93.51166666666667%, test acc: 88.89%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.18446738104820265\n",
            "Epoch 14 / 200: avg. grad_norm of last epoch 1.2750556626406429\n",
            "Current train acc: 93.83833333333334%, test acc: 88.89%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.17683381251096728\n",
            "Epoch 15 / 200: avg. grad_norm of last epoch 1.289462719902754\n",
            "Current train acc: 94.22666666666667%, test acc: 89.11%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.17211034447749454\n",
            "Epoch 16 / 200: avg. grad_norm of last epoch 1.340689804238374\n",
            "Current train acc: 93.68%, test acc: 88.73%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.1627818696459134\n",
            "Epoch 17 / 200: avg. grad_norm of last epoch 1.289723678590995\n",
            "Current train acc: 93.85166666666667%, test acc: 88.88%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.15675884769757592\n",
            "Epoch 18 / 200: avg. grad_norm of last epoch 1.3096965859192038\n",
            "Current train acc: 94.61166666666666%, test acc: 89.21%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.1513496731042861\n",
            "Epoch 19 / 200: avg. grad_norm of last epoch 1.3220450143063651\n",
            "Current train acc: 94.70666666666666%, test acc: 88.92%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.14624249180157972\n",
            "Epoch 20 / 200: avg. grad_norm of last epoch 1.2986218449647173\n",
            "Current train acc: 94.29833333333333%, test acc: 88.38%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.14455723359584816\n",
            "Epoch 21 / 200: avg. grad_norm of last epoch 1.4207177719498933\n",
            "Current train acc: 94.68%, test acc: 88.89%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.1358424194216729\n",
            "Epoch 22 / 200: avg. grad_norm of last epoch 1.2776860037852482\n",
            "Current train acc: 95.31666666666666%, test acc: 89.31%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.13084094617764153\n",
            "Epoch 23 / 200: avg. grad_norm of last epoch 1.3021898182001355\n",
            "Current train acc: 95.31666666666666%, test acc: 89.24%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.12707034622033445\n",
            "Epoch 24 / 200: avg. grad_norm of last epoch 1.2567075167732964\n",
            "Current train acc: 94.95%, test acc: 88.74%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.12355789595444991\n",
            "Epoch 25 / 200: avg. grad_norm of last epoch 1.3413884772034372\n",
            "Current train acc: 94.8%, test acc: 88.31%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.12267923050324116\n",
            "Epoch 26 / 200: avg. grad_norm of last epoch 1.3935505437092162\n",
            "Current train acc: 95.145%, test acc: 88.43%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.11424278324047722\n",
            "Epoch 27 / 200: avg. grad_norm of last epoch 1.2490812605402515\n",
            "Current train acc: 95.925%, test acc: 88.93%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.11016012589732813\n",
            "Epoch 28 / 200: avg. grad_norm of last epoch 1.2496743877787286\n",
            "Current train acc: 96.29166666666667%, test acc: 89.2%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.11199741888840989\n",
            "Epoch 29 / 200: avg. grad_norm of last epoch 1.4013731276446342\n",
            "Current train acc: 96.28333333333333%, test acc: 89.11%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.10272603811820347\n",
            "Epoch 30 / 200: avg. grad_norm of last epoch 1.2184293902316217\n",
            "Current train acc: 96.45%, test acc: 89.19%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.10266240439414984\n",
            "Epoch 31 / 200: avg. grad_norm of last epoch 1.2894133614351682\n",
            "Current train acc: 96.27%, test acc: 89.36%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.10071628360748296\n",
            "Epoch 32 / 200: avg. grad_norm of last epoch 1.3337613657818161\n",
            "Current train acc: 95.74166666666666%, test acc: 88.72%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.09901079098383586\n",
            "Epoch 33 / 200: avg. grad_norm of last epoch 1.4102601039198297\n",
            "Current train acc: 96.87833333333333%, test acc: 89.37%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.09574566127657888\n",
            "Epoch 34 / 200: avg. grad_norm of last epoch 1.3590530843793764\n",
            "Current train acc: 96.45%, test acc: 89.02%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.09243380434910453\n",
            "Epoch 35 / 200: avg. grad_norm of last epoch 1.3091865093995971\n",
            "Current train acc: 97.175%, test acc: 89.53%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.08843328251640002\n",
            "Epoch 36 / 200: avg. grad_norm of last epoch 1.294437703305416\n",
            "Current train acc: 97.03166666666667%, test acc: 89.34%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.08486772083838777\n",
            "Epoch 37 / 200: avg. grad_norm of last epoch 1.2488564678523855\n",
            "Current train acc: 96.55333333333333%, test acc: 88.59%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.08450611416002107\n",
            "Epoch 38 / 200: avg. grad_norm of last epoch 1.3486598782420056\n",
            "Current train acc: 96.93166666666667%, test acc: 89.07%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.08308451285560932\n",
            "Epoch 39 / 200: avg. grad_norm of last epoch 1.2972110555380778\n",
            "Current train acc: 97.44%, test acc: 89.32%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.08112967867851262\n",
            "Epoch 40 / 200: avg. grad_norm of last epoch 1.333615757885275\n",
            "Current train acc: 97.60833333333333%, test acc: 89.16%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.07409135155677798\n",
            "Epoch 41 / 200: avg. grad_norm of last epoch 1.1511876055753238\n",
            "Current train acc: 97.105%, test acc: 89.31%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.07774138956467307\n",
            "Epoch 42 / 200: avg. grad_norm of last epoch 1.3402225636429033\n",
            "Current train acc: 96.58833333333334%, test acc: 88.78%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.07026664343973005\n",
            "Epoch 43 / 200: avg. grad_norm of last epoch 1.1278350175010625\n",
            "Current train acc: 96.86666666666666%, test acc: 88.51%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.0682448526670535\n",
            "Epoch 44 / 200: avg. grad_norm of last epoch 1.138859812562254\n",
            "Current train acc: 97.77166666666666%, test acc: 89.28%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.06745028149485584\n",
            "Epoch 45 / 200: avg. grad_norm of last epoch 1.2260476562136098\n",
            "Current train acc: 97.72166666666666%, test acc: 89.13%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.06975453743338587\n",
            "Epoch 46 / 200: avg. grad_norm of last epoch 1.3152786865260748\n",
            "Current train acc: 97.78833333333333%, test acc: 88.93%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.06497357958058518\n",
            "Epoch 47 / 200: avg. grad_norm of last epoch 1.1677972805154866\n",
            "Current train acc: 98.105%, test acc: 89.05%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.061766051381826365\n",
            "Epoch 48 / 200: avg. grad_norm of last epoch 1.178491708122507\n",
            "Current train acc: 98.095%, test acc: 89.11%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.0638752411286036\n",
            "Epoch 49 / 200: avg. grad_norm of last epoch 1.2699045814766077\n",
            "Current train acc: 97.65333333333334%, test acc: 89.1%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.05905182867149512\n",
            "Epoch 50 / 200: avg. grad_norm of last epoch 1.115752836309463\n",
            "Current train acc: 97.30166666666666%, test acc: 88.5%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.06340503262082742\n",
            "Epoch 51 / 200: avg. grad_norm of last epoch 1.380103091342801\n",
            "Current train acc: 97.91833333333334%, test acc: 89.46%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.06618028637568163\n",
            "Epoch 52 / 200: avg. grad_norm of last epoch 1.4781781766742021\n",
            "Current train acc: 97.87833333333333%, test acc: 88.88%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.0605657243331273\n",
            "Epoch 53 / 200: avg. grad_norm of last epoch 1.3018242630798853\n",
            "Current train acc: 98.275%, test acc: 89.12%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.05675795533657072\n",
            "Epoch 54 / 200: avg. grad_norm of last epoch 1.1769043637084124\n",
            "Current train acc: 98.00666666666666%, test acc: 89.14%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.05251119729429481\n",
            "Epoch 55 / 200: avg. grad_norm of last epoch 1.067273219127315\n",
            "Current train acc: 97.71333333333334%, test acc: 88.78%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.05415614863832789\n",
            "Epoch 56 / 200: avg. grad_norm of last epoch 1.156275112170794\n",
            "Current train acc: 98.39%, test acc: 89.68%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.059798702757557234\n",
            "Epoch 57 / 200: avg. grad_norm of last epoch 1.5768861001243675\n",
            "Current train acc: 98.13833333333334%, test acc: 88.87%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.052873644769191805\n",
            "Epoch 58 / 200: avg. grad_norm of last epoch 1.2265661494697557\n",
            "Current train acc: 98.53666666666666%, test acc: 89.44%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.05128498338262238\n",
            "Epoch 59 / 200: avg. grad_norm of last epoch 1.184930786584958\n",
            "Current train acc: 97.95666666666666%, test acc: 89.06%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.049491354294369606\n",
            "Epoch 60 / 200: avg. grad_norm of last epoch 1.1658700313821762\n",
            "Current train acc: 98.61833333333334%, test acc: 89.64%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.04782817346155644\n",
            "Epoch 61 / 200: avg. grad_norm of last epoch 1.148786540469492\n",
            "Current train acc: 98.51333333333334%, test acc: 89.58%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.04356541830847659\n",
            "Epoch 62 / 200: avg. grad_norm of last epoch 1.0070836816022528\n",
            "Current train acc: 98.55666666666667%, test acc: 89.15%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.045012110561629196\n",
            "Epoch 63 / 200: avg. grad_norm of last epoch 1.0820444922918202\n",
            "Current train acc: 98.49333333333334%, test acc: 89.21%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.043484987649321585\n",
            "Epoch 64 / 200: avg. grad_norm of last epoch 1.0583214618867942\n",
            "Current train acc: 98.54166666666667%, test acc: 89.47%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.042810729718704976\n",
            "Epoch 65 / 200: avg. grad_norm of last epoch 1.0179907693565902\n",
            "Current train acc: 98.25%, test acc: 89.04%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.03997370158135889\n",
            "Epoch 66 / 200: avg. grad_norm of last epoch 0.984852468597408\n",
            "Current train acc: 98.69%, test acc: 89.26%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.037374538818498435\n",
            "Epoch 67 / 200: avg. grad_norm of last epoch 0.9130930546951053\n",
            "Current train acc: 98.515%, test acc: 89.43%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.03613949443201225\n",
            "Epoch 68 / 200: avg. grad_norm of last epoch 0.9014924937682032\n",
            "Current train acc: 98.85166666666667%, test acc: 89.29%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.041505514361957714\n",
            "Epoch 69 / 200: avg. grad_norm of last epoch 1.1339467344479701\n",
            "Current train acc: 97.705%, test acc: 88.9%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.03915446579207976\n",
            "Epoch 70 / 200: avg. grad_norm of last epoch 1.0680253248774245\n",
            "Current train acc: 98.57333333333334%, test acc: 89.42%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.04133002180556458\n",
            "Epoch 71 / 200: avg. grad_norm of last epoch 1.1496049904834376\n",
            "Current train acc: 98.16333333333333%, test acc: 89.24%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.04058489546279108\n",
            "Epoch 72 / 200: avg. grad_norm of last epoch 1.1008823672729364\n",
            "Current train acc: 98.68833333333333%, test acc: 89.27%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.03275664966975648\n",
            "Epoch 73 / 200: avg. grad_norm of last epoch 0.923835783878511\n",
            "Current train acc: 98.09166666666667%, test acc: 88.89%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.03464879235873621\n",
            "Epoch 74 / 200: avg. grad_norm of last epoch 0.9196645437011494\n",
            "Current train acc: 98.90166666666667%, test acc: 89.56%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.03582709532777465\n",
            "Epoch 75 / 200: avg. grad_norm of last epoch 1.0748295148819969\n",
            "Current train acc: 98.89666666666666%, test acc: 89.43%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.03305363725125792\n",
            "Epoch 76 / 200: avg. grad_norm of last epoch 0.969515455266158\n",
            "Current train acc: 97.88833333333334%, test acc: 88.73%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.050481346901754535\n",
            "Epoch 77 / 200: avg. grad_norm of last epoch 1.6490461379440418\n",
            "Current train acc: 99.05%, test acc: 89.31%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.03498771762351195\n",
            "Epoch 78 / 200: avg. grad_norm of last epoch 1.038421973757357\n",
            "Current train acc: 98.915%, test acc: 88.92%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.03181863499954342\n",
            "Epoch 79 / 200: avg. grad_norm of last epoch 0.9098399202939145\n",
            "Current train acc: 99.11%, test acc: 89.58%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.033440200152496484\n",
            "Epoch 80 / 200: avg. grad_norm of last epoch 0.9963832015540374\n",
            "Current train acc: 98.76666666666667%, test acc: 89.44%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.03283353676845631\n",
            "Epoch 81 / 200: avg. grad_norm of last epoch 1.0235496573408305\n",
            "Current train acc: 98.16833333333334%, test acc: 88.94%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.03921853028188152\n",
            "Epoch 82 / 200: avg. grad_norm of last epoch 1.316656854138079\n",
            "Current train acc: 98.66666666666667%, test acc: 89.41%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.044368462252616925\n",
            "Epoch 83 / 200: avg. grad_norm of last epoch 1.5851023732370533\n",
            "Current train acc: 99.16666666666667%, test acc: 89.54%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.03425546773125727\n",
            "Epoch 84 / 200: avg. grad_norm of last epoch 1.141011561803838\n",
            "Current train acc: 98.58166666666666%, test acc: 88.85%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.027272071831921745\n",
            "Epoch 85 / 200: avg. grad_norm of last epoch 0.7970023186023588\n",
            "Current train acc: 99.04166666666667%, test acc: 89.38%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.02502077701315283\n",
            "Epoch 86 / 200: avg. grad_norm of last epoch 0.8007655961947139\n",
            "Current train acc: 98.78833333333333%, test acc: 89.23%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.030813304911678028\n",
            "Epoch 87 / 200: avg. grad_norm of last epoch 0.9884511727613305\n",
            "Current train acc: 99.12833333333333%, test acc: 89.23%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.022785095619534464\n",
            "Epoch 88 / 200: avg. grad_norm of last epoch 0.6973772904045277\n",
            "Current train acc: 98.88666666666667%, test acc: 89.2%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.02707291871570049\n",
            "Epoch 89 / 200: avg. grad_norm of last epoch 0.8682868807660793\n",
            "Current train acc: 98.74166666666666%, test acc: 89.2%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.023911890910007064\n",
            "Epoch 90 / 200: avg. grad_norm of last epoch 0.7716339295580755\n",
            "Current train acc: 98.925%, test acc: 89.24%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.028390974982082873\n",
            "Epoch 91 / 200: avg. grad_norm of last epoch 0.990662943720654\n",
            "Current train acc: 98.585%, test acc: 88.76%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.025406029047320276\n",
            "Epoch 92 / 200: avg. grad_norm of last epoch 0.8482807818354524\n",
            "Current train acc: 99.165%, test acc: 89.66%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.024009879410391042\n",
            "Epoch 93 / 200: avg. grad_norm of last epoch 0.8070274099293941\n",
            "Current train acc: 98.97666666666667%, test acc: 89.28%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.032195013452693814\n",
            "Epoch 94 / 200: avg. grad_norm of last epoch 1.1379425852631027\n",
            "Current train acc: 98.87%, test acc: 89.37%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.024104854790866367\n",
            "Epoch 95 / 200: avg. grad_norm of last epoch 0.9091423235225009\n",
            "Current train acc: 99.42833333333333%, test acc: 89.53%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.020385463612278318\n",
            "Epoch 96 / 200: avg. grad_norm of last epoch 0.6662881008548192\n",
            "Current train acc: 99.32666666666667%, test acc: 89.52%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.01605523762122418\n",
            "Epoch 97 / 200: avg. grad_norm of last epoch 0.4782370110857946\n",
            "Current train acc: 99.765%, test acc: 89.9%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.012776596564923737\n",
            "Epoch 98 / 200: avg. grad_norm of last epoch 0.3888559589862759\n",
            "Current train acc: 99.675%, test acc: 89.8%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.03160249685881042\n",
            "Epoch 99 / 200: avg. grad_norm of last epoch 1.3221816111906282\n",
            "Current train acc: 98.54166666666667%, test acc: 89.27%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.03233143794747688\n",
            "Epoch 100 / 200: avg. grad_norm of last epoch 1.1642448149475835\n",
            "Current train acc: 98.79333333333334%, test acc: 89.23%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.0213476292723169\n",
            "Epoch 101 / 200: avg. grad_norm of last epoch 0.7307552814898112\n",
            "Current train acc: 99.57333333333334%, test acc: 89.7%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.02856729203338425\n",
            "Epoch 102 / 200: avg. grad_norm of last epoch 1.0825341919972986\n",
            "Current train acc: 99.28166666666667%, test acc: 89.49%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.02716855967839555\n",
            "Epoch 103 / 200: avg. grad_norm of last epoch 1.012823426258942\n",
            "Current train acc: 99.53833333333333%, test acc: 89.71%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.02036840922472376\n",
            "Epoch 104 / 200: avg. grad_norm of last epoch 0.7747716455154992\n",
            "Current train acc: 97.36166666666666%, test acc: 88.49%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.023719384719834983\n",
            "Epoch 105 / 200: avg. grad_norm of last epoch 0.8830865572287768\n",
            "Current train acc: 99.4%, test acc: 89.44%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.015290609266422709\n",
            "Epoch 106 / 200: avg. grad_norm of last epoch 0.5495669077138258\n",
            "Current train acc: 98.15166666666667%, test acc: 88.65%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.02042261910028759\n",
            "Epoch 107 / 200: avg. grad_norm of last epoch 0.770118650851645\n",
            "Current train acc: 99.425%, test acc: 89.42%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.011821702590119087\n",
            "Epoch 108 / 200: avg. grad_norm of last epoch 0.3853155765646444\n",
            "Current train acc: 99.63333333333334%, test acc: 89.47%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.014175809249980372\n",
            "Epoch 109 / 200: avg. grad_norm of last epoch 0.5431672647970227\n",
            "Current train acc: 99.43166666666667%, test acc: 89.52%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.013196937023103237\n",
            "Epoch 110 / 200: avg. grad_norm of last epoch 0.4562822015499166\n",
            "Current train acc: 99.49833333333333%, test acc: 89.49%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.012364578135094282\n",
            "Epoch 111 / 200: avg. grad_norm of last epoch 0.4347017638298837\n",
            "Current train acc: 99.46666666666667%, test acc: 89.61%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.011918380967605228\n",
            "Epoch 112 / 200: avg. grad_norm of last epoch 0.42189488518172485\n",
            "Current train acc: 99.32%, test acc: 89.43%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.03470777829363942\n",
            "Epoch 113 / 200: avg. grad_norm of last epoch 1.5894746799954282\n",
            "Current train acc: 98.255%, test acc: 88.47%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.030943810234343016\n",
            "Epoch 114 / 200: avg. grad_norm of last epoch 1.2610634956117799\n",
            "Current train acc: 98.845%, test acc: 89.47%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.022898904101550592\n",
            "Epoch 115 / 200: avg. grad_norm of last epoch 1.0317780017208875\n",
            "Current train acc: 99.33166666666666%, test acc: 89.6%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.01613679865362745\n",
            "Epoch 116 / 200: avg. grad_norm of last epoch 0.6320200388012696\n",
            "Current train acc: 99.61833333333334%, test acc: 89.51%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.008149625021250296\n",
            "Epoch 117 / 200: avg. grad_norm of last epoch 0.2768262127196871\n",
            "Current train acc: 99.78833333333333%, test acc: 89.66%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.004793568336591127\n",
            "Epoch 118 / 200: avg. grad_norm of last epoch 0.1497959869796545\n",
            "Current train acc: 99.86333333333333%, test acc: 89.59%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.003287131593989518\n",
            "Epoch 119 / 200: avg. grad_norm of last epoch 0.08224639274375573\n",
            "Current train acc: 99.96166666666667%, test acc: 89.98%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.0017059073916093155\n",
            "Epoch 120 / 200: avg. grad_norm of last epoch 0.03003224862119189\n",
            "Current train acc: 99.97166666666666%, test acc: 89.96%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.0010818023813888432\n",
            "Epoch 121 / 200: avg. grad_norm of last epoch 0.014265817828497545\n",
            "Current train acc: 99.99333333333334%, test acc: 89.99%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.0010406815915640136\n",
            "Epoch 122 / 200: avg. grad_norm of last epoch 0.013835581350055276\n",
            "Current train acc: 99.97666666666667%, test acc: 90.0%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.0011125876168021946\n",
            "Epoch 123 / 200: avg. grad_norm of last epoch 0.021793488052210708\n",
            "Current train acc: 99.995%, test acc: 90.04%\n",
            "Epoch 124 / 200: avg. loss of last epoch 0.001040407674821715\n",
            "Epoch 124 / 200: avg. grad_norm of last epoch 0.02042997382477064\n",
            "Current train acc: 100.0%, test acc: 90.05%\n",
            "Epoch 125 / 200: avg. loss of last epoch 0.0005018637715140353\n",
            "Epoch 125 / 200: avg. grad_norm of last epoch 0.0031462247566580496\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 126 / 200: avg. loss of last epoch 0.00042811085017941243\n",
            "Epoch 126 / 200: avg. grad_norm of last epoch 0.0023564127086495488\n",
            "Current train acc: 100.0%, test acc: 90.13%\n",
            "Epoch 127 / 200: avg. loss of last epoch 0.00039730322363999866\n",
            "Epoch 127 / 200: avg. grad_norm of last epoch 0.0026554031782600566\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 128 / 200: avg. loss of last epoch 0.00032904762338827493\n",
            "Epoch 128 / 200: avg. grad_norm of last epoch 0.0012217427033527838\n",
            "Current train acc: 100.0%, test acc: 89.94%\n",
            "Epoch 129 / 200: avg. loss of last epoch 0.00030789208504914604\n",
            "Epoch 129 / 200: avg. grad_norm of last epoch 0.00111048393998331\n",
            "Current train acc: 100.0%, test acc: 89.99%\n",
            "Epoch 130 / 200: avg. loss of last epoch 0.00027729395227118716\n",
            "Epoch 130 / 200: avg. grad_norm of last epoch 0.0007793366056466811\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 131 / 200: avg. loss of last epoch 0.0002634709798827922\n",
            "Epoch 131 / 200: avg. grad_norm of last epoch 0.0007602428260578897\n",
            "Current train acc: 100.0%, test acc: 90.01%\n",
            "Epoch 132 / 200: avg. loss of last epoch 0.00024877741525318334\n",
            "Epoch 132 / 200: avg. grad_norm of last epoch 0.000672976285931349\n",
            "Current train acc: 100.0%, test acc: 90.12%\n",
            "Epoch 133 / 200: avg. loss of last epoch 0.00023229246237315245\n",
            "Epoch 133 / 200: avg. grad_norm of last epoch 0.0005588467826305859\n",
            "Current train acc: 100.0%, test acc: 90.03%\n",
            "Epoch 134 / 200: avg. loss of last epoch 0.00022021129014707788\n",
            "Epoch 134 / 200: avg. grad_norm of last epoch 0.000471837635582747\n",
            "Current train acc: 100.0%, test acc: 90.01%\n",
            "Epoch 135 / 200: avg. loss of last epoch 0.0002116836641478586\n",
            "Epoch 135 / 200: avg. grad_norm of last epoch 0.00047470834855499293\n",
            "Current train acc: 100.0%, test acc: 90.02%\n",
            "Epoch 136 / 200: avg. loss of last epoch 0.0002046844276968235\n",
            "Epoch 136 / 200: avg. grad_norm of last epoch 0.00043397715747151315\n",
            "Current train acc: 100.0%, test acc: 90.05%\n",
            "Epoch 137 / 200: avg. loss of last epoch 0.00019077216049578682\n",
            "Epoch 137 / 200: avg. grad_norm of last epoch 0.0003318837099970076\n",
            "Current train acc: 100.0%, test acc: 90.06%\n",
            "Epoch 138 / 200: avg. loss of last epoch 0.00018456715664748717\n",
            "Epoch 138 / 200: avg. grad_norm of last epoch 0.00032328244693923436\n",
            "Current train acc: 100.0%, test acc: 90.05%\n",
            "Epoch 139 / 200: avg. loss of last epoch 0.00017790125527050504\n",
            "Epoch 139 / 200: avg. grad_norm of last epoch 0.00030810750370416617\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 140 / 200: avg. loss of last epoch 0.0001720153905684129\n",
            "Epoch 140 / 200: avg. grad_norm of last epoch 0.0002737933206979936\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 141 / 200: avg. loss of last epoch 0.0001674069664567165\n",
            "Epoch 141 / 200: avg. grad_norm of last epoch 0.00028075916591922465\n",
            "Current train acc: 100.0%, test acc: 90.11%\n",
            "Epoch 142 / 200: avg. loss of last epoch 0.00016179527713296315\n",
            "Epoch 142 / 200: avg. grad_norm of last epoch 0.00024561775635439074\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 143 / 200: avg. loss of last epoch 0.00015613020905487545\n",
            "Epoch 143 / 200: avg. grad_norm of last epoch 0.00022881955055936026\n",
            "Current train acc: 100.0%, test acc: 90.11%\n",
            "Epoch 144 / 200: avg. loss of last epoch 0.00015176534403581188\n",
            "Epoch 144 / 200: avg. grad_norm of last epoch 0.00022632424839146045\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 145 / 200: avg. loss of last epoch 0.0001491180389285242\n",
            "Epoch 145 / 200: avg. grad_norm of last epoch 0.0002262213559923478\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 146 / 200: avg. loss of last epoch 0.00014185819512155528\n",
            "Epoch 146 / 200: avg. grad_norm of last epoch 0.0001797378299377982\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 147 / 200: avg. loss of last epoch 0.00014032902735537704\n",
            "Epoch 147 / 200: avg. grad_norm of last epoch 0.00020113166147926975\n",
            "Current train acc: 100.0%, test acc: 90.11%\n",
            "Epoch 148 / 200: avg. loss of last epoch 0.00013694499318031973\n",
            "Epoch 148 / 200: avg. grad_norm of last epoch 0.00018348724556262728\n",
            "Current train acc: 100.0%, test acc: 90.12%\n",
            "Epoch 149 / 200: avg. loss of last epoch 0.00013300244134249324\n",
            "Epoch 149 / 200: avg. grad_norm of last epoch 0.00017349117090316568\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 150 / 200: avg. loss of last epoch 0.00012954178860915514\n",
            "Epoch 150 / 200: avg. grad_norm of last epoch 0.0001648891869801265\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 151 / 200: avg. loss of last epoch 0.0001263503013518251\n",
            "Epoch 151 / 200: avg. grad_norm of last epoch 0.00015520855111419713\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 152 / 200: avg. loss of last epoch 0.0001242978623253292\n",
            "Epoch 152 / 200: avg. grad_norm of last epoch 0.00015030801242277354\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 153 / 200: avg. loss of last epoch 0.00012151485181772549\n",
            "Epoch 153 / 200: avg. grad_norm of last epoch 0.00016115513324834756\n",
            "Current train acc: 100.0%, test acc: 90.09%\n",
            "Epoch 154 / 200: avg. loss of last epoch 0.00011873905836546324\n",
            "Epoch 154 / 200: avg. grad_norm of last epoch 0.00013629794858929572\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 155 / 200: avg. loss of last epoch 0.0001146121224640713\n",
            "Epoch 155 / 200: avg. grad_norm of last epoch 0.0001191358094660469\n",
            "Current train acc: 100.0%, test acc: 90.11%\n",
            "Epoch 156 / 200: avg. loss of last epoch 0.00011296245960402309\n",
            "Epoch 156 / 200: avg. grad_norm of last epoch 0.00012457142594791574\n",
            "Current train acc: 100.0%, test acc: 90.12%\n",
            "Epoch 157 / 200: avg. loss of last epoch 0.00010926171679942247\n",
            "Epoch 157 / 200: avg. grad_norm of last epoch 0.00011134509754672018\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 158 / 200: avg. loss of last epoch 0.00010894350173863725\n",
            "Epoch 158 / 200: avg. grad_norm of last epoch 0.00011575775808701147\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 159 / 200: avg. loss of last epoch 0.00010549596244527486\n",
            "Epoch 159 / 200: avg. grad_norm of last epoch 0.0001046181638409831\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 160 / 200: avg. loss of last epoch 0.00010406077794856774\n",
            "Epoch 160 / 200: avg. grad_norm of last epoch 0.00010406901499040373\n",
            "Current train acc: 100.0%, test acc: 90.06%\n",
            "Epoch 161 / 200: avg. loss of last epoch 0.00010199541746017842\n",
            "Epoch 161 / 200: avg. grad_norm of last epoch 0.00010197141947246314\n",
            "Current train acc: 100.0%, test acc: 90.12%\n",
            "Epoch 162 / 200: avg. loss of last epoch 0.00010002036006965985\n",
            "Epoch 162 / 200: avg. grad_norm of last epoch 9.683323298380147e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 163 / 200: avg. loss of last epoch 9.849804160670218e-05\n",
            "Epoch 163 / 200: avg. grad_norm of last epoch 9.888258446046258e-05\n",
            "Current train acc: 100.0%, test acc: 90.05%\n",
            "Epoch 164 / 200: avg. loss of last epoch 9.702479531212406e-05\n",
            "Epoch 164 / 200: avg. grad_norm of last epoch 9.921780078011481e-05\n",
            "Current train acc: 100.0%, test acc: 90.02%\n",
            "Epoch 165 / 200: avg. loss of last epoch 9.430384750885434e-05\n",
            "Epoch 165 / 200: avg. grad_norm of last epoch 8.254931518410814e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 166 / 200: avg. loss of last epoch 9.380682988363938e-05\n",
            "Epoch 166 / 200: avg. grad_norm of last epoch 8.899593746622459e-05\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 167 / 200: avg. loss of last epoch 9.221480423342047e-05\n",
            "Epoch 167 / 200: avg. grad_norm of last epoch 8.728415038210594e-05\n",
            "Current train acc: 100.0%, test acc: 90.06%\n",
            "Epoch 168 / 200: avg. loss of last epoch 8.993128978666685e-05\n",
            "Epoch 168 / 200: avg. grad_norm of last epoch 7.989419670782508e-05\n",
            "Current train acc: 100.0%, test acc: 90.11%\n",
            "Epoch 169 / 200: avg. loss of last epoch 8.83599098325551e-05\n",
            "Epoch 169 / 200: avg. grad_norm of last epoch 7.389168743885324e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 170 / 200: avg. loss of last epoch 8.753821952608027e-05\n",
            "Epoch 170 / 200: avg. grad_norm of last epoch 7.58286107978823e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 171 / 200: avg. loss of last epoch 8.600290152632325e-05\n",
            "Epoch 171 / 200: avg. grad_norm of last epoch 7.433251736947074e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 172 / 200: avg. loss of last epoch 8.469655182464825e-05\n",
            "Epoch 172 / 200: avg. grad_norm of last epoch 7.00134999665199e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 173 / 200: avg. loss of last epoch 8.307315424608541e-05\n",
            "Epoch 173 / 200: avg. grad_norm of last epoch 6.754918634634725e-05\n",
            "Current train acc: 100.0%, test acc: 90.09%\n",
            "Epoch 174 / 200: avg. loss of last epoch 8.216912623271736e-05\n",
            "Epoch 174 / 200: avg. grad_norm of last epoch 6.468434392734719e-05\n",
            "Current train acc: 100.0%, test acc: 90.12%\n",
            "Epoch 175 / 200: avg. loss of last epoch 8.057575210890113e-05\n",
            "Epoch 175 / 200: avg. grad_norm of last epoch 6.299191753897918e-05\n",
            "Current train acc: 100.0%, test acc: 90.02%\n",
            "Epoch 176 / 200: avg. loss of last epoch 7.98102680031055e-05\n",
            "Epoch 176 / 200: avg. grad_norm of last epoch 6.257043962866522e-05\n",
            "Current train acc: 100.0%, test acc: 90.09%\n",
            "Epoch 177 / 200: avg. loss of last epoch 7.857666742347645e-05\n",
            "Epoch 177 / 200: avg. grad_norm of last epoch 5.964553639236818e-05\n",
            "Current train acc: 100.0%, test acc: 90.14%\n",
            "Epoch 178 / 200: avg. loss of last epoch 7.71717601368436e-05\n",
            "Epoch 178 / 200: avg. grad_norm of last epoch 5.9118065278007045e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 179 / 200: avg. loss of last epoch 7.6352515151666e-05\n",
            "Epoch 179 / 200: avg. grad_norm of last epoch 5.78351222895821e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 180 / 200: avg. loss of last epoch 7.557167428215812e-05\n",
            "Epoch 180 / 200: avg. grad_norm of last epoch 5.7519405029908615e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 181 / 200: avg. loss of last epoch 7.424541101912232e-05\n",
            "Epoch 181 / 200: avg. grad_norm of last epoch 5.3836737107142546e-05\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 182 / 200: avg. loss of last epoch 7.353222527890454e-05\n",
            "Epoch 182 / 200: avg. grad_norm of last epoch 5.274732282559967e-05\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 183 / 200: avg. loss of last epoch 7.263202867822355e-05\n",
            "Epoch 183 / 200: avg. grad_norm of last epoch 5.285956931020359e-05\n",
            "Current train acc: 100.0%, test acc: 90.11%\n",
            "Epoch 184 / 200: avg. loss of last epoch 7.143384131777566e-05\n",
            "Epoch 184 / 200: avg. grad_norm of last epoch 5.138905151214687e-05\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 185 / 200: avg. loss of last epoch 7.041999164017997e-05\n",
            "Epoch 185 / 200: avg. grad_norm of last epoch 4.821678428948233e-05\n",
            "Current train acc: 100.0%, test acc: 90.12%\n",
            "Epoch 186 / 200: avg. loss of last epoch 6.973098088152864e-05\n",
            "Epoch 186 / 200: avg. grad_norm of last epoch 4.815969630174799e-05\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 187 / 200: avg. loss of last epoch 6.902713014278566e-05\n",
            "Epoch 187 / 200: avg. grad_norm of last epoch 4.8395269204847345e-05\n",
            "Current train acc: 100.0%, test acc: 90.06%\n",
            "Epoch 188 / 200: avg. loss of last epoch 6.776136040571142e-05\n",
            "Epoch 188 / 200: avg. grad_norm of last epoch 4.411325040071897e-05\n",
            "Current train acc: 100.0%, test acc: 90.09%\n",
            "Epoch 189 / 200: avg. loss of last epoch 6.717439518858255e-05\n",
            "Epoch 189 / 200: avg. grad_norm of last epoch 4.5926881439395045e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 190 / 200: avg. loss of last epoch 6.663484783202876e-05\n",
            "Epoch 190 / 200: avg. grad_norm of last epoch 4.474830534610469e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 191 / 200: avg. loss of last epoch 6.573796013738801e-05\n",
            "Epoch 191 / 200: avg. grad_norm of last epoch 4.239424230073397e-05\n",
            "Current train acc: 100.0%, test acc: 90.04%\n",
            "Epoch 192 / 200: avg. loss of last epoch 6.490790797009444e-05\n",
            "Epoch 192 / 200: avg. grad_norm of last epoch 4.382102608756773e-05\n",
            "Current train acc: 100.0%, test acc: 90.13%\n",
            "Epoch 193 / 200: avg. loss of last epoch 6.432339460055422e-05\n",
            "Epoch 193 / 200: avg. grad_norm of last epoch 4.179397752865118e-05\n",
            "Current train acc: 100.0%, test acc: 90.06%\n",
            "Epoch 194 / 200: avg. loss of last epoch 6.318355727319917e-05\n",
            "Epoch 194 / 200: avg. grad_norm of last epoch 3.939472816095762e-05\n",
            "Current train acc: 100.0%, test acc: 90.06%\n",
            "Epoch 195 / 200: avg. loss of last epoch 6.251880335864068e-05\n",
            "Epoch 195 / 200: avg. grad_norm of last epoch 3.8165936219484605e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 196 / 200: avg. loss of last epoch 6.220140437192938e-05\n",
            "Epoch 196 / 200: avg. grad_norm of last epoch 4.056893002359982e-05\n",
            "Current train acc: 100.0%, test acc: 90.1%\n",
            "Epoch 197 / 200: avg. loss of last epoch 6.138934667590844e-05\n",
            "Epoch 197 / 200: avg. grad_norm of last epoch 3.816634550733417e-05\n",
            "Current train acc: 100.0%, test acc: 90.08%\n",
            "Epoch 198 / 200: avg. loss of last epoch 6.075625449836181e-05\n",
            "Epoch 198 / 200: avg. grad_norm of last epoch 3.766702787548365e-05\n",
            "Current train acc: 100.0%, test acc: 90.05%\n",
            "Epoch 199 / 200: avg. loss of last epoch 5.9873157914262274e-05\n",
            "Epoch 199 / 200: avg. grad_norm of last epoch 3.5727774453679015e-05\n",
            "Current train acc: 100.0%, test acc: 90.07%\n",
            "Epoch 200 / 200: avg. loss of last epoch 5.9383846620524626e-05\n",
            "Epoch 200 / 200: avg. grad_norm of last epoch 3.45295160083567e-05\n",
            "Current train acc: 100.0%, test acc: 90.04%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epochs = 200\n",
        "\n",
        "scheduler = constant_learning_rate_scheduler(0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "\n",
        "sgdm_history = train(model, criterion, optimizer, epochs, fashion_train_loader, fashion_test_loader, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb10mimax9DZ"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/Fashion-Other-Optimizers/SGD-M_constantLR.json\", sgdm_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "46sWrgvgx_NG",
        "outputId": "3ab5cb41-b16f-4479-a6fe-f07699e1543f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f84f95284d0>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss(sgdm_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3Rsp0cEsAf0"
      },
      "source": [
        "## Training with SSMG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmrinfmesBuB",
        "outputId": "1704cbcb-4045-4837-979c-0699b9a0ed85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 200: avg. loss of last epoch 0.533162461773555\n",
            "avg. grad_norm of last epoch 2.1530154910322468\n",
            "Current train acc: 83.83166666666666%, test acc: 82.52%\n",
            "Epoch 2 / 200: avg. loss of last epoch 0.3685311560312913\n",
            "avg. grad_norm of last epoch 1.5144792919988934\n",
            "Current train acc: 86.42666666666666%, test acc: 84.76%\n",
            "Epoch 3 / 200: avg. loss of last epoch 0.32564437292416876\n",
            "avg. grad_norm of last epoch 1.3799010300351686\n",
            "Current train acc: 87.735%, test acc: 85.63%\n",
            "Epoch 4 / 200: avg. loss of last epoch 0.2974340852896371\n",
            "avg. grad_norm of last epoch 1.3006394647332382\n",
            "Current train acc: 88.445%, test acc: 85.97%\n",
            "Epoch 5 / 200: avg. loss of last epoch 0.27606966770489955\n",
            "avg. grad_norm of last epoch 1.281248979995513\n",
            "Current train acc: 88.66166666666666%, test acc: 86.02%\n",
            "Epoch 6 / 200: avg. loss of last epoch 0.2588917136987051\n",
            "avg. grad_norm of last epoch 1.2906826899176482\n",
            "Current train acc: 89.64166666666667%, test acc: 86.76%\n",
            "Epoch 7 / 200: avg. loss of last epoch 0.24328377122879036\n",
            "avg. grad_norm of last epoch 1.2925354689348318\n",
            "Current train acc: 90.465%, test acc: 87.59%\n",
            "Epoch 8 / 200: avg. loss of last epoch 0.22950709549585976\n",
            "avg. grad_norm of last epoch 1.3032988305200626\n",
            "Current train acc: 91.18%, test acc: 87.67%\n",
            "Epoch 9 / 200: avg. loss of last epoch 0.21824515307744338\n",
            "avg. grad_norm of last epoch 1.364668842001425\n",
            "Current train acc: 90.915%, test acc: 87.44%\n",
            "Epoch 10 / 200: avg. loss of last epoch 0.206609521261851\n",
            "avg. grad_norm of last epoch 1.3873998172716677\n",
            "Current train acc: 91.08333333333333%, test acc: 87.23%\n",
            "Epoch 11 / 200: avg. loss of last epoch 0.1992933340072634\n",
            "avg. grad_norm of last epoch 1.4720644583912512\n",
            "Current train acc: 91.72333333333333%, test acc: 87.74%\n",
            "Epoch 12 / 200: avg. loss of last epoch 0.18793022018273678\n",
            "avg. grad_norm of last epoch 1.4645509329048558\n",
            "Current train acc: 92.22333333333333%, test acc: 87.89%\n",
            "Epoch 13 / 200: avg. loss of last epoch 0.17766486032009127\n",
            "avg. grad_norm of last epoch 1.4236307109534123\n",
            "Current train acc: 92.66333333333333%, test acc: 88.08%\n",
            "Epoch 14 / 200: avg. loss of last epoch 0.16953561478455864\n",
            "avg. grad_norm of last epoch 1.4869379115070498\n",
            "Current train acc: 92.7%, test acc: 88.18%\n",
            "Epoch 15 / 200: avg. loss of last epoch 0.16100880712668106\n",
            "avg. grad_norm of last epoch 1.515195282002549\n",
            "Current train acc: 92.70833333333333%, test acc: 87.87%\n",
            "Epoch 16 / 200: avg. loss of last epoch 0.15644166759649925\n",
            "avg. grad_norm of last epoch 1.6418726315166352\n",
            "Current train acc: 92.83666666666667%, test acc: 87.85%\n",
            "Epoch 17 / 200: avg. loss of last epoch 0.15357948294480633\n",
            "avg. grad_norm of last epoch 1.711665760963625\n",
            "Current train acc: 92.67166666666667%, test acc: 87.61%\n",
            "Epoch 18 / 200: avg. loss of last epoch 0.14550517435073854\n",
            "avg. grad_norm of last epoch 1.6265853444811271\n",
            "Current train acc: 93.24%, test acc: 87.93%\n",
            "Epoch 19 / 200: avg. loss of last epoch 0.1410594520886739\n",
            "avg. grad_norm of last epoch 1.7169897657119606\n",
            "Current train acc: 92.80833333333334%, test acc: 87.71%\n",
            "Epoch 20 / 200: avg. loss of last epoch 0.13472050522963214\n",
            "avg. grad_norm of last epoch 1.6593418469482764\n",
            "Current train acc: 93.225%, test acc: 87.75%\n",
            "Epoch 21 / 200: avg. loss of last epoch 0.12706520338853206\n",
            "avg. grad_norm of last epoch 1.5413222560316568\n",
            "Current train acc: 92.525%, test acc: 87.14%\n",
            "Epoch 22 / 200: avg. loss of last epoch 0.12392771988709772\n",
            "avg. grad_norm of last epoch 1.6825712817623184\n",
            "Current train acc: 93.28833333333333%, test acc: 87.54%\n",
            "Epoch 23 / 200: avg. loss of last epoch 0.12185118522644045\n",
            "avg. grad_norm of last epoch 1.7737317022987475\n",
            "Current train acc: 93.06166666666667%, test acc: 87.44%\n",
            "Epoch 24 / 200: avg. loss of last epoch 0.12297415891488385\n",
            "avg. grad_norm of last epoch 1.9785639757898592\n",
            "Current train acc: 92.52666666666667%, test acc: 87.14%\n",
            "Epoch 25 / 200: avg. loss of last epoch 0.11702712475458775\n",
            "avg. grad_norm of last epoch 1.7524524684680427\n",
            "Current train acc: 93.42166666666667%, test acc: 87.76%\n",
            "Epoch 26 / 200: avg. loss of last epoch 0.10746948520739882\n",
            "avg. grad_norm of last epoch 1.5677993242061539\n",
            "Current train acc: 93.71333333333334%, test acc: 87.67%\n",
            "Epoch 27 / 200: avg. loss of last epoch 0.10837480030059815\n",
            "avg. grad_norm of last epoch 1.6877449228790777\n",
            "Current train acc: 93.53333333333333%, test acc: 87.66%\n",
            "Epoch 28 / 200: avg. loss of last epoch 0.10341044762134559\n",
            "avg. grad_norm of last epoch 1.656685062724121\n",
            "Current train acc: 93.345%, test acc: 87.08%\n",
            "Epoch 29 / 200: avg. loss of last epoch 0.10327397873600323\n",
            "avg. grad_norm of last epoch 1.7383655126722923\n",
            "Current train acc: 94.24%, test acc: 87.98%\n",
            "Epoch 30 / 200: avg. loss of last epoch 0.09684722526868184\n",
            "avg. grad_norm of last epoch 1.686484274853771\n",
            "Current train acc: 93.83166666666666%, test acc: 88.25%\n",
            "Epoch 31 / 200: avg. loss of last epoch 0.09213617496093128\n",
            "avg. grad_norm of last epoch 1.644851014615821\n",
            "Current train acc: 93.915%, test acc: 88.09%\n",
            "Epoch 32 / 200: avg. loss of last epoch 0.09795742482542993\n",
            "avg. grad_norm of last epoch 1.9586564863598006\n",
            "Current train acc: 94.41833333333334%, test acc: 88.06%\n",
            "Epoch 33 / 200: avg. loss of last epoch 0.09172705426613484\n",
            "avg. grad_norm of last epoch 1.752883851581546\n",
            "Current train acc: 94.43833333333333%, test acc: 88.4%\n",
            "Epoch 34 / 200: avg. loss of last epoch 0.08629349987705551\n",
            "avg. grad_norm of last epoch 1.6033659048024809\n",
            "Current train acc: 94.735%, test acc: 88.39%\n",
            "Epoch 35 / 200: avg. loss of last epoch 0.08560538023610911\n",
            "avg. grad_norm of last epoch 1.7073438703044543\n",
            "Current train acc: 94.655%, test acc: 88.16%\n",
            "Epoch 36 / 200: avg. loss of last epoch 0.0894207033316295\n",
            "avg. grad_norm of last epoch 1.9251633841289906\n",
            "Current train acc: 94.80666666666667%, test acc: 88.27%\n",
            "Epoch 37 / 200: avg. loss of last epoch 0.08455453101098538\n",
            "avg. grad_norm of last epoch 1.7969677869704235\n",
            "Current train acc: 94.95166666666667%, test acc: 88.24%\n",
            "Epoch 38 / 200: avg. loss of last epoch 0.07369805216391886\n",
            "avg. grad_norm of last epoch 1.4861644623367647\n",
            "Current train acc: 94.785%, test acc: 88.1%\n",
            "Epoch 39 / 200: avg. loss of last epoch 0.07404021088083577\n",
            "avg. grad_norm of last epoch 1.5864747459325597\n",
            "Current train acc: 94.93%, test acc: 87.97%\n",
            "Epoch 40 / 200: avg. loss of last epoch 0.0770391910930475\n",
            "avg. grad_norm of last epoch 1.7448541691424582\n",
            "Current train acc: 94.78666666666666%, test acc: 88.12%\n",
            "Epoch 41 / 200: avg. loss of last epoch 0.07140721228321399\n",
            "avg. grad_norm of last epoch 1.6327287909704171\n",
            "Current train acc: 95.09333333333333%, test acc: 88.62%\n",
            "Epoch 42 / 200: avg. loss of last epoch 0.07216319982806838\n",
            "avg. grad_norm of last epoch 1.6946251943419655\n",
            "Current train acc: 95.09666666666666%, test acc: 88.56%\n",
            "Epoch 43 / 200: avg. loss of last epoch 0.07726427191793925\n",
            "avg. grad_norm of last epoch 1.897509248609282\n",
            "Current train acc: 94.85666666666667%, test acc: 88.72%\n",
            "Epoch 44 / 200: avg. loss of last epoch 0.07386158207704628\n",
            "avg. grad_norm of last epoch 1.8219517344821334\n",
            "Current train acc: 95.41833333333334%, test acc: 88.1%\n",
            "Epoch 45 / 200: avg. loss of last epoch 0.07220405551791195\n",
            "avg. grad_norm of last epoch 1.7738277384123946\n",
            "Current train acc: 95.22666666666667%, test acc: 88.29%\n",
            "Epoch 46 / 200: avg. loss of last epoch 0.07645166746377938\n",
            "avg. grad_norm of last epoch 2.0140581394997463\n",
            "Current train acc: 95.20333333333333%, test acc: 88.25%\n",
            "Epoch 47 / 200: avg. loss of last epoch 0.06956971460779508\n",
            "avg. grad_norm of last epoch 1.6950906450428462\n",
            "Current train acc: 95.795%, test acc: 88.39%\n",
            "Epoch 48 / 200: avg. loss of last epoch 0.06207872745196019\n",
            "avg. grad_norm of last epoch 1.5057627960341038\n",
            "Current train acc: 95.6%, test acc: 88.7%\n",
            "Epoch 49 / 200: avg. loss of last epoch 0.0566820202996334\n",
            "avg. grad_norm of last epoch 1.4076345793043747\n",
            "Current train acc: 95.49666666666667%, test acc: 88.22%\n",
            "Epoch 50 / 200: avg. loss of last epoch 0.07397090848286943\n",
            "avg. grad_norm of last epoch 2.19130216708874\n",
            "Current train acc: 94.69333333333333%, test acc: 87.91%\n",
            "Epoch 51 / 200: avg. loss of last epoch 0.06379863266646865\n",
            "avg. grad_norm of last epoch 1.6216128749002403\n",
            "Current train acc: 95.26%, test acc: 88.16%\n",
            "Epoch 52 / 200: avg. loss of last epoch 0.05838833010594047\n",
            "avg. grad_norm of last epoch 1.5393699880934613\n",
            "Current train acc: 95.12833333333333%, test acc: 88.05%\n",
            "Epoch 53 / 200: avg. loss of last epoch 0.05444617302566764\n",
            "avg. grad_norm of last epoch 1.4269260386359572\n",
            "Current train acc: 95.37666666666667%, test acc: 88.22%\n",
            "Epoch 54 / 200: avg. loss of last epoch 0.05116269265959667\n",
            "avg. grad_norm of last epoch 1.3727459660663424\n",
            "Current train acc: 95.99833333333333%, test acc: 88.35%\n",
            "Epoch 55 / 200: avg. loss of last epoch 0.05294483159085114\n",
            "avg. grad_norm of last epoch 1.431102405067087\n",
            "Current train acc: 95.785%, test acc: 88.12%\n",
            "Epoch 56 / 200: avg. loss of last epoch 0.05879744625588264\n",
            "avg. grad_norm of last epoch 1.6881163672003336\n",
            "Current train acc: 95.865%, test acc: 88.35%\n",
            "Epoch 57 / 200: avg. loss of last epoch 0.05546838515202205\n",
            "avg. grad_norm of last epoch 1.6491928223454968\n",
            "Current train acc: 95.74833333333333%, test acc: 88.38%\n",
            "Epoch 58 / 200: avg. loss of last epoch 0.05454038374026618\n",
            "avg. grad_norm of last epoch 1.5935589079313595\n",
            "Current train acc: 95.54%, test acc: 88.18%\n",
            "Epoch 59 / 200: avg. loss of last epoch 0.05308047038912772\n",
            "avg. grad_norm of last epoch 1.5360327006849244\n",
            "Current train acc: 95.48%, test acc: 87.84%\n",
            "Epoch 60 / 200: avg. loss of last epoch 0.051955741625403354\n",
            "avg. grad_norm of last epoch 1.5708078212568457\n",
            "Current train acc: 95.65833333333333%, test acc: 88.33%\n",
            "Epoch 61 / 200: avg. loss of last epoch 0.04749334783256054\n",
            "avg. grad_norm of last epoch 1.4766577093234643\n",
            "Current train acc: 94.89166666666667%, test acc: 87.98%\n",
            "Epoch 62 / 200: avg. loss of last epoch 0.05177684186051291\n",
            "avg. grad_norm of last epoch 1.621696965009119\n",
            "Current train acc: 95.52333333333333%, test acc: 88.2%\n",
            "Epoch 63 / 200: avg. loss of last epoch 0.048637404778599756\n",
            "avg. grad_norm of last epoch 1.5294689080684594\n",
            "Current train acc: 94.95833333333333%, test acc: 88.01%\n",
            "Epoch 64 / 200: avg. loss of last epoch 0.05176169580668209\n",
            "avg. grad_norm of last epoch 1.6100515205796708\n",
            "Current train acc: 95.04833333333333%, test acc: 87.42%\n",
            "Epoch 65 / 200: avg. loss of last epoch 0.046742899052550455\n",
            "avg. grad_norm of last epoch 1.4982520720682944\n",
            "Current train acc: 96.145%, test acc: 88.75%\n",
            "Epoch 66 / 200: avg. loss of last epoch 0.048272227036952935\n",
            "avg. grad_norm of last epoch 1.5277449495914088\n",
            "Current train acc: 96.06666666666666%, test acc: 88.46%\n",
            "Epoch 67 / 200: avg. loss of last epoch 0.04292349163244166\n",
            "avg. grad_norm of last epoch 1.385984020595071\n",
            "Current train acc: 96.65833333333333%, test acc: 88.44%\n",
            "Epoch 68 / 200: avg. loss of last epoch 0.055181494094928056\n",
            "avg. grad_norm of last epoch 1.917421716917097\n",
            "Current train acc: 95.60166666666667%, test acc: 87.97%\n",
            "Epoch 69 / 200: avg. loss of last epoch 0.04611424754212294\n",
            "avg. grad_norm of last epoch 1.5350351246667824\n",
            "Current train acc: 95.92166666666667%, test acc: 88.39%\n",
            "Epoch 70 / 200: avg. loss of last epoch 0.042110121746858\n",
            "avg. grad_norm of last epoch 1.3225451113809188\n",
            "Current train acc: 95.64%, test acc: 88.22%\n",
            "Epoch 71 / 200: avg. loss of last epoch 0.04060130288551252\n",
            "avg. grad_norm of last epoch 1.272971670323068\n",
            "Current train acc: 96.65666666666667%, test acc: 88.81%\n",
            "Epoch 72 / 200: avg. loss of last epoch 0.04477543795630343\n",
            "avg. grad_norm of last epoch 1.6094590114164453\n",
            "Current train acc: 95.82833333333333%, test acc: 88.09%\n",
            "Epoch 73 / 200: avg. loss of last epoch 0.03967760936121145\n",
            "avg. grad_norm of last epoch 1.3005710155591732\n",
            "Current train acc: 95.90166666666667%, test acc: 88.26%\n",
            "Epoch 74 / 200: avg. loss of last epoch 0.04106117704162997\n",
            "avg. grad_norm of last epoch 1.3598997088983105\n",
            "Current train acc: 96.155%, test acc: 88.37%\n",
            "Epoch 75 / 200: avg. loss of last epoch 0.03537072920501233\n",
            "avg. grad_norm of last epoch 1.2084232598061095\n",
            "Current train acc: 96.22%, test acc: 88.39%\n",
            "Epoch 76 / 200: avg. loss of last epoch 0.0439482912088434\n",
            "avg. grad_norm of last epoch 1.5752199738292552\n",
            "Current train acc: 96.5%, test acc: 88.15%\n",
            "Epoch 77 / 200: avg. loss of last epoch 0.041560688912123424\n",
            "avg. grad_norm of last epoch 1.4621538325678893\n",
            "Current train acc: 95.485%, test acc: 87.82%\n",
            "Epoch 78 / 200: avg. loss of last epoch 0.042004580784589095\n",
            "avg. grad_norm of last epoch 1.5064380442621323\n",
            "Current train acc: 95.76%, test acc: 88.45%\n",
            "Epoch 79 / 200: avg. loss of last epoch 0.05475205576121808\n",
            "avg. grad_norm of last epoch 2.2764400040534865\n",
            "Current train acc: 96.23833333333333%, test acc: 88.6%\n",
            "Epoch 80 / 200: avg. loss of last epoch 0.048656040636946736\n",
            "avg. grad_norm of last epoch 1.8145637392442084\n",
            "Current train acc: 95.635%, test acc: 88.01%\n",
            "Epoch 81 / 200: avg. loss of last epoch 0.03720414983530833\n",
            "avg. grad_norm of last epoch 1.2562305075594695\n",
            "Current train acc: 96.03166666666667%, test acc: 88.14%\n",
            "Epoch 82 / 200: avg. loss of last epoch 0.033564646308248236\n",
            "avg. grad_norm of last epoch 1.152270159445505\n",
            "Current train acc: 95.90666666666667%, test acc: 87.89%\n",
            "Epoch 83 / 200: avg. loss of last epoch 0.030954841744403026\n",
            "avg. grad_norm of last epoch 1.0697362046290197\n",
            "Current train acc: 95.32166666666667%, test acc: 87.49%\n",
            "Epoch 84 / 200: avg. loss of last epoch 0.032635372267539285\n",
            "avg. grad_norm of last epoch 1.178769348838677\n",
            "Current train acc: 96.415%, test acc: 87.85%\n",
            "Epoch 85 / 200: avg. loss of last epoch 0.034755480019748236\n",
            "avg. grad_norm of last epoch 1.32557354222259\n",
            "Current train acc: 96.655%, test acc: 88.21%\n",
            "Epoch 86 / 200: avg. loss of last epoch 0.043793988656500984\n",
            "avg. grad_norm of last epoch 1.779232112149147\n",
            "Current train acc: 96.76166666666667%, test acc: 88.53%\n",
            "Epoch 87 / 200: avg. loss of last epoch 0.033103890873864304\n",
            "avg. grad_norm of last epoch 1.1958724812818202\n",
            "Current train acc: 97.11666666666666%, test acc: 88.47%\n",
            "Epoch 88 / 200: avg. loss of last epoch 0.027136842971667657\n",
            "avg. grad_norm of last epoch 0.970773774079814\n",
            "Current train acc: 96.985%, test acc: 88.59%\n",
            "Epoch 89 / 200: avg. loss of last epoch 0.039028973285605534\n",
            "avg. grad_norm of last epoch 1.5695217646087265\n",
            "Current train acc: 96.07333333333334%, test acc: 87.97%\n",
            "Epoch 90 / 200: avg. loss of last epoch 0.034461598535502964\n",
            "avg. grad_norm of last epoch 1.3522152531898632\n",
            "Current train acc: 96.215%, test acc: 88.12%\n",
            "Epoch 91 / 200: avg. loss of last epoch 0.04254784877051911\n",
            "avg. grad_norm of last epoch 1.7609052022564267\n",
            "Current train acc: 96.61666666666666%, test acc: 88.24%\n",
            "Epoch 92 / 200: avg. loss of last epoch 0.03530383736751974\n",
            "avg. grad_norm of last epoch 1.424602358575656\n",
            "Current train acc: 97.00666666666666%, test acc: 88.54%\n",
            "Epoch 93 / 200: avg. loss of last epoch 0.029932726365420985\n",
            "avg. grad_norm of last epoch 1.1389147190289661\n",
            "Current train acc: 96.69%, test acc: 88.09%\n",
            "Epoch 94 / 200: avg. loss of last epoch 0.03406119449039302\n",
            "avg. grad_norm of last epoch 1.3686860258510127\n",
            "Current train acc: 96.14333333333333%, test acc: 88.12%\n",
            "Epoch 95 / 200: avg. loss of last epoch 0.032461337898174895\n",
            "avg. grad_norm of last epoch 1.2970036123317847\n",
            "Current train acc: 96.71%, test acc: 88.36%\n",
            "Epoch 96 / 200: avg. loss of last epoch 0.03765553375060365\n",
            "avg. grad_norm of last epoch 1.601329129193705\n",
            "Current train acc: 96.93166666666667%, test acc: 88.33%\n",
            "Epoch 97 / 200: avg. loss of last epoch 0.027600750618428014\n",
            "avg. grad_norm of last epoch 1.0423686276347077\n",
            "Current train acc: 96.99333333333334%, test acc: 88.51%\n",
            "Epoch 98 / 200: avg. loss of last epoch 0.026750517029066882\n",
            "avg. grad_norm of last epoch 1.0064920296457889\n",
            "Current train acc: 97.06833333333333%, test acc: 88.23%\n",
            "Epoch 99 / 200: avg. loss of last epoch 0.026999767593915258\n",
            "avg. grad_norm of last epoch 1.0326721732656794\n",
            "Current train acc: 97.075%, test acc: 88.03%\n",
            "Epoch 100 / 200: avg. loss of last epoch 0.03293951325342058\n",
            "avg. grad_norm of last epoch 1.4062266837976074\n",
            "Current train acc: 97.045%, test acc: 88.35%\n",
            "Epoch 101 / 200: avg. loss of last epoch 0.03671722616180776\n",
            "avg. grad_norm of last epoch 1.515350826537167\n",
            "Current train acc: 97.35833333333333%, test acc: 88.75%\n",
            "Epoch 102 / 200: avg. loss of last epoch 0.02456144900831084\n",
            "avg. grad_norm of last epoch 0.896133835514748\n",
            "Current train acc: 96.93666666666667%, test acc: 88.02%\n",
            "Epoch 103 / 200: avg. loss of last epoch 0.02777649398446085\n",
            "avg. grad_norm of last epoch 1.1641147128172789\n",
            "Current train acc: 96.46833333333333%, test acc: 88.1%\n",
            "Epoch 104 / 200: avg. loss of last epoch 0.028317895097161344\n",
            "avg. grad_norm of last epoch 1.2173776653110617\n",
            "Current train acc: 96.96833333333333%, test acc: 88.29%\n",
            "Epoch 105 / 200: avg. loss of last epoch 0.033454629959166066\n",
            "avg. grad_norm of last epoch 1.6019634404172114\n",
            "Current train acc: 96.68833333333333%, test acc: 88.17%\n",
            "Epoch 106 / 200: avg. loss of last epoch 0.034616495317220664\n",
            "avg. grad_norm of last epoch 1.556489980222504\n",
            "Current train acc: 97.05333333333333%, test acc: 88.23%\n",
            "Epoch 107 / 200: avg. loss of last epoch 0.02660850666115682\n",
            "avg. grad_norm of last epoch 1.095555538086788\n",
            "Current train acc: 97.19333333333333%, test acc: 88.74%\n",
            "Epoch 108 / 200: avg. loss of last epoch 0.028522212999438273\n",
            "avg. grad_norm of last epoch 1.2259902898845734\n",
            "Current train acc: 96.365%, test acc: 87.92%\n",
            "Epoch 109 / 200: avg. loss of last epoch 0.028703777166580183\n",
            "avg. grad_norm of last epoch 1.2224284748856027\n",
            "Current train acc: 97.35666666666667%, test acc: 88.8%\n",
            "Epoch 110 / 200: avg. loss of last epoch 0.029568328811538716\n",
            "avg. grad_norm of last epoch 1.2211303289903088\n",
            "Current train acc: 97.41833333333334%, test acc: 88.51%\n",
            "Epoch 111 / 200: avg. loss of last epoch 0.02491513854973019\n",
            "avg. grad_norm of last epoch 0.9961914439936993\n",
            "Current train acc: 97.94666666666667%, test acc: 88.45%\n",
            "Epoch 112 / 200: avg. loss of last epoch 0.033599451873451466\n",
            "avg. grad_norm of last epoch 1.5772384389298695\n",
            "Current train acc: 97.19%, test acc: 88.29%\n",
            "Epoch 113 / 200: avg. loss of last epoch 0.027515480643262466\n",
            "avg. grad_norm of last epoch 1.232933680740453\n",
            "Current train acc: 97.19833333333334%, test acc: 88.34%\n",
            "Epoch 114 / 200: avg. loss of last epoch 0.02424291082241882\n",
            "avg. grad_norm of last epoch 1.0148494871436198\n",
            "Current train acc: 98.12166666666667%, test acc: 88.94%\n",
            "Epoch 115 / 200: avg. loss of last epoch 0.02559621109068391\n",
            "avg. grad_norm of last epoch 1.0566138832525414\n",
            "Current train acc: 97.35%, test acc: 88.78%\n",
            "Epoch 116 / 200: avg. loss of last epoch 0.025802047913273157\n",
            "avg. grad_norm of last epoch 1.1038038613469536\n",
            "Current train acc: 96.95166666666667%, test acc: 88.18%\n",
            "Epoch 117 / 200: avg. loss of last epoch 0.02246163400635122\n",
            "avg. grad_norm of last epoch 0.9423034638525042\n",
            "Current train acc: 97.79666666666667%, test acc: 88.85%\n",
            "Epoch 118 / 200: avg. loss of last epoch 0.024692211381842674\n",
            "avg. grad_norm of last epoch 1.031749922487169\n",
            "Current train acc: 97.78166666666667%, test acc: 88.66%\n",
            "Epoch 119 / 200: avg. loss of last epoch 0.019260001902406405\n",
            "avg. grad_norm of last epoch 0.7596439498396238\n",
            "Current train acc: 97.82833333333333%, test acc: 88.43%\n",
            "Epoch 120 / 200: avg. loss of last epoch 0.022318277142445237\n",
            "avg. grad_norm of last epoch 0.9444090575527134\n",
            "Current train acc: 97.72166666666666%, test acc: 88.83%\n",
            "Epoch 121 / 200: avg. loss of last epoch 0.020603859745400663\n",
            "avg. grad_norm of last epoch 0.8419118163321889\n",
            "Current train acc: 97.76333333333334%, test acc: 88.41%\n",
            "Epoch 122 / 200: avg. loss of last epoch 0.027123244338917225\n",
            "avg. grad_norm of last epoch 1.3402850167233966\n",
            "Current train acc: 97.31166666666667%, test acc: 88.42%\n",
            "Epoch 123 / 200: avg. loss of last epoch 0.027635742654465143\n",
            "avg. grad_norm of last epoch 1.312305196855435\n",
            "Current train acc: 97.35833333333333%, test acc: 88.19%\n",
            "Epoch 124 / 200: avg. loss of last epoch 0.0234049122470198\n",
            "avg. grad_norm of last epoch 1.1445403657364235\n",
            "Current train acc: 97.645%, test acc: 88.14%\n",
            "Epoch 125 / 200: avg. loss of last epoch 0.024939332020903638\n",
            "avg. grad_norm of last epoch 1.1665050057538777\n",
            "Current train acc: 97.46%, test acc: 88.03%\n",
            "Epoch 126 / 200: avg. loss of last epoch 0.021923758362606186\n",
            "avg. grad_norm of last epoch 0.9630792647937632\n",
            "Current train acc: 97.87%, test acc: 88.56%\n",
            "Epoch 127 / 200: avg. loss of last epoch 0.025571361858149358\n",
            "avg. grad_norm of last epoch 1.2114877116148115\n",
            "Current train acc: 97.22166666666666%, test acc: 88.39%\n",
            "Epoch 128 / 200: avg. loss of last epoch 0.019771694065444163\n",
            "avg. grad_norm of last epoch 0.8935949383098197\n",
            "Current train acc: 96.64666666666666%, test acc: 88.06%\n",
            "Epoch 129 / 200: avg. loss of last epoch 0.02707525349774708\n",
            "avg. grad_norm of last epoch 1.3032232020663679\n",
            "Current train acc: 97.84333333333333%, test acc: 88.38%\n",
            "Epoch 130 / 200: avg. loss of last epoch 0.023882917158802332\n",
            "avg. grad_norm of last epoch 1.162101850508207\n",
            "Current train acc: 98.11833333333334%, test acc: 88.49%\n",
            "Epoch 131 / 200: avg. loss of last epoch 0.02348078964352611\n",
            "avg. grad_norm of last epoch 1.111586649904502\n",
            "Current train acc: 97.73%, test acc: 88.13%\n",
            "Epoch 132 / 200: avg. loss of last epoch 0.019362636381884426\n",
            "avg. grad_norm of last epoch 0.9003455380182043\n",
            "Current train acc: 98.00166666666667%, test acc: 88.59%\n",
            "Epoch 133 / 200: avg. loss of last epoch 0.017440854446093248\n",
            "avg. grad_norm of last epoch 0.7691234018931333\n",
            "Current train acc: 97.845%, test acc: 88.64%\n",
            "Epoch 134 / 200: avg. loss of last epoch 0.019133555084156494\n",
            "avg. grad_norm of last epoch 0.8919086642999204\n",
            "Current train acc: 97.95%, test acc: 88.65%\n",
            "Epoch 135 / 200: avg. loss of last epoch 0.020835624268961454\n",
            "avg. grad_norm of last epoch 0.9161914585671697\n",
            "Current train acc: 97.955%, test acc: 88.26%\n",
            "Epoch 136 / 200: avg. loss of last epoch 0.020195324622544784\n",
            "avg. grad_norm of last epoch 0.9383361782348832\n",
            "Current train acc: 98.195%, test acc: 89.0%\n",
            "Epoch 137 / 200: avg. loss of last epoch 0.02124903740448257\n",
            "avg. grad_norm of last epoch 1.0300050820893794\n",
            "Current train acc: 97.78333333333333%, test acc: 88.5%\n",
            "Epoch 138 / 200: avg. loss of last epoch 0.02069924528256525\n",
            "avg. grad_norm of last epoch 1.0007538149590012\n",
            "Current train acc: 97.99166666666666%, test acc: 88.76%\n",
            "Epoch 139 / 200: avg. loss of last epoch 0.01916075076457735\n",
            "avg. grad_norm of last epoch 0.9156119371068587\n",
            "Current train acc: 96.66333333333333%, test acc: 88.01%\n",
            "Epoch 140 / 200: avg. loss of last epoch 0.02513497682589416\n",
            "avg. grad_norm of last epoch 1.2203002623819192\n",
            "Current train acc: 97.77333333333333%, test acc: 88.54%\n",
            "Epoch 141 / 200: avg. loss of last epoch 0.01975168667122103\n",
            "avg. grad_norm of last epoch 0.9348462677424512\n",
            "Current train acc: 98.20333333333333%, test acc: 88.55%\n",
            "Epoch 142 / 200: avg. loss of last epoch 0.01457869312919987\n",
            "avg. grad_norm of last epoch 0.6775577767432347\n",
            "Current train acc: 98.11166666666666%, test acc: 88.73%\n",
            "Epoch 143 / 200: avg. loss of last epoch 0.014361458443105228\n",
            "avg. grad_norm of last epoch 0.626560220660555\n",
            "Current train acc: 97.965%, test acc: 88.58%\n",
            "Epoch 144 / 200: avg. loss of last epoch 0.01833304410961766\n",
            "avg. grad_norm of last epoch 0.9572474712421791\n",
            "Current train acc: 98.11%, test acc: 88.47%\n",
            "Epoch 145 / 200: avg. loss of last epoch 0.021923920378352824\n",
            "avg. grad_norm of last epoch 1.0637315716651696\n",
            "Current train acc: 97.63833333333334%, test acc: 88.33%\n",
            "Epoch 146 / 200: avg. loss of last epoch 0.02279250557214642\n",
            "avg. grad_norm of last epoch 1.1198995436897792\n",
            "Current train acc: 97.63166666666666%, test acc: 88.1%\n",
            "Epoch 147 / 200: avg. loss of last epoch 0.017198067007524284\n",
            "avg. grad_norm of last epoch 0.8520454086919514\n",
            "Current train acc: 97.94666666666667%, test acc: 88.54%\n",
            "Epoch 148 / 200: avg. loss of last epoch 0.02149220078795526\n",
            "avg. grad_norm of last epoch 1.0765033536898132\n",
            "Current train acc: 97.53%, test acc: 88.34%\n",
            "Epoch 149 / 200: avg. loss of last epoch 0.02106645828510325\n",
            "avg. grad_norm of last epoch 0.994667221975578\n",
            "Current train acc: 98.405%, test acc: 88.88%\n",
            "Epoch 150 / 200: avg. loss of last epoch 0.013726089400155855\n",
            "avg. grad_norm of last epoch 0.66024852245032\n",
            "Current train acc: 98.20166666666667%, test acc: 88.66%\n",
            "Epoch 151 / 200: avg. loss of last epoch 0.01427456996338442\n",
            "avg. grad_norm of last epoch 0.6931261845715038\n",
            "Current train acc: 98.37333333333333%, test acc: 88.8%\n",
            "Epoch 152 / 200: avg. loss of last epoch 0.015780756515419735\n",
            "avg. grad_norm of last epoch 0.7217587671275234\n",
            "Current train acc: 98.67166666666667%, test acc: 88.96%\n",
            "Epoch 153 / 200: avg. loss of last epoch 0.015235334746756903\n",
            "avg. grad_norm of last epoch 0.7245277858847351\n",
            "Current train acc: 98.40666666666667%, test acc: 88.56%\n",
            "Epoch 154 / 200: avg. loss of last epoch 0.014604068551786862\n",
            "avg. grad_norm of last epoch 0.69059785775066\n",
            "Current train acc: 98.08666666666667%, test acc: 88.59%\n",
            "Epoch 155 / 200: avg. loss of last epoch 0.023267701947813257\n",
            "avg. grad_norm of last epoch 1.2744985948982408\n",
            "Current train acc: 98.37%, test acc: 88.6%\n",
            "Epoch 156 / 200: avg. loss of last epoch 0.02618792149157575\n",
            "avg. grad_norm of last epoch 1.3879731502981674\n",
            "Current train acc: 97.54666666666667%, test acc: 88.26%\n",
            "Epoch 157 / 200: avg. loss of last epoch 0.022343488287553195\n",
            "avg. grad_norm of last epoch 1.2222653610758765\n",
            "Current train acc: 97.50166666666667%, test acc: 88.11%\n",
            "Epoch 158 / 200: avg. loss of last epoch 0.01524042100361549\n",
            "avg. grad_norm of last epoch 0.7082838536037759\n",
            "Current train acc: 97.96666666666667%, test acc: 88.34%\n",
            "Epoch 159 / 200: avg. loss of last epoch 0.015829423365059\n",
            "avg. grad_norm of last epoch 0.7543449690080929\n",
            "Current train acc: 98.11%, test acc: 88.76%\n",
            "Epoch 160 / 200: avg. loss of last epoch 0.02086370489600425\n",
            "avg. grad_norm of last epoch 1.0688696685648684\n",
            "Current train acc: 97.635%, test acc: 87.94%\n",
            "Epoch 161 / 200: avg. loss of last epoch 0.017969693193538132\n",
            "avg. grad_norm of last epoch 0.9257686760520057\n",
            "Current train acc: 97.755%, test acc: 88.34%\n",
            "Epoch 162 / 200: avg. loss of last epoch 0.016602061201212933\n",
            "avg. grad_norm of last epoch 0.8247514257705421\n",
            "Current train acc: 98.39166666666667%, test acc: 88.3%\n",
            "Epoch 163 / 200: avg. loss of last epoch 0.024726865672102815\n",
            "avg. grad_norm of last epoch 1.3989107674861059\n",
            "Current train acc: 97.87666666666667%, test acc: 88.78%\n",
            "Epoch 164 / 200: avg. loss of last epoch 0.02063516075046111\n",
            "avg. grad_norm of last epoch 1.0565735212834197\n",
            "Current train acc: 98.225%, test acc: 88.69%\n",
            "Epoch 165 / 200: avg. loss of last epoch 0.02023486131072666\n",
            "avg. grad_norm of last epoch 1.0693265935881309\n",
            "Current train acc: 98.4%, test acc: 88.59%\n",
            "Epoch 166 / 200: avg. loss of last epoch 0.025308652789083615\n",
            "avg. grad_norm of last epoch 1.36170999176486\n",
            "Current train acc: 97.495%, test acc: 88.13%\n",
            "Epoch 167 / 200: avg. loss of last epoch 0.02149365018835912\n",
            "avg. grad_norm of last epoch 1.0931397529138713\n",
            "Current train acc: 98.12666666666667%, test acc: 88.73%\n",
            "Epoch 168 / 200: avg. loss of last epoch 0.015908394025110958\n",
            "avg. grad_norm of last epoch 0.8422711240494077\n",
            "Current train acc: 98.14%, test acc: 88.37%\n",
            "Epoch 169 / 200: avg. loss of last epoch 0.014708608111987521\n",
            "avg. grad_norm of last epoch 0.7002952695144714\n",
            "Current train acc: 98.73666666666666%, test acc: 88.58%\n",
            "Epoch 170 / 200: avg. loss of last epoch 0.012264553885278293\n",
            "avg. grad_norm of last epoch 0.6258552275341158\n",
            "Current train acc: 98.51333333333334%, test acc: 88.59%\n",
            "Epoch 171 / 200: avg. loss of last epoch 0.011032072443751775\n",
            "avg. grad_norm of last epoch 0.5372401885585302\n",
            "Current train acc: 97.83833333333334%, test acc: 88.17%\n",
            "Epoch 172 / 200: avg. loss of last epoch 0.011529843039166496\n",
            "avg. grad_norm of last epoch 0.6192927732538648\n",
            "Current train acc: 98.68166666666667%, test acc: 88.9%\n",
            "Epoch 173 / 200: avg. loss of last epoch 0.02391703103239027\n",
            "avg. grad_norm of last epoch 1.3586687887390998\n",
            "Current train acc: 98.305%, test acc: 88.65%\n",
            "Epoch 174 / 200: avg. loss of last epoch 0.0167386611588144\n",
            "avg. grad_norm of last epoch 0.8698446828543288\n",
            "Current train acc: 98.44166666666666%, test acc: 88.88%\n",
            "Epoch 175 / 200: avg. loss of last epoch 0.013013602223402504\n",
            "avg. grad_norm of last epoch 0.6377380663348925\n",
            "Current train acc: 98.56%, test acc: 88.69%\n",
            "Epoch 176 / 200: avg. loss of last epoch 0.009543398113238304\n",
            "avg. grad_norm of last epoch 0.47258654164790714\n",
            "Current train acc: 98.81833333333333%, test acc: 89.03%\n",
            "Epoch 177 / 200: avg. loss of last epoch 0.0078061158133864725\n",
            "avg. grad_norm of last epoch 0.3989815778103307\n",
            "Current train acc: 98.99666666666667%, test acc: 89.01%\n",
            "Epoch 178 / 200: avg. loss of last epoch 0.0138129351023507\n",
            "avg. grad_norm of last epoch 0.7780003661556574\n",
            "Current train acc: 97.63%, test acc: 88.66%\n",
            "Epoch 179 / 200: avg. loss of last epoch 0.016083849418442705\n",
            "avg. grad_norm of last epoch 0.8782174145166632\n",
            "Current train acc: 98.63333333333334%, test acc: 88.79%\n",
            "Epoch 180 / 200: avg. loss of last epoch 0.014112754120848453\n",
            "avg. grad_norm of last epoch 0.6926734102832856\n",
            "Current train acc: 98.69%, test acc: 88.84%\n",
            "Epoch 181 / 200: avg. loss of last epoch 0.009805658767737136\n",
            "avg. grad_norm of last epoch 0.5226080928793183\n",
            "Current train acc: 98.54166666666667%, test acc: 88.58%\n",
            "Epoch 182 / 200: avg. loss of last epoch 0.014397193665616228\n",
            "avg. grad_norm of last epoch 0.7863921140447341\n",
            "Current train acc: 98.97833333333334%, test acc: 88.78%\n",
            "Epoch 183 / 200: avg. loss of last epoch 0.014003817060845903\n",
            "avg. grad_norm of last epoch 0.7695249990298971\n",
            "Current train acc: 98.43666666666667%, test acc: 88.63%\n",
            "Epoch 184 / 200: avg. loss of last epoch 0.010760642645407152\n",
            "avg. grad_norm of last epoch 0.5595921825678307\n",
            "Current train acc: 98.625%, test acc: 88.84%\n",
            "Epoch 185 / 200: avg. loss of last epoch 0.013536590531282122\n",
            "avg. grad_norm of last epoch 0.7672508266289602\n",
            "Current train acc: 98.56666666666666%, test acc: 88.55%\n",
            "Epoch 186 / 200: avg. loss of last epoch 0.009157896735131123\n",
            "avg. grad_norm of last epoch 0.49386197454833447\n",
            "Current train acc: 98.95%, test acc: 89.06%\n",
            "Epoch 187 / 200: avg. loss of last epoch 0.014254325576351643\n",
            "avg. grad_norm of last epoch 0.7494839083151155\n",
            "Current train acc: 98.595%, test acc: 88.94%\n",
            "Epoch 188 / 200: avg. loss of last epoch 0.013026003178431235\n",
            "avg. grad_norm of last epoch 0.6648443464171742\n",
            "Current train acc: 98.59833333333333%, test acc: 88.69%\n",
            "Epoch 189 / 200: avg. loss of last epoch 0.012516032611904664\n",
            "avg. grad_norm of last epoch 0.7311403141335936\n",
            "Current train acc: 98.735%, test acc: 88.91%\n",
            "Epoch 190 / 200: avg. loss of last epoch 0.016488191616768014\n",
            "avg. grad_norm of last epoch 0.8726330440099332\n",
            "Current train acc: 99.07166666666667%, test acc: 88.89%\n",
            "Epoch 191 / 200: avg. loss of last epoch 0.010521408339155216\n",
            "avg. grad_norm of last epoch 0.5734596471530188\n",
            "Current train acc: 98.53166666666667%, test acc: 88.65%\n",
            "Epoch 192 / 200: avg. loss of last epoch 0.021860495622044722\n",
            "avg. grad_norm of last epoch 1.2404122348160826\n",
            "Current train acc: 98.56166666666667%, test acc: 89.0%\n",
            "Epoch 193 / 200: avg. loss of last epoch 0.014685285675789545\n",
            "avg. grad_norm of last epoch 0.8340243134362137\n",
            "Current train acc: 97.69166666666666%, test acc: 88.28%\n",
            "Epoch 194 / 200: avg. loss of last epoch 0.014603517869037267\n",
            "avg. grad_norm of last epoch 0.8222567043532424\n",
            "Current train acc: 98.80666666666667%, test acc: 89.17%\n",
            "Epoch 195 / 200: avg. loss of last epoch 0.014043243908851092\n",
            "avg. grad_norm of last epoch 0.856133282434002\n",
            "Current train acc: 98.69166666666666%, test acc: 88.72%\n",
            "Epoch 196 / 200: avg. loss of last epoch 0.01375270285157798\n",
            "avg. grad_norm of last epoch 0.7866196441451297\n",
            "Current train acc: 98.81833333333333%, test acc: 89.17%\n",
            "Epoch 197 / 200: avg. loss of last epoch 0.014271461676456963\n",
            "avg. grad_norm of last epoch 0.8506630375324148\n",
            "Current train acc: 98.94333333333333%, test acc: 88.72%\n",
            "Epoch 198 / 200: avg. loss of last epoch 0.011156510933158762\n",
            "avg. grad_norm of last epoch 0.6526441945067895\n",
            "Current train acc: 98.75666666666666%, test acc: 89.01%\n",
            "Epoch 199 / 200: avg. loss of last epoch 0.017892118880971503\n",
            "avg. grad_norm of last epoch 1.055907533528003\n",
            "Current train acc: 98.48333333333333%, test acc: 88.54%\n",
            "Epoch 200 / 200: avg. loss of last epoch 0.01715606367085904\n",
            "avg. grad_norm of last epoch 0.9923979953228068\n",
            "Current train acc: 98.33166666666666%, test acc: 88.57%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = LeNet_300_100()\n",
        "model = model.to(device)\n",
        "epoch_count = 200\n",
        "\n",
        "\n",
        "scheduler = constant_learning_rate_scheduler(0.2)\n",
        "\n",
        "#SSMG is single shuffle variant of the SMG (with different optimizer step.) \n",
        "#Thus, reload the batch by shuffling it once and disable shuffling in every epoch\n",
        "fashion_train_loader, fashion_test_loader = fashionmnist_loader(128, True)\n",
        "\n",
        "# beta is proposed in paper and epoch_count is inferenced from the graphs\n",
        "ssmgHistory = SSMG_train(model, criterion, epoch_count, fashion_train_loader, fashion_test_loader, \n",
        "                    scheduler, beta=0.5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC0moiGO8q1L"
      },
      "outputs": [],
      "source": [
        "#Save the history\n",
        "save_history_json(\"/content/gdrive/MyDrive/SMGExperiments/Fashion-Other-Optimizers/SSMG_constantLR.json\", ssmgHistory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "j4OdmOtU82AQ",
        "outputId": "6582fa24-7af1-4f98-f440-1a15bbe43e51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6e84450550>]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_loss(ssmgHistory)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SMG-Fashion",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "baba8200128446eb8c8de1c46af5b601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d42a77b92e446139584c80f90905f5e",
              "IPY_MODEL_7086157374414258aa605af32d91a144",
              "IPY_MODEL_dc211171e56d4f68bfd2b396259a0135"
            ],
            "layout": "IPY_MODEL_0166bc1ed3814b5cbac22d19212824fd"
          }
        },
        "8d42a77b92e446139584c80f90905f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806f16bad58b4e1b87252ebde54a339f",
            "placeholder": "​",
            "style": "IPY_MODEL_eda1f7d73ee6427b817aecb293c5a3b4",
            "value": ""
          }
        },
        "7086157374414258aa605af32d91a144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9664d37767d47d896007f4c18cf2251",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29e9d00f16ec45a5a90c6aa7e1c4f8c1",
            "value": 170498071
          }
        },
        "dc211171e56d4f68bfd2b396259a0135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b920cbaf17c34dfa8764b6ad3601a794",
            "placeholder": "​",
            "style": "IPY_MODEL_586fb1a3e5854706a72d847eb3b7c950",
            "value": " 170499072/? [00:01&lt;00:00, 93461490.94it/s]"
          }
        },
        "0166bc1ed3814b5cbac22d19212824fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806f16bad58b4e1b87252ebde54a339f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda1f7d73ee6427b817aecb293c5a3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9664d37767d47d896007f4c18cf2251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e9d00f16ec45a5a90c6aa7e1c4f8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b920cbaf17c34dfa8764b6ad3601a794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586fb1a3e5854706a72d847eb3b7c950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c9025c173334de9a3a461f122d60469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba4b74560aab4fdbb84ae0edaa997e42",
              "IPY_MODEL_3e3fb749a2d244b9935742d0e09f722a",
              "IPY_MODEL_57dcef63a63e44a7a5eae363934269b1"
            ],
            "layout": "IPY_MODEL_da78a3406b5246b3af72c0db9d75b8ba"
          }
        },
        "ba4b74560aab4fdbb84ae0edaa997e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4be9afe692446b8302471476798784",
            "placeholder": "​",
            "style": "IPY_MODEL_5053b4e60ca44465afea6b0cfcd22c44",
            "value": ""
          }
        },
        "3e3fb749a2d244b9935742d0e09f722a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1269fae892f6472b99f79ab7401b3c6d",
            "max": 26421880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd1e73f96b7440b48ab414c750c90cb8",
            "value": 26421880
          }
        },
        "57dcef63a63e44a7a5eae363934269b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2cdc548298346c99b402be463b7bd9d",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff2a7d676ea48229f18a86db397351b",
            "value": " 26422272/? [00:01&lt;00:00, 24303481.96it/s]"
          }
        },
        "da78a3406b5246b3af72c0db9d75b8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4be9afe692446b8302471476798784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5053b4e60ca44465afea6b0cfcd22c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1269fae892f6472b99f79ab7401b3c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd1e73f96b7440b48ab414c750c90cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2cdc548298346c99b402be463b7bd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff2a7d676ea48229f18a86db397351b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1faaec9c51b3496bb0861321a6c385c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce499b47beaa44c4b9136cd376b593f4",
              "IPY_MODEL_dd472c69660b44aea8c6694cd934f31a",
              "IPY_MODEL_6f10245b0b404934a44e1e73163753e5"
            ],
            "layout": "IPY_MODEL_6c00908f37b7474c874f0b263fa8648f"
          }
        },
        "ce499b47beaa44c4b9136cd376b593f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4458430668b040a0bb078ebecfabfbb7",
            "placeholder": "​",
            "style": "IPY_MODEL_83328625bf9d480a8c169a71023cddb3",
            "value": ""
          }
        },
        "dd472c69660b44aea8c6694cd934f31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57aa421bd57643d282f5b755cb847d1b",
            "max": 29515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4f59186d1ea4366a2c0cd3b41ae70eb",
            "value": 29515
          }
        },
        "6f10245b0b404934a44e1e73163753e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee8ab9fcba24c17aee2e014868125e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad831ebe6a64351ada239d4a2b030a4",
            "value": " 29696/? [00:00&lt;00:00, 46483.92it/s]"
          }
        },
        "6c00908f37b7474c874f0b263fa8648f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4458430668b040a0bb078ebecfabfbb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83328625bf9d480a8c169a71023cddb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57aa421bd57643d282f5b755cb847d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f59186d1ea4366a2c0cd3b41ae70eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ee8ab9fcba24c17aee2e014868125e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad831ebe6a64351ada239d4a2b030a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d141005b30c64596b118686eb461c55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78fc9c75521d4d2b82764ec01ca1fa65",
              "IPY_MODEL_771a406c6088407f8c55c5c11e8f9ebd",
              "IPY_MODEL_9ed0121747dc454b941b97cad73c9356"
            ],
            "layout": "IPY_MODEL_a87d53fcc7094eb7bdc23eea3ce3b408"
          }
        },
        "78fc9c75521d4d2b82764ec01ca1fa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72f5cf0606e442a4a709e916f701dbd8",
            "placeholder": "​",
            "style": "IPY_MODEL_1afe2f54c0e3477e932e7e7c2ff50809",
            "value": ""
          }
        },
        "771a406c6088407f8c55c5c11e8f9ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69d22b375a574294a58a876aea4617a9",
            "max": 4422102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaf55fcff17b45d2907aa40768edaffb",
            "value": 4422102
          }
        },
        "9ed0121747dc454b941b97cad73c9356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d058a7be54634e90b7400f09c46177a3",
            "placeholder": "​",
            "style": "IPY_MODEL_ca2da4e25dd741c6b79fcb30aca020ef",
            "value": " 4422656/? [00:00&lt;00:00, 8024051.08it/s]"
          }
        },
        "a87d53fcc7094eb7bdc23eea3ce3b408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f5cf0606e442a4a709e916f701dbd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1afe2f54c0e3477e932e7e7c2ff50809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69d22b375a574294a58a876aea4617a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf55fcff17b45d2907aa40768edaffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d058a7be54634e90b7400f09c46177a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca2da4e25dd741c6b79fcb30aca020ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e442f6c9f8a04572bb068fc0c4d344ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34cc73abcbf04692a84cbcbac82c4525",
              "IPY_MODEL_949b412c80d54d43b74dce81b213b5a4",
              "IPY_MODEL_0c22ab15b6d84c8d8f778ebe6a108f1f"
            ],
            "layout": "IPY_MODEL_13dc90490d874e44be4bc3f212a30e37"
          }
        },
        "34cc73abcbf04692a84cbcbac82c4525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd9b30c406845229f6d3ee2598fefa5",
            "placeholder": "​",
            "style": "IPY_MODEL_839531b462204439965448be1f0b8c6f",
            "value": ""
          }
        },
        "949b412c80d54d43b74dce81b213b5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b45be6936fe416b954120e63d5a4c2f",
            "max": 5148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_811f3931e2e44131ba9c39f6af742c73",
            "value": 5148
          }
        },
        "0c22ab15b6d84c8d8f778ebe6a108f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89616fd9e49e4175bf302214286e02d7",
            "placeholder": "​",
            "style": "IPY_MODEL_a8448180d8e84221adab466c8382f9ad",
            "value": " 6144/? [00:00&lt;00:00, 183702.62it/s]"
          }
        },
        "13dc90490d874e44be4bc3f212a30e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd9b30c406845229f6d3ee2598fefa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839531b462204439965448be1f0b8c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b45be6936fe416b954120e63d5a4c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811f3931e2e44131ba9c39f6af742c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89616fd9e49e4175bf302214286e02d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8448180d8e84221adab466c8382f9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}